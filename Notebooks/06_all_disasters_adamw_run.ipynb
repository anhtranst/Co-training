{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 06 — All Disasters: AdamW + Linear Scheduler (run-3)\n",
    "\n",
    "This notebook runs the **full 120 experiments** (10 events × 4 budgets × 3 seeds)\n",
    "using the updated training pipeline with **AdamW optimizer**, **linear LR scheduler**,\n",
    "and **10% warmup**. Only the **baseline** stopping strategy is used.\n",
    "\n",
    "### What changed vs previous runs\n",
    "\n",
    "| Setting | run-1 / run-2 | run-3 (this notebook) |\n",
    "|---|---|---|\n",
    "| Optimizer | Adam | **AdamW** |\n",
    "| Weight decay | 0 | **0.01** |\n",
    "| LR scheduler | None | **Linear with warmup** |\n",
    "| Warmup ratio | N/A | **0.1** (10% of total steps) |\n",
    "| Stopping strategy | baseline | baseline |\n",
    "| Other hyperparams | Paper defaults | Paper defaults |\n",
    "\n",
    "### Results location\n",
    "\n",
    "Results are stored in `results/gpt-4o/test/run-3/` with the standard layout:\n",
    "```\n",
    "results/gpt-4o/test/run-3/\n",
    "  {event}/\n",
    "    {budget}_set{seed}/\n",
    "      metrics.json\n",
    "```\n",
    "\n",
    "### Resume support\n",
    "\n",
    "Same two-level resume as notebooks 02/03:\n",
    "1. **Event level**: Events with all 12 `metrics.json` files are skipped entirely.\n",
    "2. **Experiment level**: Individual `(budget, seed_set)` combinations with existing\n",
    "   results are skipped within each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: D:\\Workspace\\Co-Training\n",
      "Budgets: [5, 10, 25, 50]\n",
      "Seed sets: [1, 2, 3]\n",
      "Experiments per event: 12\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_repo_root(marker: str = \"lg_cotrain\") -> Path:\n",
    "    for candidate in [Path().resolve()] + list(Path().resolve().parents):\n",
    "        if (candidate / marker).is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot find repo root: no ancestor directory contains '{marker}/'. \"\n",
    "        \"Run the notebook from inside the repository.\"\n",
    "    )\n",
    "\n",
    "repo_root = _find_repo_root()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lg_cotrain.run_all import BUDGETS, SEED_SETS, run_all_experiments, format_summary_table\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Budgets: {BUDGETS}\")\n",
    "print(f\"Seed sets: {SEED_SETS}\")\n",
    "print(f\"Experiments per event: {len(BUDGETS) * len(SEED_SETS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-label source: gpt-4o\n",
      "Run name: run-3\n",
      "Results root: D:\\Workspace\\Co-Training\\results\\gpt-4o\\test\\run-3\n",
      "Stopping strategy: baseline\n",
      "Weight decay: 0.01\n",
      "Warmup ratio: 0.1\n"
     ]
    }
   ],
   "source": [
    "# ---- Configuration ----\n",
    "PSEUDO_LABEL_SOURCE = \"gpt-4o\"\n",
    "RUN_NAME = \"run-3\"\n",
    "\n",
    "DATA_ROOT = str(repo_root / \"data\")\n",
    "RESULTS_ROOT = str(repo_root / \"results\" / PSEUDO_LABEL_SOURCE / \"test\" / RUN_NAME)\n",
    "\n",
    "# Hyperparameters: paper defaults + AdamW weight decay + linear scheduler\n",
    "STOPPING_STRATEGY = \"baseline\"\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "print(f\"Pseudo-label source: {PSEUDO_LABEL_SOURCE}\")\n",
    "print(f\"Run name: {RUN_NAME}\")\n",
    "print(f\"Results root: {RESULTS_ROOT}\")\n",
    "print(f\"Stopping strategy: {STOPPING_STRATEGY}\")\n",
    "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"Warmup ratio: {WARMUP_RATIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 events total\n",
      "  Completed: 0 (0 experiments)\n",
      "  Pending:   10 (up to 120 experiments)\n",
      "\n",
      "Pending events (will be run):\n",
      "  - california_wildfires_2018\n",
      "  - canada_wildfires_2016\n",
      "  - cyclone_idai_2019\n",
      "  - hurricane_dorian_2019\n",
      "  - hurricane_florence_2018\n",
      "  - hurricane_harvey_2017\n",
      "  - hurricane_irma_2017\n",
      "  - hurricane_maria_2017\n",
      "  - kaikoura_earthquake_2016\n",
      "  - kerala_floods_2018\n"
     ]
    }
   ],
   "source": [
    "def is_event_complete(event, results_root):\n",
    "    \"\"\"Check if all 12 metrics.json files exist for an event.\"\"\"\n",
    "    for budget in BUDGETS:\n",
    "        for seed_set in SEED_SETS:\n",
    "            path = Path(results_root) / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "            if not path.exists():\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Discover events from data directory\n",
    "data_dir = Path(DATA_ROOT) / \"original\"\n",
    "all_events = sorted(p.name for p in data_dir.iterdir() if p.is_dir())\n",
    "\n",
    "completed_events = [e for e in all_events if is_event_complete(e, RESULTS_ROOT)]\n",
    "pending_events = [e for e in all_events if e not in completed_events]\n",
    "\n",
    "print(f\"Found {len(all_events)} events total\")\n",
    "print(f\"  Completed: {len(completed_events)} ({len(completed_events) * 12} experiments)\")\n",
    "print(f\"  Pending:   {len(pending_events)} (up to {len(pending_events) * 12} experiments)\")\n",
    "\n",
    "if completed_events:\n",
    "    print(f\"\\nCompleted events (will be skipped):\")\n",
    "    for e in completed_events:\n",
    "        print(f\"  - {e}\")\n",
    "\n",
    "if pending_events:\n",
    "    print(f\"\\nPending events (will be run):\")\n",
    "    for e in pending_events:\n",
    "        print(f\"  - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments\n",
    "\n",
    "For each pending event, we call `run_all_experiments` with the AdamW\n",
    "hyperparameters (`weight_decay=0.01`, `warmup_ratio=0.1`) and baseline\n",
    "stopping strategy.\n",
    "\n",
    "Individual experiments that already have `metrics.json` are automatically\n",
    "skipped (useful if the notebook crashed mid-event).\n",
    "\n",
    "**Expected runtime**: ~3–5 hours for all 120 experiments on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments: 120\n",
      "Already completed: 0\n",
      "Remaining: 120\n",
      "\n",
      "============================================================\n",
      "Event 1/10: california_wildfires_2018\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Co-Training\\co-training-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 23:27:24,386 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=1\n",
      "2026-02-20 23:27:24,424 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 23:27:24,437 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-20 23:27:24,440 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 988.12it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1013.16it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 23:27:43,160 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0981, mean_prob2=0.1025\n",
      "2026-02-20 23:28:00,550 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0997, mean_prob2=0.0991\n",
      "2026-02-20 23:28:18,604 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1010, mean_prob2=0.0970\n"
     ]
    }
   ],
   "source": [
    "class ProgressTracker:\n",
    "    \"\"\"Track global progress across all experiments.\"\"\"\n",
    "\n",
    "    def __init__(self, total, already_done, start_time):\n",
    "        self.total = total\n",
    "        self.done = already_done\n",
    "        self.start_time = start_time\n",
    "\n",
    "    def update(self, event, budget, seed_set, status):\n",
    "        self.done += 1\n",
    "        elapsed = time.time() - self.start_time\n",
    "        pct = 100.0 * self.done / self.total\n",
    "        elapsed_h = elapsed / 3600\n",
    "\n",
    "        remaining = self.total - self.done\n",
    "        if elapsed > 0 and self.done > 0:\n",
    "            eta_h = (elapsed / self.done) * remaining / 3600\n",
    "        else:\n",
    "            eta_h = 0\n",
    "\n",
    "        print(\n",
    "            f\"[PROGRESS] {self.done}/{self.total} ({pct:.1f}%)\"\n",
    "            f\" | Elapsed: {elapsed_h:.2f}h | ETA: {eta_h:.2f}h\"\n",
    "        )\n",
    "\n",
    "# Count already-completed experiments\n",
    "already_done = sum(\n",
    "    1\n",
    "    for e in all_events\n",
    "    for b in BUDGETS\n",
    "    for s in SEED_SETS\n",
    "    if (Path(RESULTS_ROOT) / e / f\"{b}_set{s}\" / \"metrics.json\").exists()\n",
    ")\n",
    "total_experiments = len(all_events) * len(BUDGETS) * len(SEED_SETS)\n",
    "\n",
    "print(f\"Total experiments: {total_experiments}\")\n",
    "print(f\"Already completed: {already_done}\")\n",
    "print(f\"Remaining: {total_experiments - already_done}\")\n",
    "\n",
    "all_event_results = {}\n",
    "overall_start = time.time()\n",
    "tracker = ProgressTracker(total_experiments, already_done, overall_start)\n",
    "\n",
    "# Run pending events\n",
    "for i, event in enumerate(pending_events, 1):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Event {i}/{len(pending_events)}: {event}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    results = run_all_experiments(\n",
    "        event,\n",
    "        pseudo_label_source=PSEUDO_LABEL_SOURCE,\n",
    "        stopping_strategy=STOPPING_STRATEGY,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        data_root=DATA_ROOT,\n",
    "        results_root=RESULTS_ROOT,\n",
    "        _on_experiment_done=tracker.update,\n",
    "    )\n",
    "    all_event_results[event] = results\n",
    "\n",
    "    print()\n",
    "    print(format_summary_table(results, event))\n",
    "\n",
    "# Load results for already-completed events\n",
    "for event in completed_events:\n",
    "    results = []\n",
    "    for budget in BUDGETS:\n",
    "        for seed_set in SEED_SETS:\n",
    "            path = Path(RESULTS_ROOT) / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "            with open(path) as f:\n",
    "                results.append(json.load(f))\n",
    "    all_event_results[event] = results\n",
    "\n",
    "overall_elapsed = time.time() - overall_start\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"All events done in {overall_elapsed / 3600:.2f}h\")\n",
    "print(f\"Total events with results: {len(all_event_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Disaster Results\n",
    "\n",
    "We now aggregate results across all events to compare how the pipeline\n",
    "performs with AdamW on different disaster types and how performance scales\n",
    "with the labeled data budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross-disaster summary: event -> budget -> mean macro-F1\n",
    "summary = {}\n",
    "for event in sorted(all_event_results.keys()):\n",
    "    results = all_event_results[event]\n",
    "    by_budget = {b: [] for b in BUDGETS}\n",
    "    for r in results:\n",
    "        if r is not None:\n",
    "            by_budget[r[\"budget\"]].append(r)\n",
    "    summary[event] = {}\n",
    "    for b in BUDGETS:\n",
    "        f1s = [r[\"test_macro_f1\"] for r in by_budget[b]]\n",
    "        errs = [r[\"test_error_rate\"] for r in by_budget[b]]\n",
    "        summary[event][b] = {\n",
    "            \"f1_mean\": statistics.mean(f1s) if f1s else None,\n",
    "            \"f1_std\": statistics.stdev(f1s) if len(f1s) >= 2 else None,\n",
    "            \"err_mean\": statistics.mean(errs) if errs else None,\n",
    "            \"err_std\": statistics.stdev(errs) if len(errs) >= 2 else None,\n",
    "            \"n_seeds\": len(f1s),\n",
    "        }\n",
    "\n",
    "# Print grand summary table\n",
    "header = f\"{'Event':<35}\"\n",
    "for b in BUDGETS:\n",
    "    header += f\" | B={b:<11}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for event in sorted(summary.keys()):\n",
    "    row = f\"{event:<35}\"\n",
    "    for b in BUDGETS:\n",
    "        s = summary[event][b]\n",
    "        if s[\"f1_mean\"] is not None and s[\"f1_std\"] is not None:\n",
    "            row += f\" | {s['f1_mean']:.3f}+/-{s['f1_std']:.3f}\"\n",
    "        elif s[\"f1_mean\"] is not None:\n",
    "            row += f\" | {s['f1_mean']:.3f}      \"\n",
    "        else:\n",
    "            row += f\" | {'N/A':<11}\"\n",
    "    print(row)\n",
    "\n",
    "# Grand mean across all events\n",
    "print()\n",
    "grand_row = f\"{'GRAND MEAN':<35}\"\n",
    "for b in BUDGETS:\n",
    "    all_f1 = [summary[e][b][\"f1_mean\"] for e in summary if summary[e][b][\"f1_mean\"] is not None]\n",
    "    if all_f1:\n",
    "        grand_row += f\" | {statistics.mean(all_f1):.3f}      \"\n",
    "    else:\n",
    "        grand_row += f\" | {'N/A':<11}\"\n",
    "print(grand_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot: Macro-F1 by budget, one line per event\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for event in sorted(summary.keys()):\n",
    "    means = [summary[event][b][\"f1_mean\"] or 0 for b in BUDGETS]\n",
    "    stds = [summary[event][b][\"f1_std\"] or 0 for b in BUDGETS]\n",
    "    ax.errorbar(BUDGETS, means, yerr=stds, marker=\"o\", capsize=3, label=event)\n",
    "\n",
    "ax.set_xlabel(\"Budget (labeled samples per class)\")\n",
    "ax.set_ylabel(\"Test Macro-F1 (mean +/- std across seeds)\")\n",
    "ax.set_title(f\"LG-CoTrain Performance — {PSEUDO_LABEL_SOURCE} — AdamW (run-3)\")\n",
    "ax.set_xticks(BUDGETS)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap: events (rows) x budgets (columns), colored by mean macro-F1\n",
    "events_sorted = sorted(summary.keys())\n",
    "heatmap_data = np.zeros((len(events_sorted), len(BUDGETS)))\n",
    "\n",
    "for i, event in enumerate(events_sorted):\n",
    "    for j, b in enumerate(BUDGETS):\n",
    "        val = summary[event][b][\"f1_mean\"]\n",
    "        heatmap_data[i, j] = val if val is not None else 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(heatmap_data, cmap=\"YlOrRd\", aspect=\"auto\")\n",
    "\n",
    "ax.set_xticks(range(len(BUDGETS)))\n",
    "ax.set_xticklabels([f\"B={b}\" for b in BUDGETS])\n",
    "ax.set_yticks(range(len(events_sorted)))\n",
    "ax.set_yticklabels(events_sorted, fontsize=9)\n",
    "ax.set_title(f\"Mean Test Macro-F1 — {PSEUDO_LABEL_SOURCE} — AdamW (run-3)\")\n",
    "\n",
    "for i in range(len(events_sorted)):\n",
    "    for j in range(len(BUDGETS)):\n",
    "        val = heatmap_data[i, j]\n",
    "        color = \"white\" if val > 0.6 else \"black\"\n",
    "        ax.text(j, i, f\"{val:.3f}\", ha=\"center\", va=\"center\", color=color, fontsize=9)\n",
    "\n",
    "fig.colorbar(im, ax=ax, label=\"Macro-F1\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lg_cotrain.dashboard import collect_all_metrics, generate_html\n",
    "\n",
    "metrics = collect_all_metrics(RESULTS_ROOT)\n",
    "html = generate_html(metrics, RESULTS_ROOT)\n",
    "dashboard_path = Path(RESULTS_ROOT) / \"dashboard.html\"\n",
    "dashboard_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dashboard_path.write_text(html)\n",
    "print(f\"Dashboard written to: {dashboard_path}\")\n",
    "print(f\"Metrics loaded: {len(metrics)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook ran all 120 experiments using the updated pipeline with:\n",
    "- **Optimizer**: AdamW (weight_decay=0.01)\n",
    "- **LR scheduler**: Linear with 10% warmup\n",
    "- **Stopping strategy**: baseline (patience=5 on ensemble dev macro-F1)\n",
    "- **Other hyperparameters**: Paper defaults (lr=2e-5, batch_size=32, etc.)\n",
    "\n",
    "Results are stored in `results/gpt-4o/test/run-3/`.\n",
    "\n",
    "### CLI equivalent\n",
    "```bash\n",
    "python -m lg_cotrain.run_experiment \\\n",
    "    --events california_wildfires_2018 canada_wildfires_2016 cyclone_idai_2019 \\\n",
    "            hurricane_dorian_2019 hurricane_florence_2018 hurricane_harvey_2017 \\\n",
    "            hurricane_irma_2017 hurricane_maria_2017 kaikoura_earthquake_2016 \\\n",
    "            kerala_floods_2018 \\\n",
    "    --pseudo-label-source gpt-4o \\\n",
    "    --stopping-strategy baseline \\\n",
    "    --weight-decay 0.01 \\\n",
    "    --warmup-ratio 0.1 \\\n",
    "    --output-folder results/gpt-4o/test/run-3\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
