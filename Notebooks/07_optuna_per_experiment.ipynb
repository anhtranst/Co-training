{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LG-CoTrain: Per-Experiment Optuna Hyperparameter Tuning\n",
    "\n",
    "This notebook runs **120 separate Optuna studies** — one for each\n",
    "(event, budget, seed_set) combination — to find experiment-specific\n",
    "optimal hyperparameters.\n",
    "\n",
    "### Why per-experiment tuning?\n",
    "\n",
    "- Different disaster events and budget levels may benefit from different\n",
    "  hyperparameters (e.g., low-budget experiments may need different LR or patience).\n",
    "- Each study optimizes `dev_macro_f1` — **no test-set leakage**.\n",
    "- Results are saved as JSON files for easy inspection and reuse.\n",
    "\n",
    "### Search space (6 hyperparameters)\n",
    "\n",
    "| Parameter | Type | Range | Default |\n",
    "|-----------|------|-------|--------|\n",
    "| `lr` | Float (log) | 1e-5 to 1e-3 | 2e-5 |\n",
    "| `batch_size` | Categorical | [8, 16, 32, 64] | 32 |\n",
    "| `cotrain_epochs` | Integer | 5 to 20 | 10 |\n",
    "| `finetune_patience` | Integer | 4 to 10 | 5 |\n",
    "| `weight_decay` | Float | 0.0 to 0.1 | 0.01 |\n",
    "| `warmup_ratio` | Float | 0.0 to 0.3 | 0.1 |\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. Run this notebook to find 120 sets of optimal hyperparameters\n",
    "2. Use notebook 08 to run final experiments with the optimized hyperparameters\n",
    "3. Compare against run-3 (default hyperparameters)\n",
    "\n",
    "### Incremental scaling\n",
    "\n",
    "Results are stored under `trials_{n}/` subfolders. Running with a higher\n",
    "`N_TRIALS` automatically continues from previous results:\n",
    "\n",
    "- First run with `N_TRIALS=10` → saves to `trials_10/`\n",
    "- Later run with `N_TRIALS=20` → loads 10 previous trials, runs 10 new, saves to `trials_20/`\n",
    "- Both `trials_10/` and `trials_20/` coexist — no data is overwritten\n",
    "\n",
    "### Resume support\n",
    "\n",
    "Studies whose `trials_{N_TRIALS}/best_params.json` already exists are\n",
    "automatically skipped. You can interrupt and restart this notebook safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: D:\\Workspace\\Co-Training\n",
      "Events (10): ['california_wildfires_2018', 'canada_wildfires_2016', 'cyclone_idai_2019', 'hurricane_dorian_2019', 'hurricane_florence_2018', 'hurricane_harvey_2017', 'hurricane_irma_2017', 'hurricane_maria_2017', 'kaikoura_earthquake_2016', 'kerala_floods_2018']\n",
      "Budgets: [5, 10, 25, 50]\n",
      "Seed sets: [1, 2, 3]\n",
      "Total studies: 120\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_repo_root(marker: str = \"lg_cotrain\") -> Path:\n",
    "    for candidate in [Path().resolve()] + list(Path().resolve().parents):\n",
    "        if (candidate / marker).is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot find repo root: no ancestor directory contains '{marker}/'. \"\n",
    "        \"Run the notebook from inside the repository.\"\n",
    "    )\n",
    "\n",
    "\n",
    "repo_root = _find_repo_root()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import lg_cotrain.optuna_per_experiment\n",
    "importlib.reload(lg_cotrain.optuna_per_experiment)\n",
    "from lg_cotrain.optuna_per_experiment import (\n",
    "    ALL_EVENTS, BUDGETS, SEED_SETS,\n",
    "    run_all_studies, load_best_params,\n",
    ")\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Events ({len(ALL_EVENTS)}): {ALL_EVENTS}\")\n",
    "print(f\"Budgets: {BUDGETS}\")\n",
    "print(f\"Seed sets: {SEED_SETS}\")\n",
    "print(f\"Total studies: {len(ALL_EVENTS) * len(BUDGETS) * len(SEED_SETS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "- **`N_TRIALS`**: Number of Optuna trials per study. More trials = better\n",
    "  hyperparameters but longer runtime. Start with 10-15.\n",
    "- **`NUM_GPUS`**: Number of GPUs for parallel study execution. Each study\n",
    "  runs on one GPU; multiple studies run simultaneously.\n",
    "- **`STORAGE_DIR`**: Where to save results. Each trial count gets its own\n",
    "  subfolder (`trials_{N_TRIALS}/`), so increasing `N_TRIALS` later won't\n",
    "  overwrite previous results.\n",
    "\n",
    "### Runtime estimate\n",
    "\n",
    "- ~7 min per pipeline run x N_TRIALS per study x 120 studies\n",
    "- With 2 GPUs: N_TRIALS=15 -> ~105 hours (~4.4 days)\n",
    "- Incremental: if you previously ran with N_TRIALS=10, running N_TRIALS=20\n",
    "  only executes 10 new trials per study (saves ~50% time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies        : 120\n",
      "Trials/study   : 10\n",
      "Total trials   : 1200 (max — fewer if continuing from previous runs)\n",
      "GPUs           : 2\n",
      "Storage dir    : D:\\Workspace\\Co-Training\\results\\optuna\\per_experiment\n",
      "Results folder : trials_10/\n",
      "Est. runtime   : ~70 hours (2.9 days) from scratch\n",
      "\n",
      "Search space:\n",
      "  lr               : 1e-5 to 1e-3  (log-uniform)\n",
      "  batch_size       : [8, 16, 32, 64]\n",
      "  cotrain_epochs   : 5 to 20\n",
      "  finetune_patience: 4 to 10\n",
      "  weight_decay     : 0.0 to 0.1\n",
      "  warmup_ratio     : 0.0 to 0.3\n"
     ]
    }
   ],
   "source": [
    "# ---- Tuning Configuration ----\n",
    "\n",
    "N_TRIALS  = 10        # Optuna trials per study (incremental: continues from previous runs)\n",
    "NUM_GPUS  = 2         # Number of GPUs for parallel execution\n",
    "\n",
    "DATA_ROOT    = str(repo_root / \"data\")\n",
    "STORAGE_DIR  = str(repo_root / \"results\" / \"optuna\" / \"per_experiment\")\n",
    "\n",
    "PSEUDO_LABEL_SOURCE = \"gpt-4o\"\n",
    "\n",
    "# Optionally restrict to a subset (set to None for all)\n",
    "EVENTS    = None   # or e.g. [\"hurricane_harvey_2017\", \"kerala_floods_2018\"]\n",
    "BUDGETS_  = None   # or e.g. [5, 50]\n",
    "SEEDS_    = None   # or e.g. [1]\n",
    "\n",
    "events_to_use  = EVENTS or ALL_EVENTS\n",
    "budgets_to_use = BUDGETS_ or BUDGETS\n",
    "seeds_to_use   = SEEDS_ or SEED_SETS\n",
    "total_studies   = len(events_to_use) * len(budgets_to_use) * len(seeds_to_use)\n",
    "total_trials    = total_studies * N_TRIALS\n",
    "\n",
    "est_hours = total_trials * 7 / 60 / max(NUM_GPUS, 1)\n",
    "\n",
    "print(f\"Studies        : {total_studies}\")\n",
    "print(f\"Trials/study   : {N_TRIALS}\")\n",
    "print(f\"Total trials   : {total_trials} (max — fewer if continuing from previous runs)\")\n",
    "print(f\"GPUs           : {NUM_GPUS}\")\n",
    "print(f\"Storage dir    : {STORAGE_DIR}\")\n",
    "print(f\"Results folder : trials_{N_TRIALS}/\")\n",
    "print(f\"Est. runtime   : ~{est_hours:.0f} hours ({est_hours/24:.1f} days) from scratch\")\n",
    "print()\n",
    "print(\"Search space:\")\n",
    "print(\"  lr               : 1e-5 to 1e-3  (log-uniform)\")\n",
    "print(\"  batch_size       : [8, 16, 32, 64]\")\n",
    "print(\"  cotrain_epochs   : 5 to 20\")\n",
    "print(\"  finetune_patience: 4 to 10\")\n",
    "print(\"  weight_decay     : 0.0 to 0.1\")\n",
    "print(\"  warmup_ratio     : 0.0 to 0.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run All Optuna Studies\n",
    "\n",
    "This cell launches all studies. With `NUM_GPUS > 1`, studies run in parallel\n",
    "across GPUs using `ProcessPoolExecutor` with spawn context.\n",
    "\n",
    "**Progress tracking**: After each study completes, you'll see the event,\n",
    "budget, seed, status, and best dev F1 found.\n",
    "\n",
    "**Incremental**: If previous trials exist (e.g., `trials_10/`), they are\n",
    "replayed into the TPE sampler and only the remaining trials execute.\n",
    "\n",
    "**Resume**: If `trials_{N_TRIALS}/best_params.json` already exists for a\n",
    "study, that study is skipped entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  california_wildfires_2018 budget=5 seed=1 -- SKIPPED (trials_10 exists)\n",
      "  [1/120] california_wildfires_2018 b=5 s=1 -> skipped | Elapsed: 0.00h | ETA: 0.00h\n",
      "  california_wildfires_2018 budget=5 seed=2 -- SKIPPED (trials_10 exists)\n",
      "  [2/120] california_wildfires_2018 b=5 s=2 -> skipped | Elapsed: 0.00h | ETA: 0.00h\n",
      "\n",
      "Optuna per-experiment: 120 total, 2 skipped, 118 pending\n",
      "Running 118 Optuna studies in parallel across 2 GPUs...\n",
      "  california_wildfires_2018 budget=10 seed=1 -- done (best_dev_f1=0.6272)\n",
      "  [3/120] california_wildfires_2018 b=10 s=1 -> done | Elapsed: 2.93h | ETA: 114.46h\n",
      "  california_wildfires_2018 budget=5 seed=3 -- done (best_dev_f1=0.6313)\n",
      "  [4/120] california_wildfires_2018 b=5 s=3 -> done | Elapsed: 3.28h | ETA: 95.02h\n",
      "  california_wildfires_2018 budget=10 seed=2 -- done (best_dev_f1=0.6492)\n",
      "  [5/120] california_wildfires_2018 b=10 s=2 -> done | Elapsed: 5.86h | ETA: 134.70h\n",
      "  california_wildfires_2018 budget=10 seed=3 -- done (best_dev_f1=0.6416)\n",
      "  [6/120] california_wildfires_2018 b=10 s=3 -> done | Elapsed: 6.48h | ETA: 123.20h\n",
      "  california_wildfires_2018 budget=25 seed=2 -- done (best_dev_f1=0.6689)\n",
      "  [7/120] california_wildfires_2018 b=25 s=2 -> done | Elapsed: 9.59h | ETA: 154.88h\n",
      "  california_wildfires_2018 budget=25 seed=1 -- done (best_dev_f1=0.6302)\n",
      "  [8/120] california_wildfires_2018 b=25 s=1 -> done | Elapsed: 10.29h | ETA: 144.09h\n",
      "  california_wildfires_2018 budget=25 seed=3 -- done (best_dev_f1=0.6393)\n",
      "  [9/120] california_wildfires_2018 b=25 s=3 -> done | Elapsed: 12.32h | ETA: 151.96h\n",
      "  california_wildfires_2018 budget=50 seed=1 -- done (best_dev_f1=0.6491)\n",
      "  [10/120] california_wildfires_2018 b=50 s=1 -> done | Elapsed: 13.93h | ETA: 153.21h\n",
      "  california_wildfires_2018 budget=50 seed=2 -- done (best_dev_f1=0.6610)\n",
      "  [11/120] california_wildfires_2018 b=50 s=2 -> done | Elapsed: 15.28h | ETA: 151.37h\n",
      "  canada_wildfires_2016 budget=5 seed=1 -- done (best_dev_f1=0.6301)\n",
      "  [12/120] canada_wildfires_2016 b=5 s=1 -> done | Elapsed: 16.28h | ETA: 146.54h\n",
      "  canada_wildfires_2016 budget=5 seed=2 -- done (best_dev_f1=0.6543)\n",
      "  [13/120] canada_wildfires_2016 b=5 s=2 -> done | Elapsed: 17.11h | ETA: 140.85h\n",
      "  california_wildfires_2018 budget=50 seed=3 -- done (best_dev_f1=0.6517)\n",
      "  [14/120] california_wildfires_2018 b=50 s=3 -> done | Elapsed: 17.31h | ETA: 131.09h\n",
      "  canada_wildfires_2016 budget=5 seed=3 -- done (best_dev_f1=0.6945)\n",
      "  [15/120] canada_wildfires_2016 b=5 s=3 -> done | Elapsed: 17.97h | ETA: 125.79h\n",
      "  canada_wildfires_2016 budget=10 seed=1 -- done (best_dev_f1=0.6544)\n",
      "  [16/120] canada_wildfires_2016 b=10 s=1 -> done | Elapsed: 18.39h | ETA: 119.56h\n",
      "  canada_wildfires_2016 budget=10 seed=2 -- done (best_dev_f1=0.6946)\n",
      "  [17/120] canada_wildfires_2016 b=10 s=2 -> done | Elapsed: 18.94h | ETA: 114.77h\n",
      "  canada_wildfires_2016 budget=10 seed=3 -- done (best_dev_f1=0.6981)\n",
      "  [18/120] canada_wildfires_2016 b=10 s=3 -> done | Elapsed: 19.37h | ETA: 109.77h\n",
      "  canada_wildfires_2016 budget=25 seed=1 -- done (best_dev_f1=0.7121)\n",
      "  [19/120] canada_wildfires_2016 b=25 s=1 -> done | Elapsed: 19.91h | ETA: 105.85h\n",
      "  canada_wildfires_2016 budget=25 seed=2 -- done (best_dev_f1=0.6820)\n",
      "  [20/120] canada_wildfires_2016 b=25 s=2 -> done | Elapsed: 20.25h | ETA: 101.26h\n",
      "  canada_wildfires_2016 budget=25 seed=3 -- done (best_dev_f1=0.7553)\n",
      "  [21/120] canada_wildfires_2016 b=25 s=3 -> done | Elapsed: 20.85h | ETA: 98.30h\n",
      "  canada_wildfires_2016 budget=50 seed=1 -- done (best_dev_f1=0.7222)\n",
      "  [22/120] canada_wildfires_2016 b=50 s=1 -> done | Elapsed: 21.10h | ETA: 93.99h\n",
      "  canada_wildfires_2016 budget=50 seed=2 -- done (best_dev_f1=0.7047)\n",
      "  [23/120] canada_wildfires_2016 b=50 s=2 -> done | Elapsed: 21.69h | ETA: 91.48h\n",
      "  canada_wildfires_2016 budget=50 seed=3 -- done (best_dev_f1=0.7447)\n",
      "  [24/120] canada_wildfires_2016 b=50 s=3 -> done | Elapsed: 21.97h | ETA: 87.86h\n",
      "  cyclone_idai_2019 budget=5 seed=2 -- done (best_dev_f1=0.5809)\n",
      "  [25/120] cyclone_idai_2019 b=5 s=2 -> done | Elapsed: 23.52h | ETA: 89.37h\n",
      "  cyclone_idai_2019 budget=5 seed=1 -- done (best_dev_f1=0.5756)\n",
      "  [26/120] cyclone_idai_2019 b=5 s=1 -> done | Elapsed: 23.57h | ETA: 85.22h\n",
      "  cyclone_idai_2019 budget=5 seed=3 -- done (best_dev_f1=0.5044)\n",
      "  [27/120] cyclone_idai_2019 b=5 s=3 -> done | Elapsed: 25.14h | ETA: 86.59h\n",
      "  cyclone_idai_2019 budget=10 seed=1 -- done (best_dev_f1=0.5331)\n",
      "  [28/120] cyclone_idai_2019 b=10 s=1 -> done | Elapsed: 25.54h | ETA: 83.91h\n",
      "  cyclone_idai_2019 budget=10 seed=2 -- done (best_dev_f1=0.5393)\n",
      "  [29/120] cyclone_idai_2019 b=10 s=2 -> done | Elapsed: 26.87h | ETA: 84.32h\n",
      "  cyclone_idai_2019 budget=10 seed=3 -- done (best_dev_f1=0.5069)\n",
      "  [30/120] cyclone_idai_2019 b=10 s=3 -> done | Elapsed: 27.25h | ETA: 81.74h\n",
      "  cyclone_idai_2019 budget=25 seed=1 -- done (best_dev_f1=0.5356)\n",
      "  [31/120] cyclone_idai_2019 b=25 s=1 -> done | Elapsed: 28.56h | ETA: 81.99h\n",
      "  cyclone_idai_2019 budget=25 seed=2 -- done (best_dev_f1=0.5157)\n",
      "  [32/120] cyclone_idai_2019 b=25 s=2 -> done | Elapsed: 28.72h | ETA: 78.99h\n",
      "  cyclone_idai_2019 budget=50 seed=1 -- done (best_dev_f1=0.5742)\n",
      "  [33/120] cyclone_idai_2019 b=50 s=1 -> done | Elapsed: 30.28h | ETA: 79.83h\n",
      "  cyclone_idai_2019 budget=25 seed=3 -- done (best_dev_f1=0.4935)\n",
      "  [34/120] cyclone_idai_2019 b=25 s=3 -> done | Elapsed: 30.67h | ETA: 77.58h\n",
      "  cyclone_idai_2019 budget=50 seed=2 -- done (best_dev_f1=0.5265)\n",
      "  [35/120] cyclone_idai_2019 b=50 s=2 -> done | Elapsed: 31.92h | ETA: 77.51h\n",
      "  cyclone_idai_2019 budget=50 seed=3 -- done (best_dev_f1=0.5647)\n",
      "  [36/120] cyclone_idai_2019 b=50 s=3 -> done | Elapsed: 32.56h | ETA: 75.98h\n",
      "  hurricane_dorian_2019 budget=5 seed=1 -- done (best_dev_f1=0.5801)\n",
      "  [37/120] hurricane_dorian_2019 b=5 s=1 -> done | Elapsed: 35.11h | ETA: 78.75h\n",
      "  hurricane_dorian_2019 budget=5 seed=2 -- done (best_dev_f1=0.6036)\n",
      "  [38/120] hurricane_dorian_2019 b=5 s=2 -> done | Elapsed: 36.24h | ETA: 78.19h\n",
      "  hurricane_dorian_2019 budget=5 seed=3 -- done (best_dev_f1=0.5490)\n",
      "  [39/120] hurricane_dorian_2019 b=5 s=3 -> done | Elapsed: 38.71h | ETA: 80.40h\n",
      "  hurricane_dorian_2019 budget=10 seed=1 -- done (best_dev_f1=0.5859)\n",
      "  [40/120] hurricane_dorian_2019 b=10 s=1 -> done | Elapsed: 39.08h | ETA: 78.17h\n",
      "  hurricane_dorian_2019 budget=10 seed=2 -- done (best_dev_f1=0.6079)\n",
      "  [41/120] hurricane_dorian_2019 b=10 s=2 -> done | Elapsed: 41.82h | ETA: 80.57h\n",
      "  hurricane_dorian_2019 budget=10 seed=3 -- done (best_dev_f1=0.5756)\n",
      "  [42/120] hurricane_dorian_2019 b=10 s=3 -> done | Elapsed: 41.86h | ETA: 77.74h\n",
      "  hurricane_dorian_2019 budget=25 seed=1 -- done (best_dev_f1=0.6159)\n",
      "  [43/120] hurricane_dorian_2019 b=25 s=1 -> done | Elapsed: 45.22h | ETA: 80.97h\n",
      "  hurricane_dorian_2019 budget=25 seed=2 -- done (best_dev_f1=0.5985)\n",
      "  [44/120] hurricane_dorian_2019 b=25 s=2 -> done | Elapsed: 45.62h | ETA: 78.80h\n",
      "  hurricane_dorian_2019 budget=25 seed=3 -- done (best_dev_f1=0.6062)\n",
      "  [45/120] hurricane_dorian_2019 b=25 s=3 -> done | Elapsed: 48.10h | ETA: 80.17h\n",
      "  hurricane_dorian_2019 budget=50 seed=1 -- done (best_dev_f1=0.6269)\n",
      "  [46/120] hurricane_dorian_2019 b=50 s=1 -> done | Elapsed: 48.69h | ETA: 78.33h\n",
      "  hurricane_dorian_2019 budget=50 seed=2 -- done (best_dev_f1=0.6111)\n",
      "  [47/120] hurricane_dorian_2019 b=50 s=2 -> done | Elapsed: 51.32h | ETA: 79.72h\n",
      "  hurricane_dorian_2019 budget=50 seed=3 -- done (best_dev_f1=0.6234)\n",
      "  [48/120] hurricane_dorian_2019 b=50 s=3 -> done | Elapsed: 52.14h | ETA: 78.21h\n",
      "  hurricane_florence_2018 budget=5 seed=1 -- done (best_dev_f1=0.6792)\n",
      "  [49/120] hurricane_florence_2018 b=5 s=1 -> done | Elapsed: 53.85h | ETA: 78.02h\n",
      "  hurricane_florence_2018 budget=5 seed=2 -- done (best_dev_f1=0.6704)\n",
      "  [50/120] hurricane_florence_2018 b=5 s=2 -> done | Elapsed: 55.08h | ETA: 77.12h\n",
      "  hurricane_florence_2018 budget=5 seed=3 -- done (best_dev_f1=0.6742)\n",
      "  [51/120] hurricane_florence_2018 b=5 s=3 -> done | Elapsed: 56.43h | ETA: 76.35h\n",
      "  hurricane_florence_2018 budget=10 seed=1 -- done (best_dev_f1=0.6788)\n",
      "  [52/120] hurricane_florence_2018 b=10 s=1 -> done | Elapsed: 58.42h | ETA: 76.40h\n",
      "  hurricane_florence_2018 budget=10 seed=2 -- done (best_dev_f1=0.6848)\n",
      "  [53/120] hurricane_florence_2018 b=10 s=2 -> done | Elapsed: 59.19h | ETA: 74.82h\n",
      "  hurricane_florence_2018 budget=10 seed=3 -- done (best_dev_f1=0.6818)\n",
      "  [54/120] hurricane_florence_2018 b=10 s=3 -> done | Elapsed: 60.95h | ETA: 74.50h\n",
      "  hurricane_florence_2018 budget=25 seed=1 -- done (best_dev_f1=0.7002)\n",
      "  [55/120] hurricane_florence_2018 b=25 s=1 -> done | Elapsed: 61.59h | ETA: 72.79h\n",
      "  hurricane_florence_2018 budget=25 seed=2 -- done (best_dev_f1=0.6845)\n",
      "  [56/120] hurricane_florence_2018 b=25 s=2 -> done | Elapsed: 63.36h | ETA: 72.41h\n",
      "  hurricane_florence_2018 budget=25 seed=3 -- done (best_dev_f1=0.7177)\n",
      "  [57/120] hurricane_florence_2018 b=25 s=3 -> done | Elapsed: 64.55h | ETA: 71.34h\n",
      "  hurricane_florence_2018 budget=50 seed=1 -- done (best_dev_f1=0.7139)\n",
      "  [58/120] hurricane_florence_2018 b=50 s=1 -> done | Elapsed: 65.14h | ETA: 69.64h\n",
      "  hurricane_florence_2018 budget=50 seed=3 -- done (best_dev_f1=0.7084)\n",
      "  [59/120] hurricane_florence_2018 b=50 s=3 -> done | Elapsed: 67.45h | ETA: 69.74h\n",
      "  hurricane_florence_2018 budget=50 seed=2 -- done (best_dev_f1=0.7129)\n",
      "  [60/120] hurricane_florence_2018 b=50 s=2 -> done | Elapsed: 67.60h | ETA: 67.60h\n",
      "  hurricane_harvey_2017 budget=5 seed=1 -- done (best_dev_f1=0.6318)\n",
      "  [61/120] hurricane_harvey_2017 b=5 s=1 -> done | Elapsed: 70.11h | ETA: 67.81h\n",
      "  hurricane_harvey_2017 budget=5 seed=2 -- done (best_dev_f1=0.6320)\n",
      "  [62/120] hurricane_harvey_2017 b=5 s=2 -> done | Elapsed: 71.33h | ETA: 66.73h\n",
      "  hurricane_harvey_2017 budget=5 seed=3 -- done (best_dev_f1=0.6457)\n",
      "  [63/120] hurricane_harvey_2017 b=5 s=3 -> done | Elapsed: 74.18h | ETA: 67.11h\n",
      "  hurricane_harvey_2017 budget=10 seed=1 -- done (best_dev_f1=0.6603)\n",
      "  [64/120] hurricane_harvey_2017 b=10 s=1 -> done | Elapsed: 75.35h | ETA: 65.93h\n",
      "  hurricane_harvey_2017 budget=10 seed=2 -- done (best_dev_f1=0.6568)\n",
      "  [65/120] hurricane_harvey_2017 b=10 s=2 -> done | Elapsed: 77.00h | ETA: 65.15h\n",
      "  hurricane_harvey_2017 budget=10 seed=3 -- done (best_dev_f1=0.6617)\n",
      "  [66/120] hurricane_harvey_2017 b=10 s=3 -> done | Elapsed: 79.39h | ETA: 64.96h\n",
      "  hurricane_harvey_2017 budget=25 seed=1 -- done (best_dev_f1=0.6825)\n",
      "  [67/120] hurricane_harvey_2017 b=25 s=1 -> done | Elapsed: 80.74h | ETA: 63.87h\n",
      "  hurricane_harvey_2017 budget=25 seed=2 -- done (best_dev_f1=0.6887)\n",
      "  [68/120] hurricane_harvey_2017 b=25 s=2 -> done | Elapsed: 82.77h | ETA: 63.29h\n",
      "  hurricane_harvey_2017 budget=25 seed=3 -- done (best_dev_f1=0.6737)\n",
      "  [69/120] hurricane_harvey_2017 b=25 s=3 -> done | Elapsed: 84.30h | ETA: 62.31h\n",
      "  hurricane_harvey_2017 budget=50 seed=1 -- done (best_dev_f1=0.6767)\n",
      "  [70/120] hurricane_harvey_2017 b=50 s=1 -> done | Elapsed: 86.96h | ETA: 62.11h\n",
      "  hurricane_harvey_2017 budget=50 seed=2 -- done (best_dev_f1=0.6865)\n",
      "  [71/120] hurricane_harvey_2017 b=50 s=2 -> done | Elapsed: 87.58h | ETA: 60.44h\n",
      "  hurricane_irma_2017 budget=5 seed=1 -- done (best_dev_f1=0.6301)\n",
      "  [72/120] hurricane_irma_2017 b=5 s=1 -> done | Elapsed: 91.64h | ETA: 61.10h\n",
      "  hurricane_harvey_2017 budget=50 seed=3 -- done (best_dev_f1=0.6758)\n",
      "  [73/120] hurricane_harvey_2017 b=50 s=3 -> done | Elapsed: 91.65h | ETA: 59.01h\n",
      "  hurricane_irma_2017 budget=5 seed=2 -- done (best_dev_f1=0.6249)\n",
      "  [74/120] hurricane_irma_2017 b=5 s=2 -> done | Elapsed: 95.24h | ETA: 59.20h\n",
      "  hurricane_irma_2017 budget=5 seed=3 -- done (best_dev_f1=0.6117)\n",
      "  [75/120] hurricane_irma_2017 b=5 s=3 -> done | Elapsed: 95.81h | ETA: 57.49h\n",
      "  hurricane_irma_2017 budget=10 seed=1 -- done (best_dev_f1=0.6267)\n",
      "  [76/120] hurricane_irma_2017 b=10 s=1 -> done | Elapsed: 99.41h | ETA: 57.55h\n",
      "  hurricane_irma_2017 budget=10 seed=2 -- done (best_dev_f1=0.6453)\n",
      "  [77/120] hurricane_irma_2017 b=10 s=2 -> done | Elapsed: 100.55h | ETA: 56.15h\n",
      "  hurricane_irma_2017 budget=25 seed=1 -- done (best_dev_f1=0.6549)\n",
      "  [78/120] hurricane_irma_2017 b=25 s=1 -> done | Elapsed: 104.25h | ETA: 56.14h\n",
      "  hurricane_irma_2017 budget=10 seed=3 -- done (best_dev_f1=0.6128)\n",
      "  [79/120] hurricane_irma_2017 b=10 s=3 -> done | Elapsed: 105.03h | ETA: 54.51h\n",
      "  hurricane_irma_2017 budget=25 seed=2 -- done (best_dev_f1=0.6460)\n",
      "  [80/120] hurricane_irma_2017 b=25 s=2 -> done | Elapsed: 108.43h | ETA: 54.22h\n",
      "  hurricane_irma_2017 budget=25 seed=3 -- done (best_dev_f1=0.6641)\n",
      "  [81/120] hurricane_irma_2017 b=25 s=3 -> done | Elapsed: 109.23h | ETA: 52.59h\n",
      "  hurricane_irma_2017 budget=50 seed=1 -- done (best_dev_f1=0.6443)\n",
      "  [82/120] hurricane_irma_2017 b=50 s=1 -> done | Elapsed: 112.46h | ETA: 52.12h\n",
      "  hurricane_irma_2017 budget=50 seed=2 -- done (best_dev_f1=0.6770)\n",
      "  [83/120] hurricane_irma_2017 b=50 s=2 -> done | Elapsed: 112.70h | ETA: 50.24h\n",
      "  hurricane_irma_2017 budget=50 seed=3 -- done (best_dev_f1=0.6695)\n",
      "  [84/120] hurricane_irma_2017 b=50 s=3 -> done | Elapsed: 115.80h | ETA: 49.63h\n",
      "  hurricane_maria_2017 budget=5 seed=1 -- done (best_dev_f1=0.6508)\n",
      "  [85/120] hurricane_maria_2017 b=5 s=1 -> done | Elapsed: 115.93h | ETA: 47.73h\n",
      "  hurricane_maria_2017 budget=5 seed=3 -- done (best_dev_f1=0.6733)\n",
      "  [86/120] hurricane_maria_2017 b=5 s=3 -> done | Elapsed: 118.17h | ETA: 46.72h\n",
      "  hurricane_maria_2017 budget=5 seed=2 -- done (best_dev_f1=0.6890)\n",
      "  [87/120] hurricane_maria_2017 b=5 s=2 -> done | Elapsed: 118.63h | ETA: 45.00h\n",
      "  hurricane_maria_2017 budget=10 seed=1 -- done (best_dev_f1=0.6715)\n",
      "  [88/120] hurricane_maria_2017 b=10 s=1 -> done | Elapsed: 121.12h | ETA: 44.04h\n",
      "  hurricane_maria_2017 budget=10 seed=2 -- done (best_dev_f1=0.6901)\n",
      "  [89/120] hurricane_maria_2017 b=10 s=2 -> done | Elapsed: 121.82h | ETA: 42.43h\n",
      "  hurricane_maria_2017 budget=10 seed=3 -- done (best_dev_f1=0.6751)\n",
      "  [90/120] hurricane_maria_2017 b=10 s=3 -> done | Elapsed: 124.04h | ETA: 41.35h\n",
      "  hurricane_maria_2017 budget=25 seed=1 -- done (best_dev_f1=0.6674)\n",
      "  [91/120] hurricane_maria_2017 b=25 s=1 -> done | Elapsed: 124.84h | ETA: 39.78h\n",
      "  hurricane_maria_2017 budget=25 seed=2 -- done (best_dev_f1=0.6986)\n",
      "  [92/120] hurricane_maria_2017 b=25 s=2 -> done | Elapsed: 126.34h | ETA: 38.45h\n",
      "  hurricane_maria_2017 budget=25 seed=3 -- done (best_dev_f1=0.6943)\n",
      "  [93/120] hurricane_maria_2017 b=25 s=3 -> done | Elapsed: 128.17h | ETA: 37.21h\n",
      "  hurricane_maria_2017 budget=50 seed=1 -- done (best_dev_f1=0.6883)\n",
      "  [94/120] hurricane_maria_2017 b=50 s=1 -> done | Elapsed: 129.51h | ETA: 35.82h\n",
      "  hurricane_maria_2017 budget=50 seed=2 -- done (best_dev_f1=0.6893)\n",
      "  [95/120] hurricane_maria_2017 b=50 s=2 -> done | Elapsed: 131.37h | ETA: 34.57h\n",
      "  kaikoura_earthquake_2016 budget=5 seed=1 -- done (best_dev_f1=0.6818)\n",
      "  [96/120] kaikoura_earthquake_2016 b=5 s=1 -> done | Elapsed: 131.37h | ETA: 32.84h\n",
      "  kaikoura_earthquake_2016 budget=5 seed=2 -- done (best_dev_f1=0.6591)\n",
      "  [97/120] kaikoura_earthquake_2016 b=5 s=2 -> done | Elapsed: 131.37h | ETA: 31.15h\n",
      "  hurricane_maria_2017 budget=50 seed=3 -- done (best_dev_f1=0.7029)\n",
      "  [98/120] hurricane_maria_2017 b=50 s=3 -> done | Elapsed: 132.20h | ETA: 29.68h\n",
      "  kaikoura_earthquake_2016 budget=5 seed=3 -- done (best_dev_f1=0.6858)\n",
      "  [99/120] kaikoura_earthquake_2016 b=5 s=3 -> done | Elapsed: 132.47h | ETA: 28.10h\n",
      "  kaikoura_earthquake_2016 budget=10 seed=1 -- done (best_dev_f1=0.6818)\n",
      "  [100/120] kaikoura_earthquake_2016 b=10 s=1 -> done | Elapsed: 132.99h | ETA: 26.60h\n",
      "  kaikoura_earthquake_2016 budget=10 seed=2 -- done (best_dev_f1=0.6589)\n",
      "  [101/120] kaikoura_earthquake_2016 b=10 s=2 -> done | Elapsed: 133.44h | ETA: 25.10h\n",
      "  kaikoura_earthquake_2016 budget=10 seed=3 -- done (best_dev_f1=0.6757)\n",
      "  [102/120] kaikoura_earthquake_2016 b=10 s=3 -> done | Elapsed: 133.73h | ETA: 23.60h\n",
      "  kaikoura_earthquake_2016 budget=25 seed=1 -- done (best_dev_f1=0.7189)\n",
      "  [103/120] kaikoura_earthquake_2016 b=25 s=1 -> done | Elapsed: 134.32h | ETA: 22.17h\n",
      "  kaikoura_earthquake_2016 budget=25 seed=2 -- done (best_dev_f1=0.6822)\n",
      "  [104/120] kaikoura_earthquake_2016 b=25 s=2 -> done | Elapsed: 134.66h | ETA: 20.72h\n",
      "  kaikoura_earthquake_2016 budget=25 seed=3 -- done (best_dev_f1=0.6815)\n",
      "  [105/120] kaikoura_earthquake_2016 b=25 s=3 -> done | Elapsed: 135.32h | ETA: 19.33h\n",
      "  kaikoura_earthquake_2016 budget=50 seed=1 -- done (best_dev_f1=0.6907)\n",
      "  [106/120] kaikoura_earthquake_2016 b=50 s=1 -> done | Elapsed: 135.51h | ETA: 17.90h\n",
      "  kaikoura_earthquake_2016 budget=50 seed=2 -- done (best_dev_f1=0.6892)\n",
      "  [107/120] kaikoura_earthquake_2016 b=50 s=2 -> done | Elapsed: 136.25h | ETA: 16.55h\n",
      "  kaikoura_earthquake_2016 budget=50 seed=3 -- done (best_dev_f1=0.7053)\n",
      "  [108/120] kaikoura_earthquake_2016 b=50 s=3 -> done | Elapsed: 136.34h | ETA: 15.15h\n",
      "  kerala_floods_2018 budget=5 seed=2 -- done (best_dev_f1=0.6254)\n",
      "  [109/120] kerala_floods_2018 b=5 s=2 -> done | Elapsed: 140.04h | ETA: 14.13h\n",
      "  kerala_floods_2018 budget=5 seed=1 -- done (best_dev_f1=0.6070)\n",
      "  [110/120] kerala_floods_2018 b=5 s=1 -> done | Elapsed: 140.25h | ETA: 12.75h\n",
      "  kerala_floods_2018 budget=5 seed=3 -- done (best_dev_f1=0.6155)\n",
      "  [111/120] kerala_floods_2018 b=5 s=3 -> done | Elapsed: 143.16h | ETA: 11.61h\n",
      "  kerala_floods_2018 budget=10 seed=1 -- done (best_dev_f1=0.5954)\n",
      "  [112/120] kerala_floods_2018 b=10 s=1 -> done | Elapsed: 143.73h | ETA: 10.27h\n",
      "  kerala_floods_2018 budget=10 seed=2 -- done (best_dev_f1=0.6278)\n",
      "  [113/120] kerala_floods_2018 b=10 s=2 -> done | Elapsed: 146.00h | ETA: 9.04h\n",
      "  kerala_floods_2018 budget=10 seed=3 -- done (best_dev_f1=0.6159)\n",
      "  [114/120] kerala_floods_2018 b=10 s=3 -> done | Elapsed: 147.56h | ETA: 7.77h\n",
      "  kerala_floods_2018 budget=25 seed=1 -- done (best_dev_f1=0.5963)\n",
      "  [115/120] kerala_floods_2018 b=25 s=1 -> done | Elapsed: 149.56h | ETA: 6.50h\n",
      "  kerala_floods_2018 budget=25 seed=2 -- done (best_dev_f1=0.6006)\n",
      "  [116/120] kerala_floods_2018 b=25 s=2 -> done | Elapsed: 151.55h | ETA: 5.23h\n",
      "  kerala_floods_2018 budget=25 seed=3 -- done (best_dev_f1=0.6155)\n",
      "  [117/120] kerala_floods_2018 b=25 s=3 -> done | Elapsed: 153.41h | ETA: 3.93h\n",
      "  kerala_floods_2018 budget=50 seed=1 -- done (best_dev_f1=0.5920)\n",
      "  [118/120] kerala_floods_2018 b=50 s=1 -> done | Elapsed: 155.38h | ETA: 2.63h\n",
      "  kerala_floods_2018 budget=50 seed=2 -- done (best_dev_f1=0.6176)\n",
      "  [119/120] kerala_floods_2018 b=50 s=2 -> done | Elapsed: 156.44h | ETA: 1.31h\n",
      "  kerala_floods_2018 budget=50 seed=3 -- done (best_dev_f1=0.6402)\n",
      "  [120/120] kerala_floods_2018 b=50 s=3 -> done | Elapsed: 159.19h | ETA: 0.00h\n",
      "\n",
      "All studies complete: 118 ran, 2 skipped, 0 failed (573097.3s total)\n",
      "Summary saved to: D:\\Workspace\\Co-Training\\results\\optuna\\per_experiment\\summary_10.json\n",
      "\n",
      "Total time: 159.19h (9551.6min)\n"
     ]
    }
   ],
   "source": [
    "class StudyProgressTracker:\n",
    "    \"\"\"Track progress across all Optuna studies.\"\"\"\n",
    "\n",
    "    def __init__(self, total_studies: int, start_time: float):\n",
    "        self.total = total_studies\n",
    "        self.done = 0\n",
    "        self.start_time = start_time\n",
    "\n",
    "    def on_study_done(self, event, budget, seed_set, status):\n",
    "        self.done += 1\n",
    "        elapsed = time.time() - self.start_time\n",
    "        elapsed_h = elapsed / 3600\n",
    "        if self.done > 0:\n",
    "            avg_per_study = elapsed / self.done\n",
    "            remaining = (self.total - self.done) * avg_per_study\n",
    "            eta_h = remaining / 3600\n",
    "        else:\n",
    "            eta_h = 0\n",
    "        print(\n",
    "            f\"  [{self.done}/{self.total}] {event} b={budget} s={seed_set}\"\n",
    "            f\" -> {status} | Elapsed: {elapsed_h:.2f}h | ETA: {eta_h:.2f}h\"\n",
    "        )\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "tracker = StudyProgressTracker(total_studies, start_time)\n",
    "\n",
    "all_results = run_all_studies(\n",
    "    events=events_to_use,\n",
    "    budgets=budgets_to_use,\n",
    "    seed_sets=seeds_to_use,\n",
    "    n_trials=N_TRIALS,\n",
    "    num_gpus=NUM_GPUS,\n",
    "    storage_dir=STORAGE_DIR,\n",
    "    data_root=DATA_ROOT,\n",
    "    pseudo_label_source=PSEUDO_LABEL_SOURCE,\n",
    "    on_study_done=tracker.on_study_done,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal time: {elapsed / 3600:.2f}h ({elapsed / 60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results Overview\n",
    "\n",
    "Load the summary and display a table of all 120 best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load summary for the current N_TRIALS\n",
    "summary_path = Path(STORAGE_DIR) / f\"summary_{N_TRIALS}.json\"\n",
    "with open(summary_path) as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "print(f\"Total studies : {summary['total_studies']}\")\n",
    "print(f\"Completed     : {summary['completed']}\")\n",
    "print(f\"Failed        : {summary['failed']}\")\n",
    "print(f\"Trials/study  : {summary['n_trials_per_study']}\")\n",
    "print()\n",
    "\n",
    "# Show best results table\n",
    "done_studies = [s for s in summary['studies'] if s['status'] == 'done']\n",
    "\n",
    "print(f\"{'Event':>30}  {'Budget':>6}  {'Seed':>4}  {'Best Dev F1':>11}  \"\n",
    "      f\"{'LR':>10}  {'Batch':>5}  {'CoEp':>4}  {'Pat':>3}  {'WD':>6}  {'WR':>5}\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "for s in done_studies:\n",
    "    bp = s['best_params']\n",
    "    if bp is None:\n",
    "        continue\n",
    "    print(\n",
    "        f\"{s['event']:>30}  {s['budget']:>6}  {s['seed_set']:>4}  \"\n",
    "        f\"{s['best_value']:>11.4f}  \"\n",
    "        f\"{bp.get('lr', 0):>10.2e}  \"\n",
    "        f\"{bp.get('batch_size', 0):>5}  \"\n",
    "        f\"{bp.get('cotrain_epochs', 0):>4}  \"\n",
    "        f\"{bp.get('finetune_patience', 0):>3}  \"\n",
    "        f\"{bp.get('weight_decay', 0):>6.4f}  \"\n",
    "        f\"{bp.get('warmup_ratio', 0):>5.3f}\"\n",
    "    )\n",
    "\n",
    "# Aggregate stats\n",
    "if done_studies:\n",
    "    values = [s['best_value'] for s in done_studies if s['best_value'] is not None]\n",
    "    import statistics\n",
    "    print(f\"\\nBest dev F1 across all studies:\")\n",
    "    print(f\"  Mean: {statistics.mean(values):.4f}\")\n",
    "    print(f\"  Std:  {statistics.stdev(values):.4f}\" if len(values) > 1 else \"\")\n",
    "    print(f\"  Min:  {min(values):.4f}\")\n",
    "    print(f\"  Max:  {max(values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations\n",
    "\n",
    "Box plots of best dev F1 by event and budget, and parameter distribution\n",
    "analysis across all 120 studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "done_studies = [s for s in summary['studies'] if s['status'] == 'done' and s['best_value'] is not None]\n",
    "\n",
    "# --- Box plot: Best dev F1 by event ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Group by event\n",
    "event_groups = {}\n",
    "for s in done_studies:\n",
    "    event_groups.setdefault(s['event'], []).append(s['best_value'])\n",
    "\n",
    "events_sorted = sorted(event_groups.keys())\n",
    "data_by_event = [event_groups[e] for e in events_sorted]\n",
    "labels_event = [e.replace('_', '\\n') for e in events_sorted]\n",
    "\n",
    "axes[0].boxplot(data_by_event, labels=labels_event)\n",
    "axes[0].set_ylabel('Best dev macro-F1')\n",
    "axes[0].set_title('Best Dev F1 by Event')\n",
    "axes[0].tick_params(axis='x', rotation=45, labelsize=8)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Group by budget\n",
    "budget_groups = {}\n",
    "for s in done_studies:\n",
    "    budget_groups.setdefault(s['budget'], []).append(s['best_value'])\n",
    "\n",
    "budgets_sorted = sorted(budget_groups.keys())\n",
    "data_by_budget = [budget_groups[b] for b in budgets_sorted]\n",
    "\n",
    "axes[1].boxplot(data_by_budget, labels=[str(b) for b in budgets_sorted])\n",
    "axes[1].set_xlabel('Budget')\n",
    "axes[1].set_ylabel('Best dev macro-F1')\n",
    "axes[1].set_title('Best Dev F1 by Budget')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Per-Experiment Optuna: Best Dev F1 Distribution', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Parameter distributions ---\n",
    "params = ['lr', 'batch_size', 'cotrain_epochs', 'finetune_patience', 'weight_decay', 'warmup_ratio']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for ax, param in zip(axes.flat, params):\n",
    "    values = [s['best_params'][param] for s in done_studies if param in s['best_params']]\n",
    "    if not values:\n",
    "        continue\n",
    "\n",
    "    if param == 'lr':\n",
    "        log_values = [np.log10(v) for v in values]\n",
    "        ax.hist(log_values, bins=15, alpha=0.7, color='tab:blue', edgecolor='white')\n",
    "        ax.set_xlabel(f'{param} (log10)')\n",
    "    elif param == 'batch_size':\n",
    "        from collections import Counter\n",
    "        counts = Counter(values)\n",
    "        categories = [8, 16, 32, 64]\n",
    "        bar_counts = [counts.get(c, 0) for c in categories]\n",
    "        ax.bar([str(c) for c in categories], bar_counts, alpha=0.7,\n",
    "               color='tab:blue', edgecolor='white')\n",
    "        ax.set_xlabel(param)\n",
    "    else:\n",
    "        ax.hist(values, bins=15, alpha=0.7, color='tab:blue', edgecolor='white')\n",
    "        ax.set_xlabel(param)\n",
    "\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Best {param} across studies')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Optimal Hyperparameter Distributions (120 Studies)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "Use the optimized hyperparameters to run the final 120 experiments.\n",
    "The `load_best_params()` function loads all `best_params.json` files\n",
    "into a dict keyed by `(event, budget, seed_set)`.\n",
    "\n",
    "### CLI equivalent\n",
    "\n",
    "```bash\n",
    "# Run all 120 Optuna studies with 10 trials each\n",
    "python -m lg_cotrain.optuna_per_experiment --n-trials 10 --num-gpus 2\n",
    "\n",
    "# Later, scale to 20 trials (continues from 10, only 10 new trials per study)\n",
    "python -m lg_cotrain.optuna_per_experiment --n-trials 20 --num-gpus 2\n",
    "\n",
    "# Run a subset\n",
    "python -m lg_cotrain.optuna_per_experiment --n-trials 15 --num-gpus 2 \\\n",
    "    --events hurricane_harvey_2017 kerala_floods_2018 --budgets 50 --seed-sets 1\n",
    "```\n",
    "\n",
    "### Using optimized hyperparameters for final experiments\n",
    "\n",
    "```python\n",
    "from lg_cotrain.optuna_per_experiment import load_best_params\n",
    "\n",
    "# Load latest results (highest trial count)\n",
    "best = load_best_params(\"results/optuna/per_experiment\")\n",
    "params = best[(\"hurricane_harvey_2017\", 50, 1)][\"best_params\"]\n",
    "# params = {\"lr\": 0.0003, \"batch_size\": 16, ...}\n",
    "\n",
    "# Or load from a specific trial count\n",
    "best_10 = load_best_params(\"results/optuna/per_experiment\", n_trials=10)\n",
    "```\n",
    "\n",
    "### Storage structure\n",
    "\n",
    "```\n",
    "results/optuna/per_experiment/\n",
    "  {event}/\n",
    "    {budget}_set{seed_set}/\n",
    "      trials_10/best_params.json   # 10-trial results\n",
    "      trials_20/best_params.json   # 20-trial results (all 20 trials)\n",
    "  summary_10.json\n",
    "  summary_20.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
