{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# LG-CoTrain: Alternative Early Stopping — Full Experiment Run\n\nThis notebook runs the **complete experiment sweep** (all budgets × all seed sets × all events)\nunder each of the 6 stopping strategies, then produces the same comparison charts as\nnotebook 04 but with statistically reliable mean ± std estimates.\n\n| Strategy | Key Idea |\n|---|---|\n| `baseline` | Original: stop when ensemble macro-F1 plateaus for `patience` epochs |\n| `no_early_stopping` | Run all `finetune_max_epochs`; restore best-ever checkpoint (upper bound) |\n| `per_class_patience` | Stop only when **every** class F1 has individually plateaued |\n| `weighted_macro_f1` | Weight rare classes more in the stopping metric |\n| `balanced_dev` | Resample dev set to equal class sizes for the stopping signal |\n| `scaled_threshold` | Require a larger improvement delta for highly imbalanced events |\n\n**Total experiments**: 6 strategies × 10 events × 4 budgets × 3 seeds = **720 runs**\n\nResults are stored in `results/{PSEUDO_LABEL_SOURCE}/stop/{strategy}/` (e.g. `results/gpt-4o/stop/baseline/`).\nSee **notebook 04** for a fast preview using budget=50, seed=1 only.\n\n## Resume Support\n\nEvery `(event, budget, seed_set)` combination is written to its own `metrics.json`\nas soon as it completes. Re-running any cell automatically skips completed experiments."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: D:\\Workspace\\Co-Training\n",
      "Budgets  : [5, 10, 25, 50]\n",
      "Seed sets: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_repo_root(marker: str = \"lg_cotrain\") -> Path:\n",
    "    for candidate in [Path().resolve()] + list(Path().resolve().parents):\n",
    "        if (candidate / marker).is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot find repo root: no ancestor directory contains '{marker}/'. \"\n",
    "        \"Run the notebook from inside the repository.\"\n",
    "    )\n",
    "\n",
    "\n",
    "repo_root = _find_repo_root()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lg_cotrain.run_all import BUDGETS, SEED_SETS, format_summary_table, run_all_experiments\n",
    "\n",
    "\n",
    "class ProgressTracker:\n",
    "    \"\"\"Track global progress across all strategies × events × budgets × seeds.\"\"\"\n",
    "\n",
    "    def __init__(self, total: int, already_done: int, start_time: float):\n",
    "        self.total = total\n",
    "        self.done = already_done\n",
    "        self.start_time = start_time\n",
    "\n",
    "    def update(self, event, budget, seed_set, status):\n",
    "        self.done += 1\n",
    "        elapsed = time.time() - self.start_time\n",
    "        pct = 100.0 * self.done / self.total if self.total else 0\n",
    "        elapsed_h = elapsed / 3600\n",
    "        remaining = self.total - self.done\n",
    "        eta_h = (elapsed / self.done) * remaining / 3600 if self.done > 0 else 0\n",
    "        print(\n",
    "            f\"  [PROGRESS] {self.done}/{self.total} ({pct:.1f}%)\"\n",
    "            f\"  |  Elapsed: {elapsed_h:.2f}h  |  ETA: {eta_h:.2f}h  |  {status}\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Budgets  : {BUDGETS}\")\n",
    "print(f\"Seed sets: {SEED_SETS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# ---- Configuration ----\n\nPSEUDO_LABEL_SOURCE = \"gpt-4o\"\n\nSTRATEGIES = [\n    \"baseline\",\n    \"no_early_stopping\",\n    \"per_class_patience\",\n    \"weighted_macro_f1\",\n    \"balanced_dev\",\n    \"scaled_threshold\",\n]\n\nDATA_ROOT = str(repo_root / \"data\")\n\n# Discover all events\nTARGET_EVENTS = sorted(\n    p.name for p in (Path(DATA_ROOT) / \"original\").iterdir() if p.is_dir()\n)\n\n# Each strategy gets its own results sub-folder under model/stop/\nSTRATEGY_RESULTS_ROOTS = {\n    s: str(repo_root / \"results\" / PSEUDO_LABEL_SOURCE / \"stop\" / s)\n    for s in STRATEGIES\n}\n\nexpts_per_strategy = len(TARGET_EVENTS) * len(BUDGETS) * len(SEED_SETS)\ntotal_runs = len(STRATEGIES) * expts_per_strategy\n\nprint(f\"Strategies : {STRATEGIES}\")\nprint(f\"Events     : {len(TARGET_EVENTS)} events\")\nprint(f\"Per strategy: {expts_per_strategy} experiments  ({len(TARGET_EVENTS)} events × {len(BUDGETS)} budgets × {len(SEED_SETS)} seeds)\")\nprint(f\"Grand total : {total_runs} experiments\")\nprint()\nfor s, r in STRATEGY_RESULTS_ROOTS.items():\n    print(f\"  {s:<25} → {r}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Running Experiments\n",
    "\n",
    "The loop below processes one strategy at a time, running all events × budgets × seeds\n",
    "for each. Completed experiments are skipped automatically.\n",
    "\n",
    "> **Runtime estimate**: ~3-5 hours per strategy on GPU, ~18-30 hours total.\n",
    "> Run overnight or split across sessions — resume support ensures no work is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments : 720\n",
      "Already completed : 0\n",
      "Remaining         : 720\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Strategy: baseline  →  D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\n",
      "======================================================================\n",
      "\n",
      "  Event: california_wildfires_2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Co-Training\\co-training-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:31:59,510 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=1\n",
      "2026-02-20 09:31:59,557 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 09:31:59,570 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-20 09:31:59,571 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1117.91it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1144.22it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 09:32:18,527 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0981, mean_prob2=0.1025\n",
      "2026-02-20 09:32:35,814 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0997, mean_prob2=0.0991\n",
      "2026-02-20 09:32:53,157 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1010, mean_prob2=0.0970\n",
      "2026-02-20 09:33:10,895 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1015, mean_prob2=0.0978\n",
      "2026-02-20 09:33:28,806 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1025, mean_prob2=0.0998\n",
      "2026-02-20 09:33:46,922 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1033, mean_prob2=0.1032\n",
      "2026-02-20 09:34:05,045 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1043, mean_prob2=0.1063\n",
      "2026-02-20 09:34:05,047 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1067, range=[0.0520, 0.2235]\n",
      "2026-02-20 09:34:05,048 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0917, range=[0.0202, 0.2378]\n",
      "2026-02-20 09:34:05,048 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1096.92it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1187.38it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 09:35:17,164 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1141, loss2=0.1382, dev_macro_f1=0.4347, dev_err=30.45%\n",
      "2026-02-20 09:36:29,181 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0480, loss2=0.1491, dev_macro_f1=0.5579, dev_err=26.46%\n",
      "2026-02-20 09:37:45,666 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0281, loss2=0.1451, dev_macro_f1=0.5797, dev_err=26.60%\n",
      "2026-02-20 09:39:00,652 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0199, loss2=0.0971, dev_macro_f1=0.5874, dev_err=26.86%\n",
      "2026-02-20 09:40:15,402 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0123, loss2=0.0646, dev_macro_f1=0.6023, dev_err=25.80%\n",
      "2026-02-20 09:41:29,811 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0178, loss2=0.0458, dev_macro_f1=0.6106, dev_err=26.46%\n",
      "2026-02-20 09:42:40,169 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0127, loss2=0.0525, dev_macro_f1=0.6244, dev_err=25.13%\n",
      "2026-02-20 09:43:52,374 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0190, loss2=0.0303, dev_macro_f1=0.5889, dev_err=26.60%\n",
      "2026-02-20 09:45:05,900 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0155, loss2=0.0307, dev_macro_f1=0.5996, dev_err=25.93%\n",
      "2026-02-20 09:46:22,252 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0113, loss2=0.0308, dev_macro_f1=0.5883, dev_err=27.39%\n",
      "2026-02-20 09:46:22,253 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 09:46:25,270 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5910, dev_err=27.13%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:28,304 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5956, dev_err=26.99%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:31,314 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6051, dev_err=27.66%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:34,337 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6073, dev_err=27.79%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:37,366 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6114, dev_err=28.59%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:40,357 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6022, dev_err=30.32%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 09:46:43,352 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6238, dev_err=31.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 09:46:46,334 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6009, dev_err=33.11%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 09:46:49,317 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.5965, dev_err=33.91%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 09:46:52,305 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.5844, dev_err=34.97%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 09:46:55,280 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.5803, dev_err=35.37%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 09:46:58,278 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.5778, dev_err=35.64%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 09:46:58,279 - lg_cotrain - INFO - Early stopping at epoch 12\n",
      "2026-02-20 09:46:58,290 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 09:47:06,320 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\5_set1\\metrics.json\n",
      "2026-02-20 09:47:06,320 - lg_cotrain - INFO - Test error rate: 29.30%, Test macro-F1: 0.6291, Test ECE: 0.1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- done (macro_f1=0.6291)\n",
      "  [PROGRESS] 1/720 (0.1%)  |  Elapsed: 0.26h  |  ETA: 184.97h  |  done\n",
      "[2/12] budget=5, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:47:06,918 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=2\n",
      "2026-02-20 09:47:06,969 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 09:47:06,980 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-20 09:47:06,982 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1019.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1042.36it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 09:47:27,775 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0968, mean_prob2=0.0993\n",
      "2026-02-20 09:47:46,799 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0989, mean_prob2=0.0997\n",
      "2026-02-20 09:48:05,744 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1010, mean_prob2=0.0998\n",
      "2026-02-20 09:48:24,600 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1036, mean_prob2=0.1001\n",
      "2026-02-20 09:48:43,023 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1059, mean_prob2=0.1005\n",
      "2026-02-20 09:49:00,854 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1084, mean_prob2=0.1009\n",
      "2026-02-20 09:49:18,824 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1092, mean_prob2=0.1014\n",
      "2026-02-20 09:49:18,825 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1149, range=[0.0550, 0.1973]\n",
      "2026-02-20 09:49:18,825 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0926, range=[0.0286, 0.1929]\n",
      "2026-02-20 09:49:18,826 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1015.28it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1122.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 09:50:30,980 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1167, loss2=0.1434, dev_macro_f1=0.4585, dev_err=29.65%\n",
      "2026-02-20 09:51:45,473 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0456, loss2=0.1703, dev_macro_f1=0.5608, dev_err=25.53%\n",
      "2026-02-20 09:52:57,701 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0227, loss2=0.1458, dev_macro_f1=0.5944, dev_err=25.66%\n",
      "2026-02-20 09:54:08,121 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0191, loss2=0.0988, dev_macro_f1=0.6001, dev_err=26.06%\n",
      "2026-02-20 09:55:18,931 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0201, loss2=0.0709, dev_macro_f1=0.6095, dev_err=25.80%\n",
      "2026-02-20 09:56:29,065 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0160, loss2=0.0509, dev_macro_f1=0.6209, dev_err=25.13%\n",
      "2026-02-20 09:57:39,994 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0110, loss2=0.0292, dev_macro_f1=0.6262, dev_err=25.40%\n",
      "2026-02-20 09:58:51,177 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0159, loss2=0.0258, dev_macro_f1=0.6077, dev_err=25.53%\n",
      "2026-02-20 10:00:01,977 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0141, loss2=0.0349, dev_macro_f1=0.6073, dev_err=26.20%\n",
      "2026-02-20 10:01:12,102 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0099, loss2=0.0371, dev_macro_f1=0.6000, dev_err=26.33%\n",
      "2026-02-20 10:01:12,102 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 10:01:14,862 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.6126, dev_err=25.53%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:01:17,611 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6085, dev_err=26.33%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:01:20,339 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5860, dev_err=28.86%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:01:23,074 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5684, dev_err=31.25%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:01:25,804 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5674, dev_err=31.91%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 10:01:28,535 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5562, dev_err=33.64%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 10:01:28,536 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-20 10:01:28,547 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 10:01:35,834 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\5_set2\\metrics.json\n",
      "2026-02-20 10:01:35,835 - lg_cotrain - INFO - Test error rate: 27.38%, Test macro-F1: 0.5977, Test ECE: 0.1956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/12] budget=5, seed=2 -- done (macro_f1=0.5977)\n",
      "  [PROGRESS] 2/720 (0.3%)  |  Elapsed: 0.50h  |  ETA: 179.07h  |  done\n",
      "[3/12] budget=5, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 10:01:36,466 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=3\n",
      "2026-02-20 10:01:36,513 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 10:01:36,513 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-20 10:01:36,523 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1119.15it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1155.75it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:01:55,369 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1056, mean_prob2=0.0887\n",
      "2026-02-20 10:02:13,097 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1061, mean_prob2=0.0972\n",
      "2026-02-20 10:02:30,861 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1061, mean_prob2=0.1057\n",
      "2026-02-20 10:02:48,612 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1060, mean_prob2=0.1095\n",
      "2026-02-20 10:03:06,341 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1073, mean_prob2=0.1112\n",
      "2026-02-20 10:03:24,043 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1084, mean_prob2=0.1136\n",
      "2026-02-20 10:03:41,982 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1090, mean_prob2=0.1166\n",
      "2026-02-20 10:03:41,983 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1131, range=[0.0573, 0.2166]\n",
      "2026-02-20 10:03:41,984 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0895, range=[0.0153, 0.2465]\n",
      "2026-02-20 10:03:41,984 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1142.55it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1146.34it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:04:53,428 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1202, loss2=0.1403, dev_macro_f1=0.4526, dev_err=30.05%\n",
      "2026-02-20 10:06:03,708 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0498, loss2=0.1432, dev_macro_f1=0.5528, dev_err=27.79%\n",
      "2026-02-20 10:07:13,895 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0305, loss2=0.1340, dev_macro_f1=0.5920, dev_err=25.93%\n",
      "2026-02-20 10:08:24,068 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0229, loss2=0.0894, dev_macro_f1=0.5988, dev_err=25.40%\n",
      "2026-02-20 10:09:34,263 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0173, loss2=0.0665, dev_macro_f1=0.5928, dev_err=25.93%\n",
      "2026-02-20 10:10:44,417 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0147, loss2=0.0462, dev_macro_f1=0.6043, dev_err=25.40%\n",
      "2026-02-20 10:11:54,573 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0169, loss2=0.0309, dev_macro_f1=0.5959, dev_err=27.26%\n",
      "2026-02-20 10:13:04,712 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0167, loss2=0.0319, dev_macro_f1=0.5963, dev_err=26.73%\n",
      "2026-02-20 10:14:14,879 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0121, loss2=0.0314, dev_macro_f1=0.6073, dev_err=26.33%\n",
      "2026-02-20 10:15:24,855 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0083, loss2=0.0234, dev_macro_f1=0.5979, dev_err=26.73%\n",
      "2026-02-20 10:15:24,855 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 10:15:27,590 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5832, dev_err=27.66%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:15:30,316 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6024, dev_err=26.73%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:15:33,060 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5944, dev_err=27.79%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:15:35,790 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6070, dev_err=30.32%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:15:38,496 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5744, dev_err=33.64%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:15:41,221 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5639, dev_err=35.51%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:15:43,937 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5531, dev_err=37.10%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:15:46,652 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5529, dev_err=36.97%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 10:15:49,385 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.5519, dev_err=37.23%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 10:15:49,386 - lg_cotrain - INFO - Early stopping at epoch 9\n",
      "2026-02-20 10:15:49,400 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 10:15:56,666 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\5_set3\\metrics.json\n",
      "2026-02-20 10:15:56,667 - lg_cotrain - INFO - Test error rate: 31.01%, Test macro-F1: 0.5642, Test ECE: 0.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/12] budget=5, seed=3 -- done (macro_f1=0.5642)\n",
      "  [PROGRESS] 3/720 (0.4%)  |  Elapsed: 0.74h  |  ETA: 176.36h  |  done\n",
      "[4/12] budget=10, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 10:15:57,277 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=1\n",
      "2026-02-20 10:15:57,312 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 10:15:57,321 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-20 10:15:57,323 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1196.34it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1180.10it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:16:16,219 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1004, mean_prob2=0.0998\n",
      "2026-02-20 10:16:33,931 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1043, mean_prob2=0.0989\n",
      "2026-02-20 10:16:51,650 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1085, mean_prob2=0.1022\n",
      "2026-02-20 10:17:09,366 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1133, mean_prob2=0.1070\n",
      "2026-02-20 10:17:27,106 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1159, mean_prob2=0.1114\n",
      "2026-02-20 10:17:44,970 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1155, mean_prob2=0.1136\n",
      "2026-02-20 10:18:02,739 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1155, mean_prob2=0.1146\n",
      "2026-02-20 10:18:02,741 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1232, range=[0.0536, 0.2147]\n",
      "2026-02-20 10:18:02,741 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0936, range=[0.0210, 0.2716]\n",
      "2026-02-20 10:18:02,741 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1034.21it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1121.82it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:19:13,077 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1165, loss2=0.1503, dev_macro_f1=0.4432, dev_err=30.32%\n",
      "2026-02-20 10:20:22,283 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0474, loss2=0.1430, dev_macro_f1=0.5427, dev_err=26.46%\n",
      "2026-02-20 10:21:31,481 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0278, loss2=0.1493, dev_macro_f1=0.5587, dev_err=28.46%\n",
      "2026-02-20 10:22:40,708 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0198, loss2=0.1004, dev_macro_f1=0.5758, dev_err=27.13%\n",
      "2026-02-20 10:23:49,948 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0173, loss2=0.0680, dev_macro_f1=0.5833, dev_err=27.66%\n",
      "2026-02-20 10:24:59,178 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0198, loss2=0.0487, dev_macro_f1=0.5798, dev_err=26.99%\n",
      "2026-02-20 10:26:08,435 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0125, loss2=0.0419, dev_macro_f1=0.5927, dev_err=26.46%\n",
      "2026-02-20 10:27:17,672 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0115, loss2=0.0361, dev_macro_f1=0.6113, dev_err=26.20%\n",
      "2026-02-20 10:28:26,883 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0114, loss2=0.0276, dev_macro_f1=0.6102, dev_err=26.06%\n",
      "2026-02-20 10:29:36,076 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0212, loss2=0.0372, dev_macro_f1=0.6181, dev_err=25.80%\n",
      "2026-02-20 10:29:36,076 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 10:29:39,063 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.6013, dev_err=26.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:29:42,031 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5786, dev_err=29.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:29:45,000 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5633, dev_err=31.91%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:29:47,972 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5844, dev_err=34.04%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:29:50,944 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5850, dev_err=35.64%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 10:29:53,913 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5822, dev_err=36.17%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 10:29:53,913 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-20 10:29:53,917 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 10:30:01,182 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\10_set1\\metrics.json\n",
      "2026-02-20 10:30:01,182 - lg_cotrain - INFO - Test error rate: 27.24%, Test macro-F1: 0.6017, Test ECE: 0.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/12] budget=10, seed=1 -- done (macro_f1=0.6017)\n",
      "  [PROGRESS] 4/720 (0.6%)  |  Elapsed: 0.97h  |  ETA: 174.08h  |  done\n",
      "[5/12] budget=10, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 10:30:02,106 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=2\n",
      "2026-02-20 10:30:02,158 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 10:30:02,169 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-20 10:30:02,172 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1188.14it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1148.49it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:30:21,136 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0967, mean_prob2=0.1014\n",
      "2026-02-20 10:30:38,840 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0988, mean_prob2=0.1024\n",
      "2026-02-20 10:30:56,561 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1009, mean_prob2=0.1053\n",
      "2026-02-20 10:31:14,282 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1042, mean_prob2=0.1079\n",
      "2026-02-20 10:31:32,009 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1074, mean_prob2=0.1099\n",
      "2026-02-20 10:31:49,822 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1083, mean_prob2=0.1111\n",
      "2026-02-20 10:32:07,557 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1104, mean_prob2=0.1128\n",
      "2026-02-20 10:32:07,558 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1148, range=[0.0553, 0.1993]\n",
      "2026-02-20 10:32:07,559 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0971, range=[0.0270, 0.1861]\n",
      "2026-02-20 10:32:07,560 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1203.21it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1139.90it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:33:17,860 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1189, loss2=0.1514, dev_macro_f1=0.4657, dev_err=28.46%\n",
      "2026-02-20 10:34:26,987 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0488, loss2=0.1685, dev_macro_f1=0.5654, dev_err=26.06%\n",
      "2026-02-20 10:35:36,140 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0260, loss2=0.1484, dev_macro_f1=0.5633, dev_err=27.79%\n",
      "2026-02-20 10:36:45,294 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0190, loss2=0.1039, dev_macro_f1=0.6021, dev_err=26.46%\n",
      "2026-02-20 10:37:54,471 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0116, loss2=0.0753, dev_macro_f1=0.5864, dev_err=26.73%\n",
      "2026-02-20 10:39:03,656 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0158, loss2=0.0476, dev_macro_f1=0.5818, dev_err=27.26%\n",
      "2026-02-20 10:40:12,864 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0174, loss2=0.0330, dev_macro_f1=0.6066, dev_err=26.20%\n",
      "2026-02-20 10:41:22,019 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0138, loss2=0.0422, dev_macro_f1=0.6008, dev_err=27.26%\n",
      "2026-02-20 10:42:31,175 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0105, loss2=0.0271, dev_macro_f1=0.5885, dev_err=27.39%\n",
      "2026-02-20 10:43:40,296 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0171, loss2=0.0264, dev_macro_f1=0.5904, dev_err=27.93%\n",
      "2026-02-20 10:43:40,297 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 10:43:43,279 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5891, dev_err=28.06%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:43:46,258 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5965, dev_err=28.59%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:43:49,241 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6085, dev_err=28.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:43:52,202 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5983, dev_err=29.92%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:43:55,168 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5809, dev_err=30.72%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:43:58,134 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5803, dev_err=30.85%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:44:01,101 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6081, dev_err=30.32%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 10:44:04,070 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6070, dev_err=30.19%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 10:44:04,070 - lg_cotrain - INFO - Early stopping at epoch 8\n",
      "2026-02-20 10:44:04,080 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 10:44:11,332 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\10_set2\\metrics.json\n",
      "2026-02-20 10:44:11,332 - lg_cotrain - INFO - Test error rate: 28.82%, Test macro-F1: 0.5955, Test ECE: 0.1223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/12] budget=10, seed=2 -- done (macro_f1=0.5955)\n",
      "  [PROGRESS] 5/720 (0.7%)  |  Elapsed: 1.21h  |  ETA: 172.84h  |  done\n",
      "[6/12] budget=10, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 10:44:11,945 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=3\n",
      "2026-02-20 10:44:11,987 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 10:44:12,001 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-20 10:44:12,004 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1169.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1070.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:44:30,934 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1066, mean_prob2=0.1009\n",
      "2026-02-20 10:44:48,615 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1059, mean_prob2=0.1178\n",
      "2026-02-20 10:45:06,341 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1058, mean_prob2=0.1195\n",
      "2026-02-20 10:45:24,066 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1055, mean_prob2=0.1198\n",
      "2026-02-20 10:45:41,820 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1064, mean_prob2=0.1198\n",
      "2026-02-20 10:45:59,551 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1081, mean_prob2=0.1207\n",
      "2026-02-20 10:46:17,300 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1064, mean_prob2=0.1242\n",
      "2026-02-20 10:46:17,301 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1141, range=[0.0641, 0.2553]\n",
      "2026-02-20 10:46:17,302 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1028, range=[0.0295, 0.2521]\n",
      "2026-02-20 10:46:17,302 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1140.39it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1166.49it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:47:28,765 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1283, loss2=0.1494, dev_macro_f1=0.4383, dev_err=30.19%\n",
      "2026-02-20 10:48:39,721 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0547, loss2=0.1470, dev_macro_f1=0.5711, dev_err=26.06%\n",
      "2026-02-20 10:49:49,677 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0341, loss2=0.1381, dev_macro_f1=0.5960, dev_err=26.73%\n",
      "2026-02-20 10:50:59,890 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0214, loss2=0.1017, dev_macro_f1=0.6064, dev_err=25.40%\n",
      "2026-02-20 10:52:10,775 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0147, loss2=0.0632, dev_macro_f1=0.5991, dev_err=26.73%\n",
      "2026-02-20 10:53:21,402 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0152, loss2=0.0516, dev_macro_f1=0.5888, dev_err=26.73%\n",
      "2026-02-20 10:54:32,474 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0211, loss2=0.0337, dev_macro_f1=0.6086, dev_err=26.06%\n",
      "2026-02-20 10:55:42,964 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0157, loss2=0.0271, dev_macro_f1=0.6043, dev_err=26.20%\n",
      "2026-02-20 10:56:52,990 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0096, loss2=0.0218, dev_macro_f1=0.5889, dev_err=27.39%\n",
      "2026-02-20 10:58:02,637 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0074, loss2=0.0195, dev_macro_f1=0.6055, dev_err=25.93%\n",
      "2026-02-20 10:58:02,638 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 10:58:05,649 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5925, dev_err=27.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:08,720 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5645, dev_err=32.85%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:58:11,707 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5620, dev_err=35.37%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:58:14,776 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5831, dev_err=34.44%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:58:17,825 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6068, dev_err=31.91%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:20,979 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6082, dev_err=29.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:23,991 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6180, dev_err=27.93%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:27,103 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6229, dev_err=27.13%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:30,165 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6222, dev_err=26.99%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:58:33,178 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6327, dev_err=27.13%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:36,177 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6475, dev_err=26.99%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:39,279 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6481, dev_err=26.99%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:42,267 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6477, dev_err=26.73%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:58:45,274 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6495, dev_err=26.60%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 10:58:48,383 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6460, dev_err=26.33%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 10:58:51,491 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6370, dev_err=26.46%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 10:58:54,469 - lg_cotrain - INFO - Phase 3 epoch 17: dev_macro_f1=0.6379, dev_err=26.33%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 10:58:57,441 - lg_cotrain - INFO - Phase 3 epoch 18: dev_macro_f1=0.6428, dev_err=26.20%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 10:59:00,430 - lg_cotrain - INFO - Phase 3 epoch 19: dev_macro_f1=0.6392, dev_err=26.46%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 10:59:00,432 - lg_cotrain - INFO - Early stopping at epoch 19\n",
      "2026-02-20 10:59:00,442 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 10:59:07,994 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\10_set3\\metrics.json\n",
      "2026-02-20 10:59:07,995 - lg_cotrain - INFO - Test error rate: 28.27%, Test macro-F1: 0.6334, Test ECE: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/12] budget=10, seed=3 -- done (macro_f1=0.6334)\n",
      "  [PROGRESS] 6/720 (0.8%)  |  Elapsed: 1.46h  |  ETA: 173.47h  |  done\n",
      "[7/12] budget=25, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 10:59:08,595 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=1\n",
      "2026-02-20 10:59:08,633 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 10:59:08,645 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-20 10:59:08,647 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1118.13it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1090.39it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 10:59:28,142 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1076, mean_prob2=0.1029\n",
      "2026-02-20 10:59:46,178 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1097, mean_prob2=0.1024\n",
      "2026-02-20 11:00:04,579 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1092, mean_prob2=0.1119\n",
      "2026-02-20 11:00:23,048 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1100, mean_prob2=0.1164\n",
      "2026-02-20 11:00:41,354 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1105, mean_prob2=0.1208\n",
      "2026-02-20 11:01:00,208 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1118, mean_prob2=0.1223\n",
      "2026-02-20 11:01:19,653 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1123, mean_prob2=0.1237\n",
      "2026-02-20 11:01:19,654 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1214, range=[0.0484, 0.2410]\n",
      "2026-02-20 11:01:19,655 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0966, range=[0.0150, 0.2711]\n",
      "2026-02-20 11:01:19,656 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1041.06it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1009.94it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 11:02:31,134 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1185, loss2=0.1472, dev_macro_f1=0.4071, dev_err=31.38%\n",
      "2026-02-20 11:03:40,689 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0562, loss2=0.1480, dev_macro_f1=0.5342, dev_err=27.79%\n",
      "2026-02-20 11:04:50,905 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0240, loss2=0.1338, dev_macro_f1=0.5666, dev_err=26.86%\n",
      "2026-02-20 11:06:02,454 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0182, loss2=0.0964, dev_macro_f1=0.6009, dev_err=26.20%\n",
      "2026-02-20 11:07:12,695 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0216, loss2=0.0655, dev_macro_f1=0.5772, dev_err=26.60%\n",
      "2026-02-20 11:08:22,762 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0177, loss2=0.0410, dev_macro_f1=0.5829, dev_err=26.33%\n",
      "2026-02-20 11:09:32,530 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0162, loss2=0.0323, dev_macro_f1=0.6057, dev_err=25.53%\n",
      "2026-02-20 11:10:42,397 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0157, loss2=0.0352, dev_macro_f1=0.5928, dev_err=26.33%\n",
      "2026-02-20 11:11:51,998 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0183, loss2=0.0350, dev_macro_f1=0.5884, dev_err=27.13%\n",
      "2026-02-20 11:13:01,422 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0162, loss2=0.0222, dev_macro_f1=0.6011, dev_err=25.80%\n",
      "2026-02-20 11:13:01,422 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 11:13:05,260 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5632, dev_err=33.64%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:13:09,078 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5433, dev_err=39.36%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 11:13:12,918 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6037, dev_err=34.04%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:13:16,761 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6439, dev_err=28.72%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:13:20,589 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6344, dev_err=29.79%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 11:13:24,415 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6320, dev_err=31.25%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 11:13:28,237 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6199, dev_err=32.31%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 11:13:32,076 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6215, dev_err=31.78%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 11:13:35,902 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6249, dev_err=31.38%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 11:13:35,902 - lg_cotrain - INFO - Early stopping at epoch 9\n",
      "2026-02-20 11:13:35,911 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 11:13:43,433 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\25_set1\\metrics.json\n",
      "2026-02-20 11:13:43,434 - lg_cotrain - INFO - Test error rate: 29.84%, Test macro-F1: 0.6243, Test ECE: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/12] budget=25, seed=1 -- done (macro_f1=0.6243)\n",
      "  [PROGRESS] 7/720 (1.0%)  |  Elapsed: 1.70h  |  ETA: 173.25h  |  done\n",
      "[8/12] budget=25, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 11:13:44,047 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=2\n",
      "2026-02-20 11:13:44,096 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 11:13:44,105 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-20 11:13:44,106 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1086.54it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1054.73it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 11:14:04,325 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1022, mean_prob2=0.1015\n",
      "2026-02-20 11:14:23,046 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1104, mean_prob2=0.1056\n",
      "2026-02-20 11:14:41,758 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1143, mean_prob2=0.1070\n",
      "2026-02-20 11:15:00,582 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1177, mean_prob2=0.1108\n",
      "2026-02-20 11:15:19,373 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1178, mean_prob2=0.1167\n",
      "2026-02-20 11:15:38,144 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1224, mean_prob2=0.1223\n",
      "2026-02-20 11:15:56,881 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1315, mean_prob2=0.1281\n",
      "2026-02-20 11:15:56,881 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1355, range=[0.0445, 0.2410]\n",
      "2026-02-20 11:15:56,883 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0968, range=[0.0259, 0.1836]\n",
      "2026-02-20 11:15:56,883 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1000.60it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 982.45it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 11:17:08,590 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1178, loss2=0.1701, dev_macro_f1=0.4459, dev_err=29.65%\n",
      "2026-02-20 11:18:19,106 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0493, loss2=0.1701, dev_macro_f1=0.5366, dev_err=26.73%\n",
      "2026-02-20 11:19:29,377 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0263, loss2=0.1394, dev_macro_f1=0.5675, dev_err=28.86%\n",
      "2026-02-20 11:20:39,726 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0185, loss2=0.1098, dev_macro_f1=0.5952, dev_err=26.33%\n",
      "2026-02-20 11:21:50,184 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0162, loss2=0.0735, dev_macro_f1=0.6190, dev_err=25.66%\n",
      "2026-02-20 11:23:03,734 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0162, loss2=0.0579, dev_macro_f1=0.6105, dev_err=26.06%\n",
      "2026-02-20 11:24:17,197 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0158, loss2=0.0441, dev_macro_f1=0.6246, dev_err=25.40%\n",
      "2026-02-20 11:25:32,063 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0174, loss2=0.0303, dev_macro_f1=0.6400, dev_err=24.73%\n",
      "2026-02-20 11:26:46,231 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0104, loss2=0.0296, dev_macro_f1=0.6176, dev_err=26.73%\n",
      "2026-02-20 11:27:59,271 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0064, loss2=0.0264, dev_macro_f1=0.6097, dev_err=26.86%\n",
      "2026-02-20 11:27:59,271 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-20 11:28:03,258 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5928, dev_err=28.59%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:28:07,212 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5756, dev_err=33.38%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 11:28:11,180 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6250, dev_err=31.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:28:15,239 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6420, dev_err=28.06%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:28:19,202 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6528, dev_err=27.79%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:28:23,095 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6559, dev_err=27.93%, es_counter1=0, es_counter2=0\n",
      "2026-02-20 11:28:26,967 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6399, dev_err=29.12%, es_counter1=1, es_counter2=1\n",
      "2026-02-20 11:28:30,857 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6378, dev_err=28.99%, es_counter1=2, es_counter2=2\n",
      "2026-02-20 11:28:34,723 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6416, dev_err=29.12%, es_counter1=3, es_counter2=3\n",
      "2026-02-20 11:28:38,640 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6460, dev_err=28.86%, es_counter1=4, es_counter2=4\n",
      "2026-02-20 11:28:42,576 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6394, dev_err=29.52%, es_counter1=5, es_counter2=5\n",
      "2026-02-20 11:28:42,577 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-20 11:28:42,585 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-20 11:28:50,289 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-stop-baseline\\california_wildfires_2018\\25_set2\\metrics.json\n",
      "2026-02-20 11:28:50,289 - lg_cotrain - INFO - Test error rate: 27.38%, Test macro-F1: 0.6577, Test ECE: 0.0423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/12] budget=25, seed=2 -- done (macro_f1=0.6577)\n",
      "  [PROGRESS] 8/720 (1.1%)  |  Elapsed: 1.95h  |  ETA: 173.80h  |  done\n",
      "[9/12] budget=25, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 11:28:50,897 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=3\n",
      "2026-02-20 11:28:50,947 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-20 11:28:50,958 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-20 11:28:50,960 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1023.16it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1010.95it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 11:29:11,457 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1079, mean_prob2=0.1198\n",
      "2026-02-20 11:29:30,427 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1113, mean_prob2=0.1233\n",
      "2026-02-20 11:29:49,569 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1151, mean_prob2=0.1187\n",
      "2026-02-20 11:30:09,371 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1162, mean_prob2=0.1180\n",
      "2026-02-20 11:30:28,456 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1152, mean_prob2=0.1197\n",
      "2026-02-20 11:30:47,699 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1139, mean_prob2=0.1267\n",
      "2026-02-20 11:31:06,812 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1210, mean_prob2=0.1364\n",
      "2026-02-20 11:31:06,813 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1297, range=[0.0662, 0.2515]\n",
      "2026-02-20 11:31:06,813 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1071, range=[0.0096, 0.2609]\n",
      "2026-02-20 11:31:06,813 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1018.01it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 989.83it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-20 11:32:19,199 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1283, loss2=0.1586, dev_macro_f1=0.4254, dev_err=31.25%\n",
      "2026-02-20 11:33:28,545 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0538, loss2=0.1475, dev_macro_f1=0.5554, dev_err=26.86%\n",
      "2026-02-20 11:34:37,790 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0302, loss2=0.1230, dev_macro_f1=0.5890, dev_err=26.20%\n",
      "2026-02-20 11:35:46,183 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0250, loss2=0.0928, dev_macro_f1=0.6036, dev_err=25.93%\n",
      "2026-02-20 11:36:54,677 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0170, loss2=0.0643, dev_macro_f1=0.6197, dev_err=25.27%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m TARGET_EVENTS:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  Event: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     results = \u001b[43mrun_all_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpseudo_label_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPSEUDO_LABEL_SOURCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_ROOT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresults_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_on_experiment_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     all_strategy_results[strategy][event] = results\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Workspace\\Co-Training\\lg_cotrain\\run_all.py:107\u001b[39m, in \u001b[36mrun_all_experiments\u001b[39m\u001b[34m(event, budgets, seed_sets, pseudo_label_source, model_name, weight_gen_epochs, cotrain_epochs, finetune_max_epochs, finetune_patience, stopping_strategy, batch_size, lr, max_seq_length, data_root, results_root, _trainer_cls, _on_experiment_done)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    106\u001b[39m     trainer = _trainer_cls(config)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     all_results.append(result)\n\u001b[32m    109\u001b[39m     completed += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Workspace\\Co-Training\\lg_cotrain\\trainer.py:268\u001b[39m, in \u001b[36mLGCoTrainer.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Update probabilities and recompute lambdas\u001b[39;00m\n\u001b[32m    267\u001b[39m probs1 = \u001b[38;5;28mself\u001b[39m._collect_probs(model1, loader_dlg_eval, pseudo_label_ids)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m probs2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_dlg_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo_label_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m cotrain_tracker1.record_epoch(probs1)\n\u001b[32m    270\u001b[39m cotrain_tracker2.record_epoch(probs2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Workspace\\Co-Training\\lg_cotrain\\trainer.py:82\u001b[39m, in \u001b[36mLGCoTrainer._collect_probs\u001b[39m\u001b[34m(self, model, loader, pseudo_label_ids)\u001b[39m\n\u001b[32m     79\u001b[39m attention_mask = batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     80\u001b[39m sample_idx = batch[\u001b[33m\"\u001b[39m\u001b[33msample_idx\u001b[39m\u001b[33m\"\u001b[39m].numpy()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m probs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()\n\u001b[32m     83\u001b[39m all_probs.append(probs)\n\u001b[32m     84\u001b[39m all_indices.append(sample_idx)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Count already-completed experiments across all strategies (for accurate ETA from the start)\n",
    "already_done = sum(\n",
    "    1\n",
    "    for strategy in STRATEGIES\n",
    "    for event in TARGET_EVENTS\n",
    "    for budget in BUDGETS\n",
    "    for seed_set in SEED_SETS\n",
    "    if (\n",
    "        Path(STRATEGY_RESULTS_ROOTS[strategy])\n",
    "        / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "    ).exists()\n",
    ")\n",
    "total_experiments = len(STRATEGIES) * expts_per_strategy\n",
    "\n",
    "print(f\"Total experiments : {total_experiments}\")\n",
    "print(f\"Already completed : {already_done}\")\n",
    "print(f\"Remaining         : {total_experiments - already_done}\")\n",
    "print()\n",
    "\n",
    "overall_start = time.time()\n",
    "tracker = ProgressTracker(total_experiments, already_done, overall_start)\n",
    "all_strategy_results = {}  # strategy -> event -> list[result_dict]\n",
    "\n",
    "for strategy in STRATEGIES:\n",
    "    results_root = STRATEGY_RESULTS_ROOTS[strategy]\n",
    "    strat_start = time.time()\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Strategy: {strategy}  →  {results_root}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    all_strategy_results[strategy] = {}\n",
    "\n",
    "    for event in TARGET_EVENTS:\n",
    "        print(f\"\\n  Event: {event}\")\n",
    "        results = run_all_experiments(\n",
    "            event,\n",
    "            pseudo_label_source=PSEUDO_LABEL_SOURCE,\n",
    "            stopping_strategy=strategy,\n",
    "            data_root=DATA_ROOT,\n",
    "            results_root=results_root,\n",
    "            _on_experiment_done=tracker.update,\n",
    "        )\n",
    "        all_strategy_results[strategy][event] = results\n",
    "        print()\n",
    "        print(format_summary_table(results, event))\n",
    "\n",
    "    strat_elapsed = time.time() - strat_start\n",
    "    print(f\"\\n  Strategy '{strategy}' done in {strat_elapsed / 3600:.2f}h ({strat_elapsed / 60:.1f}min)\")\n",
    "\n",
    "total_elapsed = time.time() - overall_start\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"All strategies complete in {total_elapsed / 3600:.2f}h ({total_elapsed / 60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any results that already existed (re-run safe)\n",
    "for strategy in STRATEGIES:\n",
    "    results_root = Path(STRATEGY_RESULTS_ROOTS[strategy])\n",
    "    if strategy not in all_strategy_results:\n",
    "        all_strategy_results[strategy] = {}\n",
    "\n",
    "    for event in TARGET_EVENTS:\n",
    "        if event in all_strategy_results[strategy]:\n",
    "            continue\n",
    "        results = []\n",
    "        for budget in BUDGETS:\n",
    "            for seed_set in SEED_SETS:\n",
    "                path = results_root / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "                if path.exists():\n",
    "                    with open(path) as f:\n",
    "                        results.append(json.load(f))\n",
    "        if results:\n",
    "            all_strategy_results[strategy][event] = results\n",
    "\n",
    "# Build lookup: lookup[strategy][event][(budget, seed_set)] -> result\n",
    "lookup = {}\n",
    "for strategy in STRATEGIES:\n",
    "    lookup[strategy] = {}\n",
    "    for event in TARGET_EVENTS:\n",
    "        lookup[strategy][event] = {}\n",
    "        for r in all_strategy_results.get(strategy, {}).get(event, []):\n",
    "            if r is not None:\n",
    "                lookup[strategy][event][(r[\"budget\"], r[\"seed_set\"])] = r\n",
    "\n",
    "# Coverage report\n",
    "print(\"Experiments loaded per strategy:\")\n",
    "for strategy in STRATEGIES:\n",
    "    n = sum(len(lookup[strategy][e]) for e in TARGET_EVENTS)\n",
    "    expected = expts_per_strategy\n",
    "    pct = 100 * n / expected if expected else 0\n",
    "    print(f\"  {strategy:<25}: {n:>3}/{expected}  ({pct:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary tables: for each event, show mean macro-F1 per strategy × budget\n",
    "# plus a delta-from-baseline table.\n",
    "\n",
    "col_w = 10\n",
    "\n",
    "for event in TARGET_EVENTS:\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Event: {event}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    # --- Absolute macro-F1 ---\n",
    "    print(f\"{'Strategy':<26}\" + \"\".join(f\" B={b:<{col_w - 2}}\" for b in BUDGETS) + \" | Mean\")\n",
    "    print(\"-\" * (26 + col_w * len(BUDGETS) + 7))\n",
    "\n",
    "    baseline_means = {}\n",
    "    for strategy in STRATEGIES:\n",
    "        row = f\"{strategy:<26}\"\n",
    "        budget_means = []\n",
    "        for budget in BUDGETS:\n",
    "            f1s = [\n",
    "                lookup[strategy][event].get((budget, s), {}).get(\"test_macro_f1\")\n",
    "                for s in SEED_SETS\n",
    "            ]\n",
    "            f1s = [f for f in f1s if f is not None]\n",
    "            if f1s:\n",
    "                m = statistics.mean(f1s)\n",
    "                sd = statistics.stdev(f1s) if len(f1s) >= 2 else 0.0\n",
    "                budget_means.append(m)\n",
    "                row += f\" {m:.4f}±{sd:.4f}\"\n",
    "            else:\n",
    "                budget_means.append(None)\n",
    "                row += f\" {'N/A':<{col_w}}\"\n",
    "        valid = [v for v in budget_means if v is not None]\n",
    "        row += f\" | {statistics.mean(valid):.4f}\" if valid else \" | N/A\"\n",
    "        print(row)\n",
    "        if strategy == \"baseline\":\n",
    "            baseline_means = dict(zip(BUDGETS, budget_means))\n",
    "\n",
    "    # --- Delta vs baseline ---\n",
    "    print()\n",
    "    print(f\"Delta vs baseline  (+) = better:\")\n",
    "    print(f\"{'Strategy':<26}\" + \"\".join(f\" B={b:<{col_w - 2}}\" for b in BUDGETS) + \" | Mean Δ\")\n",
    "    print(\"-\" * (26 + col_w * len(BUDGETS) + 9))\n",
    "\n",
    "    for strategy in STRATEGIES:\n",
    "        if strategy == \"baseline\":\n",
    "            continue\n",
    "        row = f\"{strategy:<26}\"\n",
    "        deltas = []\n",
    "        for budget in BUDGETS:\n",
    "            f1s = [\n",
    "                lookup[strategy][event].get((budget, s), {}).get(\"test_macro_f1\")\n",
    "                for s in SEED_SETS\n",
    "            ]\n",
    "            f1s = [f for f in f1s if f is not None]\n",
    "            base = baseline_means.get(budget)\n",
    "            if f1s and base is not None:\n",
    "                d = statistics.mean(f1s) - base\n",
    "                deltas.append(d)\n",
    "                sign = \"+\" if d >= 0 else \"\"\n",
    "                row += f\" {sign}{d:.4f}   \"\n",
    "            else:\n",
    "                row += f\" {'N/A':<{col_w}}\"\n",
    "        row += f\" | {'+' if sum(deltas)/len(deltas)>=0 else ''}{sum(deltas)/len(deltas):.4f}\" if deltas else \" | N/A\"\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar chart: macro-F1 by budget, grouped bars per strategy\n",
    "# One subplot per event (mean ± std across 3 seeds)\n",
    "\n",
    "n_events     = len(TARGET_EVENTS)\n",
    "n_strategies = len(STRATEGIES)\n",
    "bar_width    = 0.8 / n_strategies\n",
    "colors       = plt.cm.tab10(np.linspace(0, 1, n_strategies))\n",
    "\n",
    "# Layout: up to 5 events per row\n",
    "ncols = min(5, n_events)\n",
    "nrows = (n_events + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4.5 * ncols, 4.5 * nrows), sharey=False)\n",
    "axes_flat = np.array(axes).flatten() if n_events > 1 else [axes]\n",
    "\n",
    "for ax, event in zip(axes_flat, TARGET_EVENTS):\n",
    "    x = np.arange(len(BUDGETS))\n",
    "    for i, (strategy, color) in enumerate(zip(STRATEGIES, colors)):\n",
    "        means, errs = [], []\n",
    "        for budget in BUDGETS:\n",
    "            f1s = [\n",
    "                lookup[strategy][event].get((budget, s), {}).get(\"test_macro_f1\")\n",
    "                for s in SEED_SETS\n",
    "            ]\n",
    "            f1s = [f for f in f1s if f is not None]\n",
    "            means.append(statistics.mean(f1s) if f1s else 0)\n",
    "            errs.append(statistics.stdev(f1s) if len(f1s) >= 2 else 0)\n",
    "        offset = (i - n_strategies / 2 + 0.5) * bar_width\n",
    "        ax.bar(\n",
    "            x + offset, means, bar_width * 0.9,\n",
    "            yerr=errs, capsize=2,\n",
    "            label=strategy, color=color, alpha=0.85,\n",
    "        )\n",
    "    ax.set_title(event.replace(\"_\", \" \").title(), fontsize=9)\n",
    "    ax.set_xlabel(\"Budget\")\n",
    "    ax.set_ylabel(\"Macro-F1\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([str(b) for b in BUDGETS])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for ax in axes_flat[n_events:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "axes_flat[0].legend(fontsize=7, loc=\"upper left\", framealpha=0.7)\n",
    "fig.suptitle(\n",
    "    f\"Stopping Strategy Comparison — All Budgets & Seeds\\n(pseudo-labels: {PSEUDO_LABEL_SOURCE})\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-event summary: for each strategy, show mean macro-F1 across all events and budgets.\n",
    "# Useful for picking a single \"best\" strategy to recommend.\n",
    "\n",
    "print(\"Grand summary — mean macro-F1 across all events and seeds\\n\")\n",
    "print(f\"{'Strategy':<26}\" + \"\".join(f\" B={b:<8}\" for b in BUDGETS) + \" | Overall\")\n",
    "print(\"-\" * (26 + 10 * len(BUDGETS) + 10))\n",
    "\n",
    "for strategy in STRATEGIES:\n",
    "    row = f\"{strategy:<26}\"\n",
    "    all_f1s = []\n",
    "    for budget in BUDGETS:\n",
    "        f1s = [\n",
    "            lookup[strategy][e].get((budget, s), {}).get(\"test_macro_f1\")\n",
    "            for e in TARGET_EVENTS\n",
    "            for s in SEED_SETS\n",
    "        ]\n",
    "        f1s = [f for f in f1s if f is not None]\n",
    "        if f1s:\n",
    "            m = statistics.mean(f1s)\n",
    "            sd = statistics.stdev(f1s) if len(f1s) >= 2 else 0\n",
    "            all_f1s.extend(f1s)\n",
    "            row += f\" {m:.4f}±{sd:.4f}\"\n",
    "        else:\n",
    "            row += f\" {'N/A':<10}\"\n",
    "    overall = statistics.mean(all_f1s) if all_f1s else None\n",
    "    row += f\" | {overall:.4f}\" if overall is not None else \" | N/A\"\n",
    "    print(row)\n",
    "\n",
    "# Per-class F1 heatmap for each event at budget=5 (hardest case)\n",
    "from lg_cotrain.data_loading import CLASS_LABELS\n",
    "\n",
    "HEATMAP_BUDGET = 5\n",
    "print(f\"\\nPer-class F1 heatmaps at budget={HEATMAP_BUDGET} (hardest imbalance scenario)\")\n",
    "\n",
    "for event in TARGET_EVENTS:\n",
    "    strategies_with_data = []\n",
    "    class_f1_matrix = []\n",
    "\n",
    "    for strategy in STRATEGIES:\n",
    "        per_class_all_seeds = [\n",
    "            lookup[strategy][event][(HEATMAP_BUDGET, s)][\"test_per_class_f1\"]\n",
    "            for s in SEED_SETS\n",
    "            if (HEATMAP_BUDGET, s) in lookup[strategy][event]\n",
    "            and \"test_per_class_f1\" in lookup[strategy][event][(HEATMAP_BUDGET, s)]\n",
    "        ]\n",
    "        if per_class_all_seeds:\n",
    "            mean_per_class = [\n",
    "                statistics.mean(seed[i] for seed in per_class_all_seeds)\n",
    "                for i in range(len(per_class_all_seeds[0]))\n",
    "            ]\n",
    "            strategies_with_data.append(strategy)\n",
    "            class_f1_matrix.append(mean_per_class)\n",
    "\n",
    "    if not strategies_with_data:\n",
    "        print(f\"  No per-class data for {event} at budget={HEATMAP_BUDGET}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    data = np.array(class_f1_matrix)\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(max(9, len(CLASS_LABELS) * 0.75), len(strategies_with_data) * 0.65 + 1.8)\n",
    "    )\n",
    "    im = ax.imshow(data, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "    ax.set_xticks(range(len(CLASS_LABELS)))\n",
    "    ax.set_xticklabels(CLASS_LABELS, rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticks(range(len(strategies_with_data)))\n",
    "    ax.set_yticklabels(strategies_with_data, fontsize=9)\n",
    "    ax.set_title(\n",
    "        f\"{event}  |  Budget={HEATMAP_BUDGET}  |  Per-class F1 (mean across seeds)\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "    for i in range(len(strategies_with_data)):\n",
    "        for j in range(len(CLASS_LABELS)):\n",
    "            val = data[i, j]\n",
    "            color = \"black\" if 0.25 < val < 0.75 else \"white\"\n",
    "            ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", fontsize=7, color=color)\n",
    "\n",
    "    fig.colorbar(im, ax=ax, label=\"F1 Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# Rebuild multi-tab dashboard with all strategy result sets.\n\nfrom lg_cotrain.dashboard import discover_result_sets, generate_html_multi\n\nTOP_RESULTS_ROOT = str(repo_root / \"results\")\n\nresult_sets = discover_result_sets(TOP_RESULTS_ROOT)\nprint(f\"Discovered {len(result_sets)} model(s):\")\nfor model, types in result_sets.items():\n    for exp_type, experiments in types.items():\n        for name, path in experiments:\n            print(f\"  {model}/{exp_type}/{name:<20} -> {path}\")\n\nhtml = generate_html_multi(result_sets, data_root=DATA_ROOT)\ndashboard_path = Path(TOP_RESULTS_ROOT) / \"dashboard.html\"\ndashboard_path.write_text(html)\nprint(f\"\\nDashboard written to: {dashboard_path}\")\nprint(\"Open in a browser to compare all strategies across all budgets and events.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}