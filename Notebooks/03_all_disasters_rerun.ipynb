{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LG-CoTrain: All Disasters Re-Run\n",
    "\n",
    "This notebook re-runs the **LG-CoTrain** co-training pipeline across **all 10 disaster\n",
    "events** with a **configurable pseudo-label source** and stores results in a\n",
    "**named sub-folder** under `results/`.\n",
    "\n",
    "### Why a separate notebook?\n",
    "\n",
    "We may run experiments multiple times with different pseudo-label sets (e.g.,\n",
    "gpt-4o vs llama-3, or multiple runs of the same model). Each run is stored in\n",
    "its own sub-folder so results are never overwritten.\n",
    "\n",
    "### Configuration (Cell 2)\n",
    "\n",
    "Edit the following variables in the **Configuration** cell before running:\n",
    "\n",
    "| Variable | Description |\n",
    "|---|---|\n",
    "| `PSEUDO_LABEL_SOURCE` | Name of the pseudo-label directory under `data/pseudo-labelled/` |\n",
    "| `RUN_NAME` | Sub-folder name under `results/` for this run |\n",
    "\n",
    "### Resume Support\n",
    "\n",
    "Same two-level resume as notebook 02:\n",
    "\n",
    "1. **Event level**: Events with all 12 `metrics.json` files are skipped entirely.\n",
    "2. **Experiment level**: Individual `(budget, seed_set)` combinations with existing\n",
    "   results are skipped within each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: D:\\Workspace\\Co-Training\n",
      "Budgets: [5, 10, 25, 50]\n",
      "Seed sets: [1, 2, 3]\n",
      "Experiments per event: 12\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_repo_root(marker: str = \"lg_cotrain\") -> Path:\n",
    "    for candidate in [Path().resolve()] + list(Path().resolve().parents):\n",
    "        if (candidate / marker).is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot find repo root: no ancestor directory contains '{marker}/'. \"\n",
    "        \"Run the notebook from inside the repository.\"\n",
    "    )\n",
    "\n",
    "repo_root = _find_repo_root()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lg_cotrain.run_all import BUDGETS, SEED_SETS, run_all_experiments, format_summary_table\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Budgets: {BUDGETS}\")\n",
    "print(f\"Seed sets: {SEED_SETS}\")\n",
    "print(f\"Experiments per event: {len(BUDGETS) * len(SEED_SETS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-label source: gpt-4o\n",
      "Run name: gpt-4o-run-2\n",
      "Data root: D:\\Workspace\\Co-Training\\data\n",
      "Results root: D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\n"
     ]
    }
   ],
   "source": [
    "# ---- User-editable configuration ----\n",
    "PSEUDO_LABEL_SOURCE = \"gpt-4o\"      # Change to use different pseudo-labels (e.g. \"llama-3\")\n",
    "RUN_NAME = \"gpt-4o-run-2\"            # Sub-folder name under results/\n",
    "\n",
    "DATA_ROOT = str(repo_root / \"data\")\n",
    "RESULTS_ROOT = str(repo_root / \"results\" / RUN_NAME)\n",
    "\n",
    "print(f\"Pseudo-label source: {PSEUDO_LABEL_SOURCE}\")\n",
    "print(f\"Run name: {RUN_NAME}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"Results root: {RESULTS_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 events total\n",
      "  Completed: 0 (0 experiments)\n",
      "  Pending:   10 (up to 120 experiments)\n",
      "\n",
      "Pending events (will be run):\n",
      "  - california_wildfires_2018\n",
      "  - canada_wildfires_2016\n",
      "  - cyclone_idai_2019\n",
      "  - hurricane_dorian_2019\n",
      "  - hurricane_florence_2018\n",
      "  - hurricane_harvey_2017\n",
      "  - hurricane_irma_2017\n",
      "  - hurricane_maria_2017\n",
      "  - kaikoura_earthquake_2016\n",
      "  - kerala_floods_2018\n"
     ]
    }
   ],
   "source": [
    "def is_event_complete(event, results_root):\n",
    "    \"\"\"Check if all 12 metrics.json files exist for an event.\"\"\"\n",
    "    for budget in BUDGETS:\n",
    "        for seed_set in SEED_SETS:\n",
    "            path = Path(results_root) / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "            if not path.exists():\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Discover events from data directory\n",
    "data_dir = Path(DATA_ROOT) / \"original\"\n",
    "all_events = sorted(p.name for p in data_dir.iterdir() if p.is_dir())\n",
    "\n",
    "completed_events = [e for e in all_events if is_event_complete(e, RESULTS_ROOT)]\n",
    "pending_events = [e for e in all_events if e not in completed_events]\n",
    "\n",
    "print(f\"Found {len(all_events)} events total\")\n",
    "print(f\"  Completed: {len(completed_events)} ({len(completed_events) * 12} experiments)\")\n",
    "print(f\"  Pending:   {len(pending_events)} (up to {len(pending_events) * 12} experiments)\")\n",
    "\n",
    "if completed_events:\n",
    "    print(f\"\\nCompleted events (will be skipped):\")\n",
    "    for e in completed_events:\n",
    "        print(f\"  - {e}\")\n",
    "\n",
    "if pending_events:\n",
    "    print(f\"\\nPending events (will be run):\")\n",
    "    for e in pending_events:\n",
    "        print(f\"  - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments\n",
    "\n",
    "For each pending event, we call `run_all_experiments` with the configured\n",
    "`pseudo_label_source` and `results_root` pointing to our named sub-folder.\n",
    "\n",
    "Individual experiments that already have `metrics.json` are automatically\n",
    "skipped (useful if the notebook crashed mid-event)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments: 120\n",
      "Already completed: 0\n",
      "Remaining: 120\n",
      "\n",
      "============================================================\n",
      "Event 1/10: california_wildfires_2018\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Co-Training\\co-training-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 13:26:52,260 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=1\n",
      "2026-02-18 13:26:52,292 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 13:26:52,303 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-18 13:26:52,305 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1072.54it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1091.60it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 13:27:10,883 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0981, mean_prob2=0.1025\n",
      "2026-02-18 13:27:28,265 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0997, mean_prob2=0.0991\n",
      "2026-02-18 13:27:45,561 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1010, mean_prob2=0.0970\n",
      "2026-02-18 13:28:03,129 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1015, mean_prob2=0.0978\n",
      "2026-02-18 13:28:20,869 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1025, mean_prob2=0.0998\n",
      "2026-02-18 13:28:38,449 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1033, mean_prob2=0.1032\n",
      "2026-02-18 13:28:56,081 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1043, mean_prob2=0.1063\n",
      "2026-02-18 13:28:56,081 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1067, range=[0.0520, 0.2235]\n",
      "2026-02-18 13:28:56,081 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0917, range=[0.0202, 0.2378]\n",
      "2026-02-18 13:28:56,081 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1117.33it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1196.18it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 13:30:07,660 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1141, loss2=0.1382, dev_macro_f1=0.4347, dev_err=30.45%\n",
      "2026-02-18 13:31:22,290 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0275, loss2=0.1066, dev_macro_f1=0.5736, dev_err=26.20%\n",
      "2026-02-18 13:32:39,045 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0103, loss2=0.0896, dev_macro_f1=0.6113, dev_err=25.80%\n",
      "2026-02-18 13:33:55,883 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0046, loss2=0.0692, dev_macro_f1=0.5822, dev_err=27.26%\n",
      "2026-02-18 13:35:11,134 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0028, loss2=0.0477, dev_macro_f1=0.5989, dev_err=27.39%\n",
      "2026-02-18 13:36:25,805 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0052, loss2=0.0322, dev_macro_f1=0.5826, dev_err=27.53%\n",
      "2026-02-18 13:37:40,768 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0055, loss2=0.0381, dev_macro_f1=0.5884, dev_err=26.86%\n",
      "2026-02-18 13:38:52,201 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0064, loss2=0.0184, dev_macro_f1=0.5885, dev_err=26.99%\n",
      "2026-02-18 13:40:04,804 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0085, loss2=0.0137, dev_macro_f1=0.6053, dev_err=26.20%\n",
      "2026-02-18 13:41:20,688 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0072, loss2=0.0083, dev_macro_f1=0.5887, dev_err=27.39%\n",
      "2026-02-18 13:41:20,688 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 13:41:23,702 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.6000, dev_err=26.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 13:41:26,711 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6115, dev_err=27.13%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 13:41:29,575 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5817, dev_err=29.92%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 13:41:32,297 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5598, dev_err=34.71%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 13:41:35,020 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5429, dev_err=38.03%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 13:41:37,741 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5195, dev_err=41.36%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 13:41:40,482 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5214, dev_err=40.82%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 13:41:40,482 - lg_cotrain - INFO - Early stopping at epoch 7\n",
      "2026-02-18 13:41:40,493 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 13:41:47,781 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\5_set1\\metrics.json\n",
      "2026-02-18 13:41:47,782 - lg_cotrain - INFO - Test error rate: 26.90%, Test macro-F1: 0.6405, Test ECE: 0.1666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- done (macro_f1=0.6405)\n",
      "[PROGRESS] 1/120 (0.8%) | Elapsed: 0.25h | ETA: 29.76h\n",
      "[2/12] budget=5, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 13:41:48,308 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=2\n",
      "2026-02-18 13:41:48,357 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 13:41:48,366 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-18 13:41:48,368 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1047.42it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1150.91it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 13:42:07,741 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0968, mean_prob2=0.0993\n",
      "2026-02-18 13:42:26,565 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0989, mean_prob2=0.0997\n",
      "2026-02-18 13:42:45,117 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1010, mean_prob2=0.0998\n",
      "2026-02-18 13:43:03,705 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1036, mean_prob2=0.1001\n",
      "2026-02-18 13:43:22,508 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1059, mean_prob2=0.1005\n",
      "2026-02-18 13:43:41,262 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1084, mean_prob2=0.1009\n",
      "2026-02-18 13:44:00,017 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1092, mean_prob2=0.1014\n",
      "2026-02-18 13:44:00,019 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1149, range=[0.0550, 0.1973]\n",
      "2026-02-18 13:44:00,020 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0926, range=[0.0286, 0.1929]\n",
      "2026-02-18 13:44:00,020 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1024.32it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1087.05it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 13:45:17,636 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1167, loss2=0.1434, dev_macro_f1=0.4585, dev_err=29.65%\n",
      "2026-02-18 13:46:35,181 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0276, loss2=0.1182, dev_macro_f1=0.5596, dev_err=26.33%\n",
      "2026-02-18 13:47:48,936 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0109, loss2=0.1020, dev_macro_f1=0.5962, dev_err=27.79%\n",
      "2026-02-18 13:49:05,101 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0048, loss2=0.0751, dev_macro_f1=0.6066, dev_err=30.32%\n",
      "2026-02-18 13:50:21,013 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0037, loss2=0.0516, dev_macro_f1=0.6130, dev_err=26.06%\n",
      "2026-02-18 13:51:34,637 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0041, loss2=0.0354, dev_macro_f1=0.6206, dev_err=25.66%\n",
      "2026-02-18 13:52:48,056 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0043, loss2=0.0262, dev_macro_f1=0.6179, dev_err=25.66%\n",
      "2026-02-18 13:53:59,266 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0064, loss2=0.0215, dev_macro_f1=0.6030, dev_err=26.06%\n",
      "2026-02-18 13:55:14,400 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0077, loss2=0.0139, dev_macro_f1=0.6079, dev_err=25.80%\n",
      "2026-02-18 13:56:31,717 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0082, loss2=0.0194, dev_macro_f1=0.5868, dev_err=27.66%\n",
      "2026-02-18 13:56:31,718 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 13:56:34,729 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5938, dev_err=27.53%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 13:56:37,747 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6034, dev_err=29.39%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 13:56:40,750 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6024, dev_err=32.31%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 13:56:43,761 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5849, dev_err=36.97%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 13:56:47,007 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5837, dev_err=38.70%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 13:56:50,011 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5932, dev_err=37.23%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 13:56:53,016 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6016, dev_err=35.77%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 13:56:53,017 - lg_cotrain - INFO - Early stopping at epoch 7\n",
      "2026-02-18 13:56:53,028 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 13:57:01,091 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\5_set2\\metrics.json\n",
      "2026-02-18 13:57:01,091 - lg_cotrain - INFO - Test error rate: 28.54%, Test macro-F1: 0.6377, Test ECE: 0.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/12] budget=5, seed=2 -- done (macro_f1=0.6377)\n",
      "[PROGRESS] 2/120 (1.7%) | Elapsed: 0.50h | ETA: 29.72h\n",
      "[3/12] budget=5, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 13:57:01,634 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=5, seed_set=3\n",
      "2026-02-18 13:57:01,682 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 13:57:01,691 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 5113\n",
      "2026-02-18 13:57:01,693 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1169.82it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1110.97it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 13:57:22,364 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1056, mean_prob2=0.0887\n",
      "2026-02-18 13:57:41,813 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1061, mean_prob2=0.0972\n",
      "2026-02-18 13:58:01,134 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1061, mean_prob2=0.1057\n",
      "2026-02-18 13:58:20,175 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1060, mean_prob2=0.1095\n",
      "2026-02-18 13:58:39,013 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1073, mean_prob2=0.1112\n",
      "2026-02-18 13:58:57,794 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1084, mean_prob2=0.1136\n",
      "2026-02-18 13:59:16,902 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1090, mean_prob2=0.1166\n",
      "2026-02-18 13:59:16,903 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1131, range=[0.0573, 0.2166]\n",
      "2026-02-18 13:59:16,904 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0895, range=[0.0153, 0.2465]\n",
      "2026-02-18 13:59:16,904 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1060.82it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1137.59it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:00:33,683 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1202, loss2=0.1403, dev_macro_f1=0.4526, dev_err=30.05%\n",
      "2026-02-18 14:01:46,871 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0288, loss2=0.1072, dev_macro_f1=0.5822, dev_err=26.33%\n",
      "2026-02-18 14:02:59,281 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0116, loss2=0.0881, dev_macro_f1=0.6231, dev_err=25.80%\n",
      "2026-02-18 14:04:14,138 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0047, loss2=0.0699, dev_macro_f1=0.6205, dev_err=27.13%\n",
      "2026-02-18 14:05:29,520 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0030, loss2=0.0454, dev_macro_f1=0.6163, dev_err=26.86%\n",
      "2026-02-18 14:06:46,293 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0045, loss2=0.0300, dev_macro_f1=0.6059, dev_err=27.26%\n",
      "2026-02-18 14:08:00,999 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0054, loss2=0.0209, dev_macro_f1=0.6024, dev_err=27.13%\n",
      "2026-02-18 14:09:11,586 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0076, loss2=0.0162, dev_macro_f1=0.5969, dev_err=27.93%\n",
      "2026-02-18 14:10:25,766 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0079, loss2=0.0075, dev_macro_f1=0.5934, dev_err=28.06%\n",
      "2026-02-18 14:11:37,430 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0081, loss2=0.0071, dev_macro_f1=0.5973, dev_err=27.93%\n",
      "2026-02-18 14:11:37,431 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 14:11:40,200 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.6120, dev_err=28.72%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:11:42,922 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5943, dev_err=30.85%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:11:45,651 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5918, dev_err=33.11%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:11:48,408 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5601, dev_err=38.03%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 14:11:51,134 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5476, dev_err=39.76%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 14:11:53,859 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5345, dev_err=40.69%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 14:11:53,860 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 14:11:53,870 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 14:12:01,149 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\5_set3\\metrics.json\n",
      "2026-02-18 14:12:01,149 - lg_cotrain - INFO - Test error rate: 27.58%, Test macro-F1: 0.6231, Test ECE: 0.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/12] budget=5, seed=3 -- done (macro_f1=0.6231)\n",
      "[PROGRESS] 3/120 (2.5%) | Elapsed: 0.75h | ETA: 29.40h\n",
      "[4/12] budget=10, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 14:12:01,789 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=1\n",
      "2026-02-18 14:12:01,845 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 14:12:01,854 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-18 14:12:01,856 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1206.87it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1094.29it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:12:20,950 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1004, mean_prob2=0.0998\n",
      "2026-02-18 14:12:38,794 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1043, mean_prob2=0.0989\n",
      "2026-02-18 14:12:56,640 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1085, mean_prob2=0.1022\n",
      "2026-02-18 14:13:14,563 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1133, mean_prob2=0.1070\n",
      "2026-02-18 14:13:32,447 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1159, mean_prob2=0.1114\n",
      "2026-02-18 14:13:50,265 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1155, mean_prob2=0.1136\n",
      "2026-02-18 14:14:08,631 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1155, mean_prob2=0.1146\n",
      "2026-02-18 14:14:08,634 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1232, range=[0.0536, 0.2147]\n",
      "2026-02-18 14:14:08,634 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0936, range=[0.0210, 0.2716]\n",
      "2026-02-18 14:14:08,634 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1150.93it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1131.25it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:15:22,716 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1165, loss2=0.1503, dev_macro_f1=0.4432, dev_err=30.32%\n",
      "2026-02-18 14:16:32,096 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0277, loss2=0.1062, dev_macro_f1=0.5522, dev_err=27.26%\n",
      "2026-02-18 14:17:41,238 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0109, loss2=0.0935, dev_macro_f1=0.5849, dev_err=27.66%\n",
      "2026-02-18 14:18:50,432 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0056, loss2=0.0654, dev_macro_f1=0.5796, dev_err=28.99%\n",
      "2026-02-18 14:19:59,942 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0041, loss2=0.0486, dev_macro_f1=0.5998, dev_err=28.06%\n",
      "2026-02-18 14:21:09,521 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0052, loss2=0.0326, dev_macro_f1=0.5922, dev_err=27.13%\n",
      "2026-02-18 14:22:18,903 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0048, loss2=0.0204, dev_macro_f1=0.5995, dev_err=26.86%\n",
      "2026-02-18 14:23:28,287 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0078, loss2=0.0189, dev_macro_f1=0.5895, dev_err=27.79%\n",
      "2026-02-18 14:24:37,705 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0086, loss2=0.0167, dev_macro_f1=0.5690, dev_err=29.65%\n",
      "2026-02-18 14:25:47,076 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0084, loss2=0.0351, dev_macro_f1=0.6065, dev_err=26.33%\n",
      "2026-02-18 14:25:47,076 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 14:25:50,071 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.6020, dev_err=28.19%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:25:53,047 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5659, dev_err=32.71%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:25:56,019 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5802, dev_err=32.58%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:25:58,991 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5849, dev_err=33.11%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 14:26:01,967 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5988, dev_err=32.85%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 14:26:04,946 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5988, dev_err=33.24%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 14:26:04,946 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 14:26:04,961 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 14:26:12,236 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\10_set1\\metrics.json\n",
      "2026-02-18 14:26:12,236 - lg_cotrain - INFO - Test error rate: 27.24%, Test macro-F1: 0.6291, Test ECE: 0.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/12] budget=10, seed=1 -- done (macro_f1=0.6291)\n",
      "[PROGRESS] 4/120 (3.3%) | Elapsed: 0.99h | ETA: 28.72h\n",
      "[5/12] budget=10, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 14:26:12,791 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=2\n",
      "2026-02-18 14:26:12,839 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 14:26:12,848 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-18 14:26:12,850 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1202.79it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1237.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:26:31,709 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0967, mean_prob2=0.1014\n",
      "2026-02-18 14:26:49,435 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0988, mean_prob2=0.1024\n",
      "2026-02-18 14:27:07,169 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1009, mean_prob2=0.1053\n",
      "2026-02-18 14:27:24,931 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1042, mean_prob2=0.1079\n",
      "2026-02-18 14:27:42,757 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1074, mean_prob2=0.1099\n",
      "2026-02-18 14:28:00,521 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1083, mean_prob2=0.1111\n",
      "2026-02-18 14:28:18,277 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1104, mean_prob2=0.1128\n",
      "2026-02-18 14:28:18,278 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1148, range=[0.0553, 0.1993]\n",
      "2026-02-18 14:28:18,278 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0971, range=[0.0270, 0.1861]\n",
      "2026-02-18 14:28:18,279 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1209.90it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1138.60it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:29:28,718 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1189, loss2=0.1514, dev_macro_f1=0.4657, dev_err=28.46%\n",
      "2026-02-18 14:30:38,033 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0288, loss2=0.1214, dev_macro_f1=0.5754, dev_err=26.86%\n",
      "2026-02-18 14:31:47,055 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0117, loss2=0.0994, dev_macro_f1=0.5830, dev_err=28.19%\n",
      "2026-02-18 14:32:56,008 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0057, loss2=0.0740, dev_macro_f1=0.5850, dev_err=28.59%\n",
      "2026-02-18 14:34:04,976 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0037, loss2=0.0510, dev_macro_f1=0.5832, dev_err=29.26%\n",
      "2026-02-18 14:35:14,026 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0040, loss2=0.0346, dev_macro_f1=0.5825, dev_err=27.39%\n",
      "2026-02-18 14:36:23,083 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0043, loss2=0.0298, dev_macro_f1=0.6056, dev_err=26.99%\n",
      "2026-02-18 14:37:32,123 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0073, loss2=0.0202, dev_macro_f1=0.5984, dev_err=26.60%\n",
      "2026-02-18 14:38:41,164 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0088, loss2=0.0238, dev_macro_f1=0.5973, dev_err=26.60%\n",
      "2026-02-18 14:39:50,257 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0064, loss2=0.0130, dev_macro_f1=0.5974, dev_err=27.26%\n",
      "2026-02-18 14:39:50,258 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 14:39:53,241 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5954, dev_err=27.66%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:39:56,205 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5937, dev_err=29.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:39:59,164 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5660, dev_err=34.04%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:40:02,131 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5795, dev_err=35.64%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 14:40:05,112 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6203, dev_err=33.11%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:08,092 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6366, dev_err=31.38%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:11,076 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6448, dev_err=29.92%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:14,053 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6466, dev_err=28.72%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:17,028 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6499, dev_err=28.46%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:19,990 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6464, dev_err=28.32%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:40:22,956 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6455, dev_err=28.19%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:40:25,935 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6603, dev_err=27.53%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:28,910 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6608, dev_err=27.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:40:31,873 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6583, dev_err=27.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:40:34,836 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6571, dev_err=27.79%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:40:37,804 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6526, dev_err=28.32%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 14:40:40,770 - lg_cotrain - INFO - Phase 3 epoch 17: dev_macro_f1=0.6573, dev_err=28.06%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 14:40:43,736 - lg_cotrain - INFO - Phase 3 epoch 18: dev_macro_f1=0.6578, dev_err=27.93%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 14:40:43,737 - lg_cotrain - INFO - Early stopping at epoch 18\n",
      "2026-02-18 14:40:43,745 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 14:40:50,992 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\10_set2\\metrics.json\n",
      "2026-02-18 14:40:50,993 - lg_cotrain - INFO - Test error rate: 28.54%, Test macro-F1: 0.6440, Test ECE: 0.0597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/12] budget=10, seed=2 -- done (macro_f1=0.6440)\n",
      "[PROGRESS] 5/120 (4.2%) | Elapsed: 1.23h | ETA: 28.39h\n",
      "[6/12] budget=10, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 14:40:51,520 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=10, seed_set=3\n",
      "2026-02-18 14:40:51,569 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 14:40:51,579 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 5063\n",
      "2026-02-18 14:40:51,580 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1187.39it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1175.77it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:41:10,327 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1066, mean_prob2=0.1009\n",
      "2026-02-18 14:41:27,978 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1059, mean_prob2=0.1178\n",
      "2026-02-18 14:41:45,652 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1058, mean_prob2=0.1195\n",
      "2026-02-18 14:42:03,342 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1055, mean_prob2=0.1198\n",
      "2026-02-18 14:42:21,025 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1064, mean_prob2=0.1198\n",
      "2026-02-18 14:42:38,678 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1081, mean_prob2=0.1207\n",
      "2026-02-18 14:42:56,358 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1064, mean_prob2=0.1242\n",
      "2026-02-18 14:42:56,360 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1141, range=[0.0641, 0.2553]\n",
      "2026-02-18 14:42:56,360 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1028, range=[0.0295, 0.2521]\n",
      "2026-02-18 14:42:56,361 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1208.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1167.35it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:44:06,506 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1283, loss2=0.1494, dev_macro_f1=0.4383, dev_err=30.19%\n",
      "2026-02-18 14:45:15,470 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0340, loss2=0.1091, dev_macro_f1=0.6009, dev_err=26.06%\n",
      "2026-02-18 14:46:24,379 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0139, loss2=0.0885, dev_macro_f1=0.6130, dev_err=25.27%\n",
      "2026-02-18 14:47:33,312 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0056, loss2=0.0650, dev_macro_f1=0.6266, dev_err=26.46%\n",
      "2026-02-18 14:48:42,320 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0038, loss2=0.0433, dev_macro_f1=0.6061, dev_err=26.46%\n",
      "2026-02-18 14:49:51,405 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0047, loss2=0.0297, dev_macro_f1=0.6091, dev_err=26.20%\n",
      "2026-02-18 14:51:00,488 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0055, loss2=0.0229, dev_macro_f1=0.5880, dev_err=27.39%\n",
      "2026-02-18 14:52:09,583 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0076, loss2=0.0179, dev_macro_f1=0.6121, dev_err=26.86%\n",
      "2026-02-18 14:53:18,666 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0088, loss2=0.0146, dev_macro_f1=0.6020, dev_err=26.46%\n",
      "2026-02-18 14:54:27,753 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0088, loss2=0.0126, dev_macro_f1=0.6122, dev_err=25.80%\n",
      "2026-02-18 14:54:27,755 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 14:54:30,733 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5872, dev_err=28.72%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:54:33,715 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5945, dev_err=33.11%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:54:36,678 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5922, dev_err=34.04%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:54:39,652 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6113, dev_err=32.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:54:42,633 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6394, dev_err=29.65%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:54:45,606 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6406, dev_err=29.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 14:54:48,567 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6207, dev_err=29.79%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 14:54:51,530 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6206, dev_err=28.99%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 14:54:54,504 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6283, dev_err=28.59%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 14:54:57,461 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6237, dev_err=28.72%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 14:55:00,429 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6251, dev_err=28.86%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 14:55:00,429 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 14:55:00,438 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 14:55:07,683 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\10_set3\\metrics.json\n",
      "2026-02-18 14:55:07,683 - lg_cotrain - INFO - Test error rate: 29.77%, Test macro-F1: 0.6125, Test ECE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/12] budget=10, seed=3 -- done (macro_f1=0.6125)\n",
      "[PROGRESS] 6/120 (5.0%) | Elapsed: 1.47h | ETA: 27.97h\n",
      "[7/12] budget=25, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 14:55:08,220 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=1\n",
      "2026-02-18 14:55:08,262 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 14:55:08,270 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-18 14:55:08,270 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1247.00it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1189.34it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:55:27,230 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1076, mean_prob2=0.1029\n",
      "2026-02-18 14:55:45,109 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1097, mean_prob2=0.1024\n",
      "2026-02-18 14:56:03,015 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1092, mean_prob2=0.1119\n",
      "2026-02-18 14:56:20,893 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1100, mean_prob2=0.1164\n",
      "2026-02-18 14:56:38,812 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1105, mean_prob2=0.1208\n",
      "2026-02-18 14:56:56,712 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1118, mean_prob2=0.1223\n",
      "2026-02-18 14:57:14,618 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1123, mean_prob2=0.1237\n",
      "2026-02-18 14:57:14,619 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1214, range=[0.0484, 0.2410]\n",
      "2026-02-18 14:57:14,620 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0966, range=[0.0150, 0.2711]\n",
      "2026-02-18 14:57:14,620 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1210.34it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1188.24it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 14:58:22,800 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1185, loss2=0.1472, dev_macro_f1=0.4071, dev_err=31.38%\n",
      "2026-02-18 14:59:29,738 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0319, loss2=0.1074, dev_macro_f1=0.5362, dev_err=28.06%\n",
      "2026-02-18 15:00:36,681 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0115, loss2=0.0954, dev_macro_f1=0.5696, dev_err=27.26%\n",
      "2026-02-18 15:01:43,769 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0061, loss2=0.0718, dev_macro_f1=0.6143, dev_err=25.80%\n",
      "2026-02-18 15:02:50,810 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0051, loss2=0.0480, dev_macro_f1=0.5964, dev_err=26.46%\n",
      "2026-02-18 15:03:57,905 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0056, loss2=0.0350, dev_macro_f1=0.5978, dev_err=26.60%\n",
      "2026-02-18 15:05:04,983 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0053, loss2=0.0282, dev_macro_f1=0.6047, dev_err=26.33%\n",
      "2026-02-18 15:06:12,112 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0055, loss2=0.0248, dev_macro_f1=0.5820, dev_err=27.39%\n",
      "2026-02-18 15:07:19,213 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0091, loss2=0.0226, dev_macro_f1=0.5971, dev_err=27.13%\n",
      "2026-02-18 15:08:26,333 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0081, loss2=0.0157, dev_macro_f1=0.6030, dev_err=26.86%\n",
      "2026-02-18 15:08:26,333 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 15:08:30,036 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5841, dev_err=34.18%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:08:33,730 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5672, dev_err=38.16%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:08:37,445 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6125, dev_err=30.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:08:41,152 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6195, dev_err=29.52%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:08:44,846 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6130, dev_err=29.65%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:08:48,548 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5947, dev_err=31.38%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 15:08:52,245 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6154, dev_err=30.32%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 15:08:55,926 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6080, dev_err=31.12%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 15:08:59,631 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6089, dev_err=31.25%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 15:08:59,631 - lg_cotrain - INFO - Early stopping at epoch 9\n",
      "2026-02-18 15:08:59,642 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 15:09:06,894 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\25_set1\\metrics.json\n",
      "2026-02-18 15:09:06,895 - lg_cotrain - INFO - Test error rate: 27.79%, Test macro-F1: 0.6596, Test ECE: 0.0528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/12] budget=25, seed=1 -- done (macro_f1=0.6596)\n",
      "[PROGRESS] 7/120 (5.8%) | Elapsed: 1.71h | ETA: 27.53h\n",
      "[8/12] budget=25, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 15:09:07,455 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=2\n",
      "2026-02-18 15:09:07,508 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 15:09:07,516 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-18 15:09:07,521 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1202.28it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1182.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:09:26,466 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1022, mean_prob2=0.1015\n",
      "2026-02-18 15:09:44,348 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1104, mean_prob2=0.1056\n",
      "2026-02-18 15:10:02,206 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1143, mean_prob2=0.1070\n",
      "2026-02-18 15:10:20,067 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1177, mean_prob2=0.1108\n",
      "2026-02-18 15:10:37,929 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1178, mean_prob2=0.1167\n",
      "2026-02-18 15:10:55,835 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1224, mean_prob2=0.1223\n",
      "2026-02-18 15:11:13,707 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1315, mean_prob2=0.1281\n",
      "2026-02-18 15:11:13,707 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1355, range=[0.0445, 0.2410]\n",
      "2026-02-18 15:11:13,707 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0968, range=[0.0259, 0.1836]\n",
      "2026-02-18 15:11:13,707 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1310.31it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1197.16it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:12:21,887 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1178, loss2=0.1701, dev_macro_f1=0.4459, dev_err=29.65%\n",
      "2026-02-18 15:13:28,894 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0315, loss2=0.1256, dev_macro_f1=0.5945, dev_err=25.13%\n",
      "2026-02-18 15:14:35,825 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0117, loss2=0.1000, dev_macro_f1=0.6064, dev_err=28.32%\n",
      "2026-02-18 15:15:42,770 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0052, loss2=0.0748, dev_macro_f1=0.6103, dev_err=26.73%\n",
      "2026-02-18 15:16:49,780 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0040, loss2=0.0559, dev_macro_f1=0.5689, dev_err=30.05%\n",
      "2026-02-18 15:17:56,854 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0039, loss2=0.0401, dev_macro_f1=0.5931, dev_err=26.73%\n",
      "2026-02-18 15:19:03,935 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0051, loss2=0.0331, dev_macro_f1=0.5887, dev_err=27.79%\n",
      "2026-02-18 15:20:11,066 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0068, loss2=0.0176, dev_macro_f1=0.6070, dev_err=26.60%\n",
      "2026-02-18 15:21:18,198 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0076, loss2=0.0199, dev_macro_f1=0.5922, dev_err=27.53%\n",
      "2026-02-18 15:22:25,311 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0081, loss2=0.0133, dev_macro_f1=0.5923, dev_err=26.99%\n",
      "2026-02-18 15:22:25,312 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 15:22:29,018 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5885, dev_err=33.24%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:32,709 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5021, dev_err=46.01%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:22:36,419 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5949, dev_err=34.57%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:40,128 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5970, dev_err=34.04%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:43,823 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5965, dev_err=33.24%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:22:47,534 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6062, dev_err=32.58%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:51,239 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6159, dev_err=32.18%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:54,941 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6340, dev_err=30.19%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:22:58,645 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6329, dev_err=29.65%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:23:02,352 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6346, dev_err=29.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:23:06,060 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6353, dev_err=29.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:23:09,754 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6343, dev_err=29.12%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:23:13,440 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6320, dev_err=29.26%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 15:23:17,135 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6286, dev_err=29.26%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 15:23:20,827 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6190, dev_err=30.19%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 15:23:24,527 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6153, dev_err=30.45%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 15:23:24,528 - lg_cotrain - INFO - Early stopping at epoch 16\n",
      "2026-02-18 15:23:24,539 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 15:23:31,780 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\25_set2\\metrics.json\n",
      "2026-02-18 15:23:31,781 - lg_cotrain - INFO - Test error rate: 28.06%, Test macro-F1: 0.6554, Test ECE: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/12] budget=25, seed=2 -- done (macro_f1=0.6554)\n",
      "[PROGRESS] 8/120 (6.7%) | Elapsed: 1.95h | ETA: 27.24h\n",
      "[9/12] budget=25, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 15:23:32,395 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=25, seed_set=3\n",
      "2026-02-18 15:23:32,440 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 15:23:32,450 - lg_cotrain - INFO - D_l1: 130, D_l2: 120, D_LG: 4913\n",
      "2026-02-18 15:23:32,453 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1056.38it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1168.84it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:23:51,506 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1079, mean_prob2=0.1198\n",
      "2026-02-18 15:24:09,361 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1113, mean_prob2=0.1233\n",
      "2026-02-18 15:24:27,215 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1151, mean_prob2=0.1187\n",
      "2026-02-18 15:24:45,069 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1162, mean_prob2=0.1180\n",
      "2026-02-18 15:25:02,968 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1152, mean_prob2=0.1197\n",
      "2026-02-18 15:25:20,816 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1139, mean_prob2=0.1267\n",
      "2026-02-18 15:25:38,694 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1210, mean_prob2=0.1364\n",
      "2026-02-18 15:25:38,695 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1297, range=[0.0662, 0.2515]\n",
      "2026-02-18 15:25:38,695 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1071, range=[0.0096, 0.2609]\n",
      "2026-02-18 15:25:38,696 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1215.03it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1147.20it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:26:46,871 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1283, loss2=0.1586, dev_macro_f1=0.4254, dev_err=31.25%\n",
      "2026-02-18 15:27:53,870 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0341, loss2=0.1101, dev_macro_f1=0.5919, dev_err=26.06%\n",
      "2026-02-18 15:29:00,791 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0143, loss2=0.0848, dev_macro_f1=0.5877, dev_err=26.33%\n",
      "2026-02-18 15:30:07,669 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0057, loss2=0.0619, dev_macro_f1=0.6224, dev_err=27.66%\n",
      "2026-02-18 15:31:14,612 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0043, loss2=0.0479, dev_macro_f1=0.6176, dev_err=26.20%\n",
      "2026-02-18 15:32:21,674 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0055, loss2=0.0339, dev_macro_f1=0.5879, dev_err=27.39%\n",
      "2026-02-18 15:33:28,725 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0053, loss2=0.0232, dev_macro_f1=0.5796, dev_err=28.46%\n",
      "2026-02-18 15:34:35,768 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0066, loss2=0.0188, dev_macro_f1=0.6044, dev_err=26.33%\n",
      "2026-02-18 15:35:42,827 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0095, loss2=0.0164, dev_macro_f1=0.6044, dev_err=28.06%\n",
      "2026-02-18 15:36:49,885 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0068, loss2=0.0130, dev_macro_f1=0.6029, dev_err=27.53%\n",
      "2026-02-18 15:36:49,886 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 15:36:53,600 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5502, dev_err=39.63%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:36:57,302 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6250, dev_err=31.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:37:01,009 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6353, dev_err=29.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:37:04,711 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6274, dev_err=29.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:37:08,406 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6231, dev_err=29.39%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 15:37:12,111 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6475, dev_err=28.46%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:37:15,803 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6424, dev_err=29.52%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:37:19,496 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6390, dev_err=29.65%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 15:37:23,184 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6425, dev_err=29.79%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 15:37:26,888 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6413, dev_err=30.19%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 15:37:30,581 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6438, dev_err=30.05%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 15:37:30,581 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 15:37:30,589 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 15:37:37,837 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\25_set3\\metrics.json\n",
      "2026-02-18 15:37:37,837 - lg_cotrain - INFO - Test error rate: 27.38%, Test macro-F1: 0.6418, Test ECE: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/12] budget=25, seed=3 -- done (macro_f1=0.6418)\n",
      "[PROGRESS] 9/120 (7.5%) | Elapsed: 2.18h | ETA: 26.90h\n",
      "[10/12] budget=50, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 15:37:38,363 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=50, seed_set=1\n",
      "2026-02-18 15:37:38,416 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 15:37:38,426 - lg_cotrain - INFO - D_l1: 250, D_l2: 250, D_LG: 4663\n",
      "2026-02-18 15:37:38,428 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1164.94it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1286.11it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:37:57,719 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1094, mean_prob2=0.0976\n",
      "2026-02-18 15:38:15,918 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1068, mean_prob2=0.1102\n",
      "2026-02-18 15:38:34,103 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1159, mean_prob2=0.1240\n",
      "2026-02-18 15:38:52,302 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1228, mean_prob2=0.1372\n",
      "2026-02-18 15:39:10,508 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1356, mean_prob2=0.1524\n",
      "2026-02-18 15:39:28,713 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1455, mean_prob2=0.1813\n",
      "2026-02-18 15:39:46,919 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1601, mean_prob2=0.2031\n",
      "2026-02-18 15:39:46,920 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1555, range=[0.0491, 0.3370]\n",
      "2026-02-18 15:39:46,921 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1002, range=[0.0098, 0.2398]\n",
      "2026-02-18 15:39:46,921 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1295.76it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1166.59it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:40:51,728 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1184, loss2=0.1841, dev_macro_f1=0.4107, dev_err=31.25%\n",
      "2026-02-18 15:41:55,417 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0350, loss2=0.1152, dev_macro_f1=0.5351, dev_err=27.13%\n",
      "2026-02-18 15:42:59,080 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0144, loss2=0.0960, dev_macro_f1=0.5757, dev_err=25.80%\n",
      "2026-02-18 15:44:02,777 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0081, loss2=0.0665, dev_macro_f1=0.5930, dev_err=27.66%\n",
      "2026-02-18 15:45:06,512 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0061, loss2=0.0610, dev_macro_f1=0.5833, dev_err=26.99%\n",
      "2026-02-18 15:46:10,248 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0047, loss2=0.0436, dev_macro_f1=0.5889, dev_err=27.39%\n",
      "2026-02-18 15:47:14,023 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0054, loss2=0.0299, dev_macro_f1=0.5944, dev_err=26.60%\n",
      "2026-02-18 15:48:17,799 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0075, loss2=0.0212, dev_macro_f1=0.5881, dev_err=27.93%\n",
      "2026-02-18 15:49:21,560 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0074, loss2=0.0244, dev_macro_f1=0.5868, dev_err=27.53%\n",
      "2026-02-18 15:50:25,304 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0061, loss2=0.0207, dev_macro_f1=0.5936, dev_err=26.20%\n",
      "2026-02-18 15:50:25,304 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 15:50:30,196 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5138, dev_err=47.61%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:35,084 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6038, dev_err=32.58%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:39,969 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6235, dev_err=31.38%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:44,871 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6237, dev_err=31.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:49,752 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6335, dev_err=31.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:54,653 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6367, dev_err=30.85%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 15:50:59,521 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6303, dev_err=30.98%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 15:51:04,402 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6307, dev_err=30.05%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 15:51:09,278 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6269, dev_err=31.12%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 15:51:14,153 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6209, dev_err=31.52%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 15:51:19,028 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6221, dev_err=31.52%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 15:51:19,029 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 15:51:19,040 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 15:51:26,276 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\50_set1\\metrics.json\n",
      "2026-02-18 15:51:26,284 - lg_cotrain - INFO - Test error rate: 29.91%, Test macro-F1: 0.6379, Test ECE: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/12] budget=50, seed=1 -- done (macro_f1=0.6379)\n",
      "[PROGRESS] 10/120 (8.3%) | Elapsed: 2.41h | ETA: 26.52h\n",
      "[11/12] budget=50, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 15:51:26,826 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=50, seed_set=2\n",
      "2026-02-18 15:51:26,876 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 15:51:26,885 - lg_cotrain - INFO - D_l1: 250, D_l2: 250, D_LG: 4663\n",
      "2026-02-18 15:51:26,887 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1243.79it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1249.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:51:46,145 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1000, mean_prob2=0.1068\n",
      "2026-02-18 15:52:04,335 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1132, mean_prob2=0.1181\n",
      "2026-02-18 15:52:22,532 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1219, mean_prob2=0.1315\n",
      "2026-02-18 15:52:40,866 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1330, mean_prob2=0.1477\n",
      "2026-02-18 15:52:59,082 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1443, mean_prob2=0.1621\n",
      "2026-02-18 15:53:17,271 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1604, mean_prob2=0.1785\n",
      "2026-02-18 15:53:35,469 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1759, mean_prob2=0.1826\n",
      "2026-02-18 15:53:35,471 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1702, range=[0.0478, 0.2996]\n",
      "2026-02-18 15:53:35,471 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1104, range=[0.0083, 0.2163]\n",
      "2026-02-18 15:53:35,471 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1181.00it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1260.77it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 15:54:40,399 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1260, loss2=0.1997, dev_macro_f1=0.4245, dev_err=30.98%\n",
      "2026-02-18 15:55:44,055 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0349, loss2=0.1333, dev_macro_f1=0.5579, dev_err=26.46%\n",
      "2026-02-18 15:56:47,658 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0155, loss2=0.1049, dev_macro_f1=0.5857, dev_err=26.86%\n",
      "2026-02-18 15:57:51,310 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0084, loss2=0.0795, dev_macro_f1=0.5928, dev_err=27.66%\n",
      "2026-02-18 15:58:54,972 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0052, loss2=0.0556, dev_macro_f1=0.5999, dev_err=26.33%\n",
      "2026-02-18 15:59:58,641 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0043, loss2=0.0491, dev_macro_f1=0.5963, dev_err=26.86%\n",
      "2026-02-18 16:01:02,316 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0057, loss2=0.0382, dev_macro_f1=0.5943, dev_err=26.20%\n",
      "2026-02-18 16:02:06,020 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0054, loss2=0.0243, dev_macro_f1=0.6023, dev_err=26.20%\n",
      "2026-02-18 16:03:09,726 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0065, loss2=0.0194, dev_macro_f1=0.6008, dev_err=26.20%\n",
      "2026-02-18 16:04:13,413 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0094, loss2=0.0278, dev_macro_f1=0.6028, dev_err=26.60%\n",
      "2026-02-18 16:04:13,413 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:04:18,304 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4688, dev_err=48.40%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:04:23,184 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6608, dev_err=27.13%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:04:28,058 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6195, dev_err=28.46%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:04:32,927 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6279, dev_err=30.32%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:04:37,799 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6461, dev_err=28.32%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:04:42,685 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6646, dev_err=26.60%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:04:47,558 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6373, dev_err=29.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:04:52,429 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6365, dev_err=29.52%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:04:57,305 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6378, dev_err=29.39%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:05:02,179 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6421, dev_err=28.59%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:05:07,058 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6357, dev_err=28.19%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:05:07,059 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 16:05:07,069 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:05:14,306 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\50_set2\\metrics.json\n",
      "2026-02-18 16:05:14,306 - lg_cotrain - INFO - Test error rate: 26.76%, Test macro-F1: 0.6578, Test ECE: 0.0888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/12] budget=50, seed=2 -- done (macro_f1=0.6578)\n",
      "[PROGRESS] 11/120 (9.2%) | Elapsed: 2.64h | ETA: 26.17h\n",
      "[12/12] budget=50, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:05:14,856 - lg_cotrain - INFO - Starting LG-CoTrain: event=california_wildfires_2018, budget=50, seed_set=3\n",
      "2026-02-18 16:05:14,900 - lg_cotrain - INFO - Detected 10 classes for event california_wildfires_2018: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:05:14,911 - lg_cotrain - INFO - D_l1: 250, D_l2: 250, D_LG: 4663\n",
      "2026-02-18 16:05:14,911 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1147.85it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1155.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:05:34,349 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1073, mean_prob2=0.1242\n",
      "2026-02-18 16:05:52,533 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1108, mean_prob2=0.1194\n",
      "2026-02-18 16:06:10,721 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1106, mean_prob2=0.1329\n",
      "2026-02-18 16:06:28,912 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1286, mean_prob2=0.1457\n",
      "2026-02-18 16:06:47,116 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1383, mean_prob2=0.1622\n",
      "2026-02-18 16:07:05,330 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1485, mean_prob2=0.1642\n",
      "2026-02-18 16:07:23,526 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1608, mean_prob2=0.1980\n",
      "2026-02-18 16:07:23,527 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1560, range=[0.0610, 0.3561]\n",
      "2026-02-18 16:07:23,528 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1162, range=[0.0041, 0.2512]\n",
      "2026-02-18 16:07:23,528 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1109.11it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1156.84it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:08:28,410 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1348, loss2=0.1846, dev_macro_f1=0.4068, dev_err=32.45%\n",
      "2026-02-18 16:09:33,334 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0427, loss2=0.1204, dev_macro_f1=0.5247, dev_err=27.53%\n",
      "2026-02-18 16:10:38,054 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0176, loss2=0.0910, dev_macro_f1=0.5764, dev_err=24.87%\n",
      "2026-02-18 16:11:42,612 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0092, loss2=0.0677, dev_macro_f1=0.6218, dev_err=25.00%\n",
      "2026-02-18 16:12:46,953 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0060, loss2=0.0518, dev_macro_f1=0.6136, dev_err=25.80%\n",
      "2026-02-18 16:13:51,411 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0051, loss2=0.0383, dev_macro_f1=0.6153, dev_err=25.93%\n",
      "2026-02-18 16:14:55,681 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0052, loss2=0.0290, dev_macro_f1=0.5882, dev_err=27.13%\n",
      "2026-02-18 16:16:00,167 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0071, loss2=0.0188, dev_macro_f1=0.6071, dev_err=26.99%\n",
      "2026-02-18 16:17:05,950 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0066, loss2=0.0137, dev_macro_f1=0.5937, dev_err=27.93%\n",
      "2026-02-18 16:18:12,105 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0091, loss2=0.0146, dev_macro_f1=0.5908, dev_err=28.19%\n",
      "2026-02-18 16:18:12,105 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:18:17,179 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4782, dev_err=49.34%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:18:22,245 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.6144, dev_err=30.98%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:18:27,303 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5924, dev_err=32.05%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:18:32,362 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6371, dev_err=29.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:18:37,412 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6283, dev_err=29.12%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:18:42,440 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6359, dev_err=30.59%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:18:47,489 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6268, dev_err=31.12%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:18:52,549 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6450, dev_err=29.52%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:18:57,620 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6468, dev_err=29.26%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:19:02,692 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6504, dev_err=28.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:19:07,766 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6525, dev_err=28.59%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:19:12,834 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6528, dev_err=28.59%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:19:17,967 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6507, dev_err=28.86%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:19:23,143 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6494, dev_err=28.99%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:19:28,108 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6499, dev_err=28.86%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:19:33,057 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6510, dev_err=28.72%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:19:37,997 - lg_cotrain - INFO - Phase 3 epoch 17: dev_macro_f1=0.6500, dev_err=28.86%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:19:37,998 - lg_cotrain - INFO - Early stopping at epoch 17\n",
      "2026-02-18 16:19:38,010 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:19:45,387 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\california_wildfires_2018\\50_set3\\metrics.json\n",
      "2026-02-18 16:19:45,387 - lg_cotrain - INFO - Test error rate: 28.75%, Test macro-F1: 0.6349, Test ECE: 0.1294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/12] budget=50, seed=3 -- done (macro_f1=0.6349)\n",
      "[PROGRESS] 12/120 (10.0%) | Elapsed: 2.88h | ETA: 25.94h\n",
      "\n",
      "Batch complete: 12 ran, 0 skipped, 0 failed (10373.9s total)\n",
      "\n",
      "=== Results for california_wildfires_2018 ===\n",
      "\n",
      "Budget    Seed 1              Seed 2              Seed 3                  Mean       Std\n",
      "           ErrR%  MacF1   ErrR%  MacF1   ErrR%  MacF1     ErrR%     MacF1\n",
      "-------------------------------------------------------------------------\n",
      "     5     26.90 0.6405   28.54 0.6377   27.58 0.6231  27.68+/-0.83   0.6338+/-0.0093\n",
      "    10     27.24 0.6291   28.54 0.6440   29.77 0.6125  28.52+/-1.27   0.6286+/-0.0158\n",
      "    25     27.79 0.6596   28.06 0.6554   27.38 0.6418  27.74+/-0.34   0.6522+/-0.0093\n",
      "    50     29.91 0.6379   26.76 0.6578   28.75 0.6349  28.47+/-1.59   0.6435+/-0.0124\n",
      "\n",
      "============================================================\n",
      "Event 2/10: canada_wildfires_2016\n",
      "============================================================\n",
      "[1/12] budget=5, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:19:45,948 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=5, seed_set=1\n",
      "2026-02-18 16:19:46,006 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:19:46,011 - lg_cotrain - INFO - D_l1: 24, D_l2: 16, D_LG: 1529\n",
      "2026-02-18 16:19:46,012 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1063.32it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1005.63it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:19:52,787 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1048, mean_prob2=0.1358\n",
      "2026-02-18 16:19:58,273 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1074, mean_prob2=0.1344\n",
      "2026-02-18 16:20:03,785 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1101, mean_prob2=0.1304\n",
      "2026-02-18 16:20:09,294 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1136, mean_prob2=0.1308\n",
      "2026-02-18 16:20:14,851 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1180, mean_prob2=0.1304\n",
      "2026-02-18 16:20:20,317 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1218, mean_prob2=0.1291\n",
      "2026-02-18 16:20:25,836 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1258, mean_prob2=0.1276\n",
      "2026-02-18 16:20:25,837 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1296, range=[0.0630, 0.2538]\n",
      "2026-02-18 16:20:25,838 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1173, range=[0.0267, 0.2920]\n",
      "2026-02-18 16:20:25,838 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 996.64it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1074.29it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:20:48,180 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1768, loss2=0.2153, dev_macro_f1=0.3042, dev_err=34.21%\n",
      "2026-02-18 16:21:09,814 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0838, loss2=0.1770, dev_macro_f1=0.4377, dev_err=27.19%\n",
      "2026-02-18 16:21:31,325 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0393, loss2=0.1228, dev_macro_f1=0.5114, dev_err=22.81%\n",
      "2026-02-18 16:21:52,327 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0206, loss2=0.0941, dev_macro_f1=0.5149, dev_err=24.56%\n",
      "2026-02-18 16:22:13,410 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0124, loss2=0.0678, dev_macro_f1=0.5312, dev_err=23.68%\n",
      "2026-02-18 16:22:34,910 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0089, loss2=0.0446, dev_macro_f1=0.5363, dev_err=24.12%\n",
      "2026-02-18 16:22:56,432 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0065, loss2=0.0267, dev_macro_f1=0.5252, dev_err=24.12%\n",
      "2026-02-18 16:23:18,466 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0052, loss2=0.0241, dev_macro_f1=0.5204, dev_err=24.56%\n",
      "2026-02-18 16:23:41,677 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0048, loss2=0.0153, dev_macro_f1=0.5589, dev_err=22.37%\n",
      "2026-02-18 16:24:04,912 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0062, loss2=0.0486, dev_macro_f1=0.5346, dev_err=23.68%\n",
      "2026-02-18 16:24:04,912 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:24:05,992 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5284, dev_err=24.56%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:24:07,054 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5101, dev_err=26.75%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:24:08,124 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5054, dev_err=26.75%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:24:09,201 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4979, dev_err=26.32%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:24:10,264 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5073, dev_err=25.00%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:24:11,330 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5280, dev_err=25.44%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:24:11,330 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 16:24:11,344 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:24:13,801 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\5_set1\\metrics.json\n",
      "2026-02-18 16:24:13,802 - lg_cotrain - INFO - Test error rate: 22.70%, Test macro-F1: 0.5683, Test ECE: 0.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- done (macro_f1=0.5683)\n",
      "[PROGRESS] 13/120 (10.8%) | Elapsed: 2.96h | ETA: 24.34h\n",
      "[2/12] budget=5, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:24:14,344 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=5, seed_set=2\n",
      "2026-02-18 16:24:14,375 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:24:14,380 - lg_cotrain - INFO - D_l1: 24, D_l2: 16, D_LG: 1529\n",
      "2026-02-18 16:24:14,380 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1042.84it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 961.99it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:24:21,504 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1398, mean_prob2=0.1292\n",
      "2026-02-18 16:24:27,234 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1412, mean_prob2=0.1312\n",
      "2026-02-18 16:24:32,899 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1391, mean_prob2=0.1344\n",
      "2026-02-18 16:24:38,587 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1340, mean_prob2=0.1382\n",
      "2026-02-18 16:24:44,283 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1296, mean_prob2=0.1418\n",
      "2026-02-18 16:24:49,968 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1235, mean_prob2=0.1446\n",
      "2026-02-18 16:24:55,630 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1255, mean_prob2=0.1462\n",
      "2026-02-18 16:24:55,631 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1532, range=[0.0860, 0.2188]\n",
      "2026-02-18 16:24:55,632 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1271, range=[0.0409, 0.2371]\n",
      "2026-02-18 16:24:55,632 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1098.29it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1013.74it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:25:18,816 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1874, loss2=0.2436, dev_macro_f1=0.1785, dev_err=42.98%\n",
      "2026-02-18 16:25:40,631 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0874, loss2=0.2074, dev_macro_f1=0.4849, dev_err=24.12%\n",
      "2026-02-18 16:26:02,677 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0421, loss2=0.1315, dev_macro_f1=0.5047, dev_err=21.93%\n",
      "2026-02-18 16:26:25,081 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0228, loss2=0.0912, dev_macro_f1=0.5311, dev_err=23.25%\n",
      "2026-02-18 16:26:47,383 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0147, loss2=0.0823, dev_macro_f1=0.5406, dev_err=23.25%\n",
      "2026-02-18 16:27:09,593 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0100, loss2=0.0523, dev_macro_f1=0.4964, dev_err=26.75%\n",
      "2026-02-18 16:27:31,547 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0071, loss2=0.0353, dev_macro_f1=0.5383, dev_err=24.56%\n",
      "2026-02-18 16:27:53,467 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0062, loss2=0.0345, dev_macro_f1=0.5259, dev_err=24.56%\n",
      "2026-02-18 16:28:15,386 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0055, loss2=0.0217, dev_macro_f1=0.5363, dev_err=24.12%\n",
      "2026-02-18 16:28:37,353 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0085, loss2=0.0132, dev_macro_f1=0.5157, dev_err=25.00%\n",
      "2026-02-18 16:28:37,354 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:28:38,379 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5149, dev_err=26.32%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:28:39,525 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5623, dev_err=23.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:28:40,531 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5533, dev_err=24.56%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:28:41,554 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5806, dev_err=28.95%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:28:42,570 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5880, dev_err=30.70%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:28:43,590 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6098, dev_err=29.39%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:28:44,590 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5957, dev_err=29.82%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:28:45,598 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5971, dev_err=29.39%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:28:46,616 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.5917, dev_err=28.95%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:28:47,633 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6087, dev_err=27.63%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:28:48,654 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.5967, dev_err=28.07%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:28:48,655 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 16:28:48,663 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:28:50,884 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\5_set2\\metrics.json\n",
      "2026-02-18 16:28:50,885 - lg_cotrain - INFO - Test error rate: 31.91%, Test macro-F1: 0.5202, Test ECE: 0.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/12] budget=5, seed=2 -- done (macro_f1=0.5202)\n",
      "[PROGRESS] 14/120 (11.7%) | Elapsed: 3.03h | ETA: 22.97h\n",
      "[3/12] budget=5, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:28:51,436 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=5, seed_set=3\n",
      "2026-02-18 16:28:51,463 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:28:51,467 - lg_cotrain - INFO - D_l1: 24, D_l2: 16, D_LG: 1529\n",
      "2026-02-18 16:28:51,468 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1159.62it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1133.46it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:28:58,021 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1292, mean_prob2=0.1199\n",
      "2026-02-18 16:29:03,698 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1298, mean_prob2=0.1166\n",
      "2026-02-18 16:29:09,364 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1292, mean_prob2=0.1153\n",
      "2026-02-18 16:29:14,940 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1305, mean_prob2=0.1164\n",
      "2026-02-18 16:29:20,396 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1323, mean_prob2=0.1180\n",
      "2026-02-18 16:29:25,958 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1357, mean_prob2=0.1240\n",
      "2026-02-18 16:29:31,376 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1403, mean_prob2=0.1323\n",
      "2026-02-18 16:29:31,377 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1453, range=[0.0577, 0.2060]\n",
      "2026-02-18 16:29:31,378 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1093, range=[0.0628, 0.1866]\n",
      "2026-02-18 16:29:31,379 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1005.24it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1047.54it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:29:53,965 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1764, loss2=0.2290, dev_macro_f1=0.3090, dev_err=34.21%\n",
      "2026-02-18 16:30:15,309 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0817, loss2=0.1651, dev_macro_f1=0.4177, dev_err=28.07%\n",
      "2026-02-18 16:30:36,648 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0389, loss2=0.1307, dev_macro_f1=0.4946, dev_err=23.68%\n",
      "2026-02-18 16:30:57,927 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0206, loss2=0.0920, dev_macro_f1=0.4992, dev_err=23.68%\n",
      "2026-02-18 16:31:19,738 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0130, loss2=0.0776, dev_macro_f1=0.5832, dev_err=20.61%\n",
      "2026-02-18 16:31:41,152 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0119, loss2=0.0560, dev_macro_f1=0.5519, dev_err=22.37%\n",
      "2026-02-18 16:32:02,335 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0089, loss2=0.0390, dev_macro_f1=0.5532, dev_err=23.25%\n",
      "2026-02-18 16:32:23,491 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0071, loss2=0.0227, dev_macro_f1=0.5261, dev_err=24.12%\n",
      "2026-02-18 16:32:44,639 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0075, loss2=0.0133, dev_macro_f1=0.5610, dev_err=22.37%\n",
      "2026-02-18 16:33:05,900 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0069, loss2=0.0110, dev_macro_f1=0.5055, dev_err=25.88%\n",
      "2026-02-18 16:33:05,901 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:33:06,883 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5283, dev_err=25.00%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:07,868 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5303, dev_err=25.88%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:08,848 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5386, dev_err=24.56%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:09,827 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5664, dev_err=25.44%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:10,803 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5956, dev_err=24.56%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:11,764 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5707, dev_err=25.00%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:33:12,719 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5863, dev_err=25.88%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:33:13,697 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5968, dev_err=25.00%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:33:14,656 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.5813, dev_err=26.75%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:33:15,632 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.5801, dev_err=28.07%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:33:16,669 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.5900, dev_err=27.63%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:33:17,670 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.5933, dev_err=27.63%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:33:18,637 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.5761, dev_err=28.95%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:33:18,638 - lg_cotrain - INFO - Early stopping at epoch 13\n",
      "2026-02-18 16:33:18,647 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:33:20,926 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\5_set3\\metrics.json\n",
      "2026-02-18 16:33:20,927 - lg_cotrain - INFO - Test error rate: 26.29%, Test macro-F1: 0.5625, Test ECE: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/12] budget=5, seed=3 -- done (macro_f1=0.5625)\n",
      "[PROGRESS] 15/120 (12.5%) | Elapsed: 3.11h | ETA: 21.77h\n",
      "[4/12] budget=10, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:33:21,493 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=10, seed_set=1\n",
      "2026-02-18 16:33:21,526 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:33:21,532 - lg_cotrain - INFO - D_l1: 40, D_l2: 40, D_LG: 1489\n",
      "2026-02-18 16:33:21,533 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1133.13it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1077.62it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:33:28,219 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1075, mean_prob2=0.1384\n",
      "2026-02-18 16:33:33,769 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1128, mean_prob2=0.1365\n",
      "2026-02-18 16:33:39,379 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1155, mean_prob2=0.1334\n",
      "2026-02-18 16:33:44,974 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1153, mean_prob2=0.1300\n",
      "2026-02-18 16:33:50,435 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1163, mean_prob2=0.1263\n",
      "2026-02-18 16:33:56,147 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1209, mean_prob2=0.1246\n",
      "2026-02-18 16:34:01,751 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1305, mean_prob2=0.1263\n",
      "2026-02-18 16:34:01,752 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1302, range=[0.0609, 0.2540]\n",
      "2026-02-18 16:34:01,753 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1162, range=[0.0245, 0.2892]\n",
      "2026-02-18 16:34:01,753 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1156.50it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1143.70it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:34:23,766 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1806, loss2=0.2148, dev_macro_f1=0.3050, dev_err=34.65%\n",
      "2026-02-18 16:34:44,783 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0838, loss2=0.1753, dev_macro_f1=0.4660, dev_err=25.00%\n",
      "2026-02-18 16:35:05,610 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0375, loss2=0.1156, dev_macro_f1=0.5051, dev_err=23.68%\n",
      "2026-02-18 16:35:26,412 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0194, loss2=0.0858, dev_macro_f1=0.5208, dev_err=24.56%\n",
      "2026-02-18 16:35:47,476 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0111, loss2=0.0586, dev_macro_f1=0.5446, dev_err=23.68%\n",
      "2026-02-18 16:36:08,151 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0075, loss2=0.0430, dev_macro_f1=0.5472, dev_err=23.68%\n",
      "2026-02-18 16:36:28,969 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0056, loss2=0.0293, dev_macro_f1=0.5505, dev_err=22.81%\n",
      "2026-02-18 16:36:49,791 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0047, loss2=0.0389, dev_macro_f1=0.5456, dev_err=24.12%\n",
      "2026-02-18 16:37:10,275 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0064, loss2=0.0273, dev_macro_f1=0.5266, dev_err=25.44%\n",
      "2026-02-18 16:37:30,835 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0067, loss2=0.0173, dev_macro_f1=0.5486, dev_err=24.12%\n",
      "2026-02-18 16:37:30,835 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:37:32,035 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5254, dev_err=26.32%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:37:33,203 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5092, dev_err=27.63%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:37:34,388 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5182, dev_err=27.63%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:37:35,646 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5914, dev_err=26.75%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:37:36,835 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5884, dev_err=25.88%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:37:38,043 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6290, dev_err=25.88%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:37:39,209 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5900, dev_err=25.88%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:37:40,374 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6232, dev_err=24.12%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:37:41,557 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6401, dev_err=23.68%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:37:42,723 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6227, dev_err=24.12%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:37:43,890 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.5733, dev_err=25.88%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:37:45,056 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.5868, dev_err=25.44%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:37:46,233 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6125, dev_err=24.56%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:37:47,400 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6138, dev_err=23.68%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:37:47,401 - lg_cotrain - INFO - Early stopping at epoch 14\n",
      "2026-02-18 16:37:47,411 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:37:49,631 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\10_set1\\metrics.json\n",
      "2026-02-18 16:37:49,631 - lg_cotrain - INFO - Test error rate: 24.49%, Test macro-F1: 0.6029, Test ECE: 0.0656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/12] budget=10, seed=1 -- done (macro_f1=0.6029)\n",
      "[PROGRESS] 16/120 (13.3%) | Elapsed: 3.18h | ETA: 20.70h\n",
      "[5/12] budget=10, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:37:50,185 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=10, seed_set=2\n",
      "2026-02-18 16:37:50,212 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:37:50,217 - lg_cotrain - INFO - D_l1: 40, D_l2: 40, D_LG: 1489\n",
      "2026-02-18 16:37:50,219 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1161.52it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1156.27it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:37:56,781 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1304, mean_prob2=0.1303\n",
      "2026-02-18 16:38:02,373 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1331, mean_prob2=0.1307\n",
      "2026-02-18 16:38:07,978 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1376, mean_prob2=0.1355\n",
      "2026-02-18 16:38:13,642 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1420, mean_prob2=0.1410\n",
      "2026-02-18 16:38:19,159 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1393, mean_prob2=0.1451\n",
      "2026-02-18 16:38:24,723 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1380, mean_prob2=0.1471\n",
      "2026-02-18 16:38:30,342 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1362, mean_prob2=0.1481\n",
      "2026-02-18 16:38:30,343 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1509, range=[0.0728, 0.3004]\n",
      "2026-02-18 16:38:30,344 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1249, range=[0.0329, 0.2307]\n",
      "2026-02-18 16:38:30,344 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1134.58it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1197.19it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:38:52,973 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1856, loss2=0.2258, dev_macro_f1=0.1780, dev_err=43.42%\n",
      "2026-02-18 16:39:14,983 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0809, loss2=0.1864, dev_macro_f1=0.4412, dev_err=25.00%\n",
      "2026-02-18 16:39:37,567 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0379, loss2=0.1309, dev_macro_f1=0.5182, dev_err=21.93%\n",
      "2026-02-18 16:40:00,165 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0208, loss2=0.1038, dev_macro_f1=0.5030, dev_err=22.37%\n",
      "2026-02-18 16:40:22,303 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0127, loss2=0.0841, dev_macro_f1=0.5253, dev_err=24.12%\n",
      "2026-02-18 16:40:43,056 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0087, loss2=0.0641, dev_macro_f1=0.5247, dev_err=25.00%\n",
      "2026-02-18 16:41:03,817 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0067, loss2=0.0404, dev_macro_f1=0.5437, dev_err=23.68%\n",
      "2026-02-18 16:41:24,448 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0048, loss2=0.0358, dev_macro_f1=0.5248, dev_err=25.44%\n",
      "2026-02-18 16:41:45,052 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0044, loss2=0.0317, dev_macro_f1=0.5272, dev_err=23.25%\n",
      "2026-02-18 16:42:05,646 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0036, loss2=0.0284, dev_macro_f1=0.5477, dev_err=23.25%\n",
      "2026-02-18 16:42:05,646 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:42:06,848 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5749, dev_err=21.93%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:42:08,044 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5567, dev_err=23.68%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:42:09,269 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6346, dev_err=22.81%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:42:10,542 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6549, dev_err=21.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:42:11,832 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6613, dev_err=20.18%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:42:13,072 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6285, dev_err=21.05%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:42:14,305 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6132, dev_err=21.49%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:42:15,559 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6405, dev_err=21.93%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:42:16,791 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6242, dev_err=22.37%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:42:18,025 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6326, dev_err=22.37%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:42:18,026 - lg_cotrain - INFO - Early stopping at epoch 10\n",
      "2026-02-18 16:42:18,041 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:42:20,435 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\10_set2\\metrics.json\n",
      "2026-02-18 16:42:20,437 - lg_cotrain - INFO - Test error rate: 22.92%, Test macro-F1: 0.5938, Test ECE: 0.0716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/12] budget=10, seed=2 -- done (macro_f1=0.5938)\n",
      "[PROGRESS] 17/120 (14.2%) | Elapsed: 3.26h | ETA: 19.75h\n",
      "[6/12] budget=10, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:42:21,062 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=10, seed_set=3\n",
      "2026-02-18 16:42:21,093 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:42:21,098 - lg_cotrain - INFO - D_l1: 40, D_l2: 40, D_LG: 1489\n",
      "2026-02-18 16:42:21,099 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1034.52it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1012.78it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:42:27,885 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1236, mean_prob2=0.1257\n",
      "2026-02-18 16:42:33,428 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1255, mean_prob2=0.1268\n",
      "2026-02-18 16:42:38,995 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1243, mean_prob2=0.1227\n",
      "2026-02-18 16:42:44,515 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1232, mean_prob2=0.1236\n",
      "2026-02-18 16:42:50,020 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1286, mean_prob2=0.1305\n",
      "2026-02-18 16:42:55,571 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1382, mean_prob2=0.1375\n",
      "2026-02-18 16:43:01,145 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1448, mean_prob2=0.1428\n",
      "2026-02-18 16:43:01,146 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1477, range=[0.0680, 0.2666]\n",
      "2026-02-18 16:43:01,148 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1151, range=[0.0672, 0.1807]\n",
      "2026-02-18 16:43:01,148 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1137.74it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 983.77it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:43:23,750 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1876, loss2=0.2327, dev_macro_f1=0.2191, dev_err=41.23%\n",
      "2026-02-18 16:43:45,406 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0904, loss2=0.1725, dev_macro_f1=0.4442, dev_err=25.88%\n",
      "2026-02-18 16:44:06,309 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0423, loss2=0.1390, dev_macro_f1=0.5068, dev_err=23.25%\n",
      "2026-02-18 16:44:26,898 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0210, loss2=0.1059, dev_macro_f1=0.5030, dev_err=24.12%\n",
      "2026-02-18 16:44:47,979 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0130, loss2=0.0870, dev_macro_f1=0.5014, dev_err=24.12%\n",
      "2026-02-18 16:45:08,999 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0095, loss2=0.0655, dev_macro_f1=0.5125, dev_err=26.32%\n",
      "2026-02-18 16:45:29,662 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0071, loss2=0.0441, dev_macro_f1=0.5169, dev_err=25.88%\n",
      "2026-02-18 16:45:50,955 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0059, loss2=0.0260, dev_macro_f1=0.5101, dev_err=25.88%\n",
      "2026-02-18 16:46:13,416 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0047, loss2=0.0202, dev_macro_f1=0.5276, dev_err=25.88%\n",
      "2026-02-18 16:46:34,066 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0075, loss2=0.0181, dev_macro_f1=0.5442, dev_err=22.37%\n",
      "2026-02-18 16:46:34,067 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:46:35,249 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5164, dev_err=26.75%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:46:36,442 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4994, dev_err=29.39%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:46:37,706 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5073, dev_err=32.46%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:46:38,911 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6194, dev_err=24.56%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:46:40,120 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6477, dev_err=23.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:46:41,308 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6495, dev_err=23.68%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:46:42,491 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6635, dev_err=22.37%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:46:43,667 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6601, dev_err=22.37%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:46:44,839 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6602, dev_err=21.93%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:46:46,012 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6381, dev_err=22.37%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:46:47,203 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6283, dev_err=23.25%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:46:48,453 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6317, dev_err=22.81%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:46:48,453 - lg_cotrain - INFO - Early stopping at epoch 12\n",
      "2026-02-18 16:46:48,463 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:46:50,816 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\10_set3\\metrics.json\n",
      "2026-02-18 16:46:50,816 - lg_cotrain - INFO - Test error rate: 23.82%, Test macro-F1: 0.6116, Test ECE: 0.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/12] budget=10, seed=3 -- done (macro_f1=0.6116)\n",
      "[PROGRESS] 18/120 (15.0%) | Elapsed: 3.33h | ETA: 18.89h\n",
      "[7/12] budget=25, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:46:51,381 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=25, seed_set=1\n",
      "2026-02-18 16:46:51,408 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:46:51,413 - lg_cotrain - INFO - D_l1: 98, D_l2: 91, D_LG: 1380\n",
      "2026-02-18 16:46:51,414 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1062.22it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1120.91it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:46:58,416 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1074, mean_prob2=0.1377\n",
      "2026-02-18 16:47:04,087 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1122, mean_prob2=0.1418\n",
      "2026-02-18 16:47:09,769 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1196, mean_prob2=0.1462\n",
      "2026-02-18 16:47:15,412 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1306, mean_prob2=0.1484\n",
      "2026-02-18 16:47:21,153 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1616, mean_prob2=0.1481\n",
      "2026-02-18 16:47:26,760 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1779, mean_prob2=0.1489\n",
      "2026-02-18 16:47:32,363 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1772, mean_prob2=0.1525\n",
      "2026-02-18 16:47:32,364 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1813, range=[0.0817, 0.2826]\n",
      "2026-02-18 16:47:32,365 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1257, range=[0.0312, 0.2190]\n",
      "2026-02-18 16:47:32,365 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1145.10it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1150.20it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:47:52,492 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1885, loss2=0.2681, dev_macro_f1=0.1648, dev_err=45.18%\n",
      "2026-02-18 16:48:11,502 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0853, loss2=0.1922, dev_macro_f1=0.4234, dev_err=26.75%\n",
      "2026-02-18 16:48:30,807 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0424, loss2=0.1375, dev_macro_f1=0.5008, dev_err=22.37%\n",
      "2026-02-18 16:48:50,011 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0251, loss2=0.1005, dev_macro_f1=0.5259, dev_err=22.37%\n",
      "2026-02-18 16:49:09,159 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0171, loss2=0.0912, dev_macro_f1=0.4998, dev_err=25.44%\n",
      "2026-02-18 16:49:28,393 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0119, loss2=0.0681, dev_macro_f1=0.5431, dev_err=23.25%\n",
      "2026-02-18 16:49:47,481 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0074, loss2=0.0455, dev_macro_f1=0.5419, dev_err=24.12%\n",
      "2026-02-18 16:50:06,692 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0055, loss2=0.0347, dev_macro_f1=0.5363, dev_err=23.68%\n",
      "2026-02-18 16:50:25,880 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0076, loss2=0.0251, dev_macro_f1=0.5498, dev_err=21.93%\n",
      "2026-02-18 16:50:44,911 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0103, loss2=0.0202, dev_macro_f1=0.5279, dev_err=24.56%\n",
      "2026-02-18 16:50:44,911 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:50:46,612 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5182, dev_err=27.19%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:50:48,298 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5015, dev_err=26.75%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:50:49,997 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5303, dev_err=25.00%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:50:51,735 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5552, dev_err=21.93%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:50:53,430 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5465, dev_err=22.37%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:50:55,147 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6764, dev_err=23.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:50:56,941 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6582, dev_err=22.37%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:50:58,696 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6405, dev_err=21.93%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:51:00,461 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6319, dev_err=22.81%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:51:02,158 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6338, dev_err=22.81%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:51:03,960 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6398, dev_err=23.25%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:51:03,961 - lg_cotrain - INFO - Early stopping at epoch 11\n",
      "2026-02-18 16:51:03,971 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:51:06,192 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\25_set1\\metrics.json\n",
      "2026-02-18 16:51:06,192 - lg_cotrain - INFO - Test error rate: 23.82%, Test macro-F1: 0.6072, Test ECE: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/12] budget=25, seed=1 -- done (macro_f1=0.6072)\n",
      "[PROGRESS] 19/120 (15.8%) | Elapsed: 3.41h | ETA: 18.10h\n",
      "[8/12] budget=25, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:51:06,741 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=25, seed_set=2\n",
      "2026-02-18 16:51:06,769 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:51:06,774 - lg_cotrain - INFO - D_l1: 98, D_l2: 91, D_LG: 1380\n",
      "2026-02-18 16:51:06,774 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1210.95it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1157.01it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:51:13,572 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1423, mean_prob2=0.1325\n",
      "2026-02-18 16:51:19,165 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1552, mean_prob2=0.1389\n",
      "2026-02-18 16:51:24,770 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1470, mean_prob2=0.1480\n",
      "2026-02-18 16:51:30,357 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1515, mean_prob2=0.1530\n",
      "2026-02-18 16:51:36,041 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1821, mean_prob2=0.1570\n",
      "2026-02-18 16:51:41,694 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.2035, mean_prob2=0.1599\n",
      "2026-02-18 16:51:47,303 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.2148, mean_prob2=0.1628\n",
      "2026-02-18 16:51:47,303 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.2091, range=[0.0748, 0.3642]\n",
      "2026-02-18 16:51:47,303 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1306, range=[0.0232, 0.2616]\n",
      "2026-02-18 16:51:47,303 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1180.13it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1198.58it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:52:07,358 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.2021, loss2=0.2857, dev_macro_f1=0.1702, dev_err=42.98%\n",
      "2026-02-18 16:52:26,356 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0859, loss2=0.2095, dev_macro_f1=0.4356, dev_err=24.56%\n",
      "2026-02-18 16:52:45,336 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0452, loss2=0.1600, dev_macro_f1=0.4483, dev_err=23.68%\n",
      "2026-02-18 16:53:04,371 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0268, loss2=0.1257, dev_macro_f1=0.5353, dev_err=20.61%\n",
      "2026-02-18 16:53:23,375 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0179, loss2=0.1069, dev_macro_f1=0.5124, dev_err=23.25%\n",
      "2026-02-18 16:53:43,034 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0111, loss2=0.0962, dev_macro_f1=0.5090, dev_err=24.56%\n",
      "2026-02-18 16:54:02,274 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0081, loss2=0.0659, dev_macro_f1=0.5549, dev_err=21.49%\n",
      "2026-02-18 16:54:21,492 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0068, loss2=0.0458, dev_macro_f1=0.5641, dev_err=22.37%\n",
      "2026-02-18 16:54:40,694 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0060, loss2=0.0301, dev_macro_f1=0.5410, dev_err=23.68%\n",
      "2026-02-18 16:54:59,974 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0059, loss2=0.0262, dev_macro_f1=0.5595, dev_err=22.37%\n",
      "2026-02-18 16:54:59,975 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:55:01,673 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5311, dev_err=25.88%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:03,354 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4866, dev_err=31.14%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:55:05,049 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5820, dev_err=24.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:06,748 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6112, dev_err=20.61%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:08,433 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5477, dev_err=24.56%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:55:10,117 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6050, dev_err=23.25%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:55:11,813 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6615, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:13,511 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6704, dev_err=22.37%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:15,225 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.7027, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:16,925 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.7156, dev_err=20.61%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:18,617 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6985, dev_err=20.61%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:55:20,320 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.7193, dev_err=20.18%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:55:22,028 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6980, dev_err=20.61%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:55:23,714 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6980, dev_err=20.61%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:55:25,402 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6980, dev_err=20.61%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:55:27,092 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6845, dev_err=20.61%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:55:28,782 - lg_cotrain - INFO - Phase 3 epoch 17: dev_macro_f1=0.6923, dev_err=20.18%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:55:28,782 - lg_cotrain - INFO - Early stopping at epoch 17\n",
      "2026-02-18 16:55:28,791 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:55:31,003 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\25_set2\\metrics.json\n",
      "2026-02-18 16:55:31,005 - lg_cotrain - INFO - Test error rate: 23.60%, Test macro-F1: 0.5994, Test ECE: 0.0966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/12] budget=25, seed=2 -- done (macro_f1=0.5994)\n",
      "[PROGRESS] 20/120 (16.7%) | Elapsed: 3.48h | ETA: 17.39h\n",
      "[9/12] budget=25, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:55:31,574 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=25, seed_set=3\n",
      "2026-02-18 16:55:31,602 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:55:31,607 - lg_cotrain - INFO - D_l1: 98, D_l2: 91, D_LG: 1380\n",
      "2026-02-18 16:55:31,608 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1213.58it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1186.71it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:55:38,309 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1237, mean_prob2=0.1271\n",
      "2026-02-18 16:55:43,919 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1305, mean_prob2=0.1330\n",
      "2026-02-18 16:55:49,540 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1356, mean_prob2=0.1394\n",
      "2026-02-18 16:55:55,134 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1272, mean_prob2=0.1511\n",
      "2026-02-18 16:56:00,741 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1197, mean_prob2=0.1571\n",
      "2026-02-18 16:56:06,367 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1301, mean_prob2=0.1624\n",
      "2026-02-18 16:56:11,966 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1516, mean_prob2=0.1710\n",
      "2026-02-18 16:56:11,967 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1504, range=[0.0638, 0.3152]\n",
      "2026-02-18 16:56:11,968 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1270, range=[0.0459, 0.1898]\n",
      "2026-02-18 16:56:11,969 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1043.63it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1222.23it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 16:56:32,067 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.2036, loss2=0.2498, dev_macro_f1=0.1675, dev_err=44.30%\n",
      "2026-02-18 16:56:51,076 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.1069, loss2=0.1754, dev_macro_f1=0.4609, dev_err=25.44%\n",
      "2026-02-18 16:57:10,108 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0520, loss2=0.1325, dev_macro_f1=0.4867, dev_err=23.68%\n",
      "2026-02-18 16:57:29,211 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0290, loss2=0.0977, dev_macro_f1=0.5022, dev_err=23.68%\n",
      "2026-02-18 16:57:48,385 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0176, loss2=0.0644, dev_macro_f1=0.4840, dev_err=25.44%\n",
      "2026-02-18 16:58:07,342 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0121, loss2=0.0604, dev_macro_f1=0.5179, dev_err=23.68%\n",
      "2026-02-18 16:58:26,535 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0092, loss2=0.0429, dev_macro_f1=0.5366, dev_err=23.25%\n",
      "2026-02-18 16:58:45,636 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0071, loss2=0.0289, dev_macro_f1=0.5294, dev_err=25.44%\n",
      "2026-02-18 16:59:04,620 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0052, loss2=0.0196, dev_macro_f1=0.5563, dev_err=22.81%\n",
      "2026-02-18 16:59:23,610 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0051, loss2=0.0238, dev_macro_f1=0.5195, dev_err=26.32%\n",
      "2026-02-18 16:59:23,611 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 16:59:25,315 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5164, dev_err=28.95%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:27,022 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5538, dev_err=24.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:28,738 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5690, dev_err=22.37%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:30,450 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.6067, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:32,150 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6201, dev_err=22.81%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:33,854 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6481, dev_err=23.68%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:35,544 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6439, dev_err=23.68%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:59:37,247 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6591, dev_err=22.37%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:38,952 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.7324, dev_err=19.74%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:40,632 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6861, dev_err=20.18%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:59:42,322 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.7301, dev_err=18.86%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:59:44,032 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.7591, dev_err=17.98%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 16:59:45,724 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6957, dev_err=18.86%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 16:59:47,409 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6957, dev_err=18.86%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 16:59:49,103 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6920, dev_err=18.86%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 16:59:50,790 - lg_cotrain - INFO - Phase 3 epoch 16: dev_macro_f1=0.6920, dev_err=18.86%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 16:59:52,477 - lg_cotrain - INFO - Phase 3 epoch 17: dev_macro_f1=0.7092, dev_err=17.98%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 16:59:52,478 - lg_cotrain - INFO - Early stopping at epoch 17\n",
      "2026-02-18 16:59:52,488 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 16:59:54,729 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\25_set3\\metrics.json\n",
      "2026-02-18 16:59:54,730 - lg_cotrain - INFO - Test error rate: 21.80%, Test macro-F1: 0.6146, Test ECE: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/12] budget=25, seed=3 -- done (macro_f1=0.6146)\n",
      "[PROGRESS] 21/120 (17.5%) | Elapsed: 3.55h | ETA: 16.75h\n",
      "[10/12] budget=50, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:59:55,324 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=50, seed_set=1\n",
      "2026-02-18 16:59:55,334 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 16:59:55,334 - lg_cotrain - INFO - D_l1: 182, D_l2: 182, D_LG: 1205\n",
      "2026-02-18 16:59:55,334 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1181.12it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1137.46it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:00:02,381 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1182, mean_prob2=0.1448\n",
      "2026-02-18 17:00:08,231 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1316, mean_prob2=0.1499\n",
      "2026-02-18 17:00:14,089 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1623, mean_prob2=0.1552\n",
      "2026-02-18 17:00:19,959 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1922, mean_prob2=0.1599\n",
      "2026-02-18 17:00:25,801 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1978, mean_prob2=0.1762\n",
      "2026-02-18 17:00:31,678 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.2282, mean_prob2=0.1943\n",
      "2026-02-18 17:00:37,537 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.2483, mean_prob2=0.2102\n",
      "2026-02-18 17:00:37,538 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.2346, range=[0.0741, 0.4128]\n",
      "2026-02-18 17:00:37,539 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1357, range=[0.0255, 0.2135]\n",
      "2026-02-18 17:00:37,539 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1172.90it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1165.06it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:00:55,393 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.2098, loss2=0.3394, dev_macro_f1=0.1618, dev_err=45.18%\n",
      "2026-02-18 17:01:13,184 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.1067, loss2=0.2221, dev_macro_f1=0.3310, dev_err=35.09%\n",
      "2026-02-18 17:01:31,691 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0581, loss2=0.1545, dev_macro_f1=0.4099, dev_err=27.19%\n",
      "2026-02-18 17:01:50,079 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0328, loss2=0.1136, dev_macro_f1=0.4618, dev_err=23.25%\n",
      "2026-02-18 17:02:08,362 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0210, loss2=0.0874, dev_macro_f1=0.4710, dev_err=25.44%\n",
      "2026-02-18 17:02:26,537 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0150, loss2=0.0709, dev_macro_f1=0.4965, dev_err=23.68%\n",
      "2026-02-18 17:02:44,694 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0101, loss2=0.0551, dev_macro_f1=0.5292, dev_err=23.68%\n",
      "2026-02-18 17:03:02,533 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0071, loss2=0.0446, dev_macro_f1=0.5181, dev_err=25.44%\n",
      "2026-02-18 17:03:20,265 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0077, loss2=0.0321, dev_macro_f1=0.5111, dev_err=24.56%\n",
      "2026-02-18 17:03:37,875 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0071, loss2=0.0290, dev_macro_f1=0.5112, dev_err=25.88%\n",
      "2026-02-18 17:03:37,876 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:03:40,549 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4831, dev_err=32.46%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:03:43,272 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5569, dev_err=22.81%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:03:45,937 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6065, dev_err=19.74%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:03:48,590 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5805, dev_err=22.37%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:03:51,234 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5945, dev_err=20.18%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:03:53,875 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5971, dev_err=20.61%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:03:56,809 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6524, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:03:59,586 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6414, dev_err=21.05%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:04:02,375 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6544, dev_err=19.74%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:04:05,169 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6995, dev_err=18.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:04:07,951 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6900, dev_err=19.30%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:04:10,721 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6847, dev_err=19.30%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:04:13,495 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6811, dev_err=19.74%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:04:16,273 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6765, dev_err=20.18%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:04:19,060 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6709, dev_err=20.61%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:04:19,061 - lg_cotrain - INFO - Early stopping at epoch 15\n",
      "2026-02-18 17:04:19,070 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:04:21,497 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\50_set1\\metrics.json\n",
      "2026-02-18 17:04:21,498 - lg_cotrain - INFO - Test error rate: 21.35%, Test macro-F1: 0.6098, Test ECE: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/12] budget=50, seed=1 -- done (macro_f1=0.6098)\n",
      "[PROGRESS] 22/120 (18.3%) | Elapsed: 3.63h | ETA: 16.15h\n",
      "[11/12] budget=50, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:04:22,056 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=50, seed_set=2\n",
      "2026-02-18 17:04:22,086 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:04:22,092 - lg_cotrain - INFO - D_l1: 182, D_l2: 182, D_LG: 1205\n",
      "2026-02-18 17:04:22,093 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1030.63it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1144.36it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:04:29,848 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1365, mean_prob2=0.1344\n",
      "2026-02-18 17:04:36,222 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1491, mean_prob2=0.1523\n",
      "2026-02-18 17:04:42,616 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1878, mean_prob2=0.1595\n",
      "2026-02-18 17:04:48,948 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.2237, mean_prob2=0.1734\n",
      "2026-02-18 17:04:55,180 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.2259, mean_prob2=0.1762\n",
      "2026-02-18 17:05:01,597 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.2688, mean_prob2=0.1934\n",
      "2026-02-18 17:05:08,122 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.2759, mean_prob2=0.2038\n",
      "2026-02-18 17:05:08,123 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.2726, range=[0.0548, 0.5132]\n",
      "2026-02-18 17:05:08,123 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1394, range=[0.0082, 0.2791]\n",
      "2026-02-18 17:05:08,124 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1104.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1045.15it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:05:26,920 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.2129, loss2=0.3587, dev_macro_f1=0.1647, dev_err=44.74%\n",
      "2026-02-18 17:05:43,658 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0979, loss2=0.2442, dev_macro_f1=0.2611, dev_err=37.28%\n",
      "2026-02-18 17:06:00,652 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0560, loss2=0.1919, dev_macro_f1=0.4133, dev_err=26.32%\n",
      "2026-02-18 17:06:17,350 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0337, loss2=0.1358, dev_macro_f1=0.4740, dev_err=22.37%\n",
      "2026-02-18 17:06:34,084 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0214, loss2=0.1142, dev_macro_f1=0.4886, dev_err=22.37%\n",
      "2026-02-18 17:06:50,828 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0150, loss2=0.0900, dev_macro_f1=0.5085, dev_err=22.81%\n",
      "2026-02-18 17:07:07,511 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0112, loss2=0.0742, dev_macro_f1=0.5059, dev_err=24.56%\n",
      "2026-02-18 17:07:24,287 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0081, loss2=0.0562, dev_macro_f1=0.5038, dev_err=23.68%\n",
      "2026-02-18 17:07:40,948 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0059, loss2=0.0389, dev_macro_f1=0.5425, dev_err=22.37%\n",
      "2026-02-18 17:07:57,621 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0051, loss2=0.0284, dev_macro_f1=0.5577, dev_err=22.81%\n",
      "2026-02-18 17:07:57,621 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:08:00,175 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5350, dev_err=25.88%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:02,734 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5570, dev_err=24.12%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:05,294 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6000, dev_err=21.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:07,830 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5924, dev_err=21.05%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:08:10,377 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6053, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:12,990 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6175, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:15,536 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6184, dev_err=21.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:18,061 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5975, dev_err=22.37%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:08:20,588 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6163, dev_err=21.05%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:08:23,267 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6413, dev_err=19.30%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:08:25,978 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6352, dev_err=20.18%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:08:28,656 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6322, dev_err=20.61%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:08:31,350 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6340, dev_err=20.61%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:08:34,032 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6364, dev_err=20.18%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:08:36,723 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6374, dev_err=20.18%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:08:36,724 - lg_cotrain - INFO - Early stopping at epoch 15\n",
      "2026-02-18 17:08:36,734 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:08:39,096 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\50_set2\\metrics.json\n",
      "2026-02-18 17:08:39,098 - lg_cotrain - INFO - Test error rate: 24.27%, Test macro-F1: 0.6061, Test ECE: 0.1070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/12] budget=50, seed=2 -- done (macro_f1=0.6061)\n",
      "[PROGRESS] 23/120 (19.2%) | Elapsed: 3.70h | ETA: 15.59h\n",
      "[12/12] budget=50, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:08:39,639 - lg_cotrain - INFO - Starting LG-CoTrain: event=canada_wildfires_2016, budget=50, seed_set=3\n",
      "2026-02-18 17:08:39,667 - lg_cotrain - INFO - Detected 8 classes for event canada_wildfires_2016: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:08:39,672 - lg_cotrain - INFO - D_l1: 182, D_l2: 182, D_LG: 1205\n",
      "2026-02-18 17:08:39,673 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1125.20it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1104.85it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:08:47,012 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1162, mean_prob2=0.1397\n",
      "2026-02-18 17:08:53,222 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1340, mean_prob2=0.1582\n",
      "2026-02-18 17:08:59,324 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1512, mean_prob2=0.1755\n",
      "2026-02-18 17:09:05,149 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1544, mean_prob2=0.1805\n",
      "2026-02-18 17:09:11,010 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1774, mean_prob2=0.2096\n",
      "2026-02-18 17:09:17,095 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1915, mean_prob2=0.2264\n",
      "2026-02-18 17:09:23,302 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.2131, mean_prob2=0.2579\n",
      "2026-02-18 17:09:23,302 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.2001, range=[0.0732, 0.3653]\n",
      "2026-02-18 17:09:23,303 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1490, range=[0.0333, 0.2032]\n",
      "2026-02-18 17:09:23,303 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1122.21it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1169.24it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:09:42,130 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.2265, loss2=0.3019, dev_macro_f1=0.1680, dev_err=43.86%\n",
      "2026-02-18 17:09:59,784 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.1201, loss2=0.1982, dev_macro_f1=0.3097, dev_err=34.21%\n",
      "2026-02-18 17:10:17,338 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0654, loss2=0.1400, dev_macro_f1=0.4092, dev_err=27.19%\n",
      "2026-02-18 17:10:34,977 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0362, loss2=0.1153, dev_macro_f1=0.4722, dev_err=23.68%\n",
      "2026-02-18 17:10:53,165 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0215, loss2=0.0904, dev_macro_f1=0.4813, dev_err=23.68%\n",
      "2026-02-18 17:11:10,197 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0143, loss2=0.0731, dev_macro_f1=0.4886, dev_err=24.12%\n",
      "2026-02-18 17:11:28,195 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0097, loss2=0.0658, dev_macro_f1=0.4824, dev_err=24.56%\n",
      "2026-02-18 17:11:46,494 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0084, loss2=0.0729, dev_macro_f1=0.4864, dev_err=24.12%\n",
      "2026-02-18 17:12:04,823 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0080, loss2=0.0433, dev_macro_f1=0.5056, dev_err=22.81%\n",
      "2026-02-18 17:12:23,141 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0116, loss2=0.0332, dev_macro_f1=0.5209, dev_err=24.12%\n",
      "2026-02-18 17:12:23,142 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:12:25,960 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4820, dev_err=32.46%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:28,777 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5647, dev_err=23.25%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:31,595 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.6198, dev_err=20.18%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:34,380 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5963, dev_err=21.49%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:12:37,187 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.6797, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:40,005 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.6859, dev_err=21.49%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:42,790 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.6558, dev_err=20.18%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:12:45,593 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.6854, dev_err=20.18%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:12:48,377 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.6710, dev_err=20.61%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:12:51,193 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.6891, dev_err=21.05%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:12:53,981 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.6891, dev_err=21.05%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:12:56,763 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.6786, dev_err=21.05%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:12:59,559 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.6761, dev_err=21.05%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:13:02,346 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.6761, dev_err=21.05%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:13:05,140 - lg_cotrain - INFO - Phase 3 epoch 15: dev_macro_f1=0.6753, dev_err=21.05%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:13:05,141 - lg_cotrain - INFO - Early stopping at epoch 15\n",
      "2026-02-18 17:13:05,150 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:13:07,593 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\canada_wildfires_2016\\50_set3\\metrics.json\n",
      "2026-02-18 17:13:07,593 - lg_cotrain - INFO - Test error rate: 22.47%, Test macro-F1: 0.6280, Test ECE: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/12] budget=50, seed=3 -- done (macro_f1=0.6280)\n",
      "[PROGRESS] 24/120 (20.0%) | Elapsed: 3.77h | ETA: 15.09h\n",
      "\n",
      "Batch complete: 12 ran, 0 skipped, 0 failed (3202.2s total)\n",
      "\n",
      "=== Results for canada_wildfires_2016 ===\n",
      "\n",
      "Budget    Seed 1              Seed 2              Seed 3                  Mean       Std\n",
      "           ErrR%  MacF1   ErrR%  MacF1   ErrR%  MacF1     ErrR%     MacF1\n",
      "-------------------------------------------------------------------------\n",
      "     5     22.70 0.5683   31.91 0.5202   26.29 0.5625  26.97+/-4.64   0.5503+/-0.0262\n",
      "    10     24.49 0.6029   22.92 0.5938   23.82 0.6116  23.75+/-0.79   0.6027+/-0.0089\n",
      "    25     23.82 0.6072   23.60 0.5994   21.80 0.6146  23.07+/-1.11   0.6071+/-0.0076\n",
      "    50     21.35 0.6098   24.27 0.6061   22.47 0.6280  22.70+/-1.47   0.6146+/-0.0117\n",
      "\n",
      "============================================================\n",
      "Event 3/10: cyclone_idai_2019\n",
      "============================================================\n",
      "[1/12] budget=5, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:13:08,264 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=5, seed_set=1\n",
      "2026-02-18 17:13:08,299 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:13:08,305 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 2703\n",
      "2026-02-18 17:13:08,307 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1000.51it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1084.58it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:13:20,034 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0924, mean_prob2=0.1170\n",
      "2026-02-18 17:13:30,486 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0938, mean_prob2=0.1103\n",
      "2026-02-18 17:13:41,012 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.0952, mean_prob2=0.1035\n",
      "2026-02-18 17:13:51,532 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.0970, mean_prob2=0.1000\n",
      "2026-02-18 17:14:01,998 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.0991, mean_prob2=0.1010\n",
      "2026-02-18 17:14:12,288 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1014, mean_prob2=0.1041\n",
      "2026-02-18 17:14:22,618 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1030, mean_prob2=0.1079\n",
      "2026-02-18 17:14:22,620 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1050, range=[0.0546, 0.2089]\n",
      "2026-02-18 17:14:22,621 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0920, range=[0.0310, 0.2221]\n",
      "2026-02-18 17:14:22,621 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 958.78it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1128.16it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:15:03,431 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1428, loss2=0.1597, dev_macro_f1=0.2929, dev_err=30.17%\n",
      "2026-02-18 17:15:42,378 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0481, loss2=0.1210, dev_macro_f1=0.3705, dev_err=27.18%\n",
      "2026-02-18 17:16:19,834 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0263, loss2=0.0902, dev_macro_f1=0.3862, dev_err=28.43%\n",
      "2026-02-18 17:16:56,960 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0164, loss2=0.0742, dev_macro_f1=0.4492, dev_err=28.18%\n",
      "2026-02-18 17:17:34,369 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0119, loss2=0.0522, dev_macro_f1=0.4942, dev_err=26.43%\n",
      "2026-02-18 17:18:11,750 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0110, loss2=0.0371, dev_macro_f1=0.5087, dev_err=24.94%\n",
      "2026-02-18 17:18:48,936 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0081, loss2=0.0292, dev_macro_f1=0.5266, dev_err=25.19%\n",
      "2026-02-18 17:19:26,118 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0090, loss2=0.0293, dev_macro_f1=0.5009, dev_err=24.44%\n",
      "2026-02-18 17:20:03,453 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0083, loss2=0.0154, dev_macro_f1=0.5091, dev_err=24.94%\n",
      "2026-02-18 17:20:40,611 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0083, loss2=0.0087, dev_macro_f1=0.4751, dev_err=26.43%\n",
      "2026-02-18 17:20:40,618 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:20:42,256 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5159, dev_err=26.43%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:20:43,888 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5128, dev_err=27.43%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:20:45,466 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5102, dev_err=34.16%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:20:47,062 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5069, dev_err=37.41%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:20:48,713 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5157, dev_err=39.15%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:20:50,362 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.4890, dev_err=40.65%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:20:50,363 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 17:20:50,377 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:20:54,385 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\5_set1\\metrics.json\n",
      "2026-02-18 17:20:54,386 - lg_cotrain - INFO - Test error rate: 24.13%, Test macro-F1: 0.5733, Test ECE: 0.0873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] budget=5, seed=1 -- done (macro_f1=0.5733)\n",
      "[PROGRESS] 25/120 (20.8%) | Elapsed: 3.90h | ETA: 14.83h\n",
      "[2/12] budget=5, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:20:54,938 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=5, seed_set=2\n",
      "2026-02-18 17:20:54,977 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:20:54,983 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 2703\n",
      "2026-02-18 17:20:54,985 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1115.40it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1111.41it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:21:05,763 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1068, mean_prob2=0.1222\n",
      "2026-02-18 17:21:15,300 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1054, mean_prob2=0.1173\n",
      "2026-02-18 17:21:24,815 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1041, mean_prob2=0.1140\n",
      "2026-02-18 17:21:34,394 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1020, mean_prob2=0.1146\n",
      "2026-02-18 17:21:44,006 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1007, mean_prob2=0.1147\n",
      "2026-02-18 17:21:53,570 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.0990, mean_prob2=0.1137\n",
      "2026-02-18 17:22:03,078 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.0983, mean_prob2=0.1149\n",
      "2026-02-18 17:22:03,081 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1099, range=[0.0630, 0.1772]\n",
      "2026-02-18 17:22:03,081 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1081, range=[0.0220, 0.1856]\n",
      "2026-02-18 17:22:03,082 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1199.14it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1139.78it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:22:41,546 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1483, loss2=0.1594, dev_macro_f1=0.2968, dev_err=30.67%\n",
      "2026-02-18 17:23:18,808 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0528, loss2=0.1554, dev_macro_f1=0.3401, dev_err=27.93%\n",
      "2026-02-18 17:23:56,067 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0260, loss2=0.1210, dev_macro_f1=0.4437, dev_err=25.69%\n",
      "2026-02-18 17:24:33,430 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0163, loss2=0.0922, dev_macro_f1=0.4608, dev_err=26.68%\n",
      "2026-02-18 17:25:11,638 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0109, loss2=0.0678, dev_macro_f1=0.4793, dev_err=25.94%\n",
      "2026-02-18 17:25:49,573 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0068, loss2=0.0490, dev_macro_f1=0.4762, dev_err=27.68%\n",
      "2026-02-18 17:26:27,394 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0057, loss2=0.0334, dev_macro_f1=0.4889, dev_err=25.19%\n",
      "2026-02-18 17:27:05,890 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0051, loss2=0.0441, dev_macro_f1=0.4824, dev_err=26.18%\n",
      "2026-02-18 17:27:45,669 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0059, loss2=0.0308, dev_macro_f1=0.5347, dev_err=23.19%\n",
      "2026-02-18 17:28:24,561 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0069, loss2=0.0121, dev_macro_f1=0.5492, dev_err=23.94%\n",
      "2026-02-18 17:28:24,562 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:28:26,196 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5301, dev_err=24.69%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:28:27,798 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5447, dev_err=24.69%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:28:29,394 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5547, dev_err=25.44%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:28:31,076 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5392, dev_err=26.93%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:28:32,777 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5044, dev_err=32.42%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:28:34,447 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5445, dev_err=33.42%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:28:36,128 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5289, dev_err=34.66%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:28:37,791 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5318, dev_err=33.67%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:28:37,792 - lg_cotrain - INFO - Early stopping at epoch 8\n",
      "2026-02-18 17:28:37,803 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:28:41,933 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\5_set2\\metrics.json\n",
      "2026-02-18 17:28:41,934 - lg_cotrain - INFO - Test error rate: 22.85%, Test macro-F1: 0.6294, Test ECE: 0.0828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/12] budget=5, seed=2 -- done (macro_f1=0.6294)\n",
      "[PROGRESS] 26/120 (21.7%) | Elapsed: 4.03h | ETA: 14.58h\n",
      "[3/12] budget=5, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:28:42,536 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=5, seed_set=3\n",
      "2026-02-18 17:28:42,582 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:28:42,590 - lg_cotrain - INFO - D_l1: 30, D_l2: 20, D_LG: 2703\n",
      "2026-02-18 17:28:42,592 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1004.37it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1153.02it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:28:53,878 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0998, mean_prob2=0.0980\n",
      "2026-02-18 17:29:04,187 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1057, mean_prob2=0.0996\n",
      "2026-02-18 17:29:14,408 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1059, mean_prob2=0.1006\n",
      "2026-02-18 17:29:24,682 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1037, mean_prob2=0.1010\n",
      "2026-02-18 17:29:34,914 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1010, mean_prob2=0.1005\n",
      "2026-02-18 17:29:45,152 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.0997, mean_prob2=0.1005\n",
      "2026-02-18 17:29:54,765 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.0990, mean_prob2=0.1004\n",
      "2026-02-18 17:29:54,766 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1100, range=[0.0588, 0.2088]\n",
      "2026-02-18 17:29:54,767 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0935, range=[0.0237, 0.2450]\n",
      "2026-02-18 17:29:54,768 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1111.78it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1029.54it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:30:33,682 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1517, loss2=0.1689, dev_macro_f1=0.2787, dev_err=31.17%\n",
      "2026-02-18 17:31:11,106 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0537, loss2=0.1375, dev_macro_f1=0.3615, dev_err=25.44%\n",
      "2026-02-18 17:31:48,374 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0254, loss2=0.1024, dev_macro_f1=0.3862, dev_err=28.43%\n",
      "2026-02-18 17:32:25,605 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0118, loss2=0.0805, dev_macro_f1=0.4182, dev_err=28.43%\n",
      "2026-02-18 17:33:02,836 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0061, loss2=0.0642, dev_macro_f1=0.5010, dev_err=30.67%\n",
      "2026-02-18 17:33:42,299 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0074, loss2=0.0412, dev_macro_f1=0.5268, dev_err=25.69%\n",
      "2026-02-18 17:34:21,712 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0073, loss2=0.0195, dev_macro_f1=0.5178, dev_err=25.44%\n",
      "2026-02-18 17:35:00,823 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0070, loss2=0.0204, dev_macro_f1=0.5073, dev_err=26.18%\n",
      "2026-02-18 17:35:40,657 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0058, loss2=0.0080, dev_macro_f1=0.5343, dev_err=23.94%\n",
      "2026-02-18 17:36:20,513 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0068, loss2=0.0051, dev_macro_f1=0.5327, dev_err=23.69%\n",
      "2026-02-18 17:36:20,514 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:36:22,194 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5775, dev_err=25.69%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:36:23,870 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4966, dev_err=31.92%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:36:25,548 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.4621, dev_err=42.64%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:36:27,227 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4282, dev_err=54.61%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:36:28,915 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.3982, dev_err=58.85%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:36:30,589 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.3862, dev_err=60.35%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:36:30,590 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 17:36:30,604 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:36:34,780 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\5_set3\\metrics.json\n",
      "2026-02-18 17:36:34,781 - lg_cotrain - INFO - Test error rate: 23.62%, Test macro-F1: 0.5878, Test ECE: 0.1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/12] budget=5, seed=3 -- done (macro_f1=0.5878)\n",
      "[PROGRESS] 27/120 (22.5%) | Elapsed: 4.16h | ETA: 14.34h\n",
      "[4/12] budget=10, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:36:35,335 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=10, seed_set=1\n",
      "2026-02-18 17:36:35,360 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:36:35,367 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 2653\n",
      "2026-02-18 17:36:35,368 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1148.81it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1084.30it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:36:46,675 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0945, mean_prob2=0.1120\n",
      "2026-02-18 17:36:56,866 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0963, mean_prob2=0.1053\n",
      "2026-02-18 17:37:07,005 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.0982, mean_prob2=0.1130\n",
      "2026-02-18 17:37:17,186 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1027, mean_prob2=0.1178\n",
      "2026-02-18 17:37:27,274 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1074, mean_prob2=0.1207\n",
      "2026-02-18 17:37:37,329 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1111, mean_prob2=0.1227\n",
      "2026-02-18 17:37:47,371 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1150, mean_prob2=0.1221\n",
      "2026-02-18 17:37:47,372 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1181, range=[0.0564, 0.1934]\n",
      "2026-02-18 17:37:47,373 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1001, range=[0.0255, 0.2688]\n",
      "2026-02-18 17:37:47,373 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1112.76it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1029.92it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:38:27,295 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1440, loss2=0.1743, dev_macro_f1=0.3050, dev_err=30.42%\n",
      "2026-02-18 17:39:06,035 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0541, loss2=0.1301, dev_macro_f1=0.3320, dev_err=28.43%\n",
      "2026-02-18 17:39:43,922 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0285, loss2=0.0970, dev_macro_f1=0.3484, dev_err=28.18%\n",
      "2026-02-18 17:40:21,248 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0185, loss2=0.0712, dev_macro_f1=0.4026, dev_err=27.18%\n",
      "2026-02-18 17:40:58,013 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0128, loss2=0.0524, dev_macro_f1=0.5372, dev_err=23.94%\n",
      "2026-02-18 17:41:34,672 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0088, loss2=0.0475, dev_macro_f1=0.5148, dev_err=24.94%\n",
      "2026-02-18 17:42:11,246 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0068, loss2=0.0313, dev_macro_f1=0.4835, dev_err=26.68%\n",
      "2026-02-18 17:42:48,259 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0064, loss2=0.0263, dev_macro_f1=0.5087, dev_err=25.44%\n",
      "2026-02-18 17:43:25,635 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0063, loss2=0.0142, dev_macro_f1=0.4900, dev_err=25.19%\n",
      "2026-02-18 17:44:02,939 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0105, loss2=0.0080, dev_macro_f1=0.5109, dev_err=24.94%\n",
      "2026-02-18 17:44:02,939 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:44:04,806 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5269, dev_err=29.43%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:44:06,646 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4036, dev_err=48.38%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:44:08,480 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.4052, dev_err=50.12%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:44:10,303 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4227, dev_err=43.14%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:44:12,150 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.4738, dev_err=35.91%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:44:13,995 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.4941, dev_err=33.17%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:44:13,995 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 17:44:14,005 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:44:17,929 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\10_set1\\metrics.json\n",
      "2026-02-18 17:44:17,930 - lg_cotrain - INFO - Test error rate: 26.57%, Test macro-F1: 0.6149, Test ECE: 0.1164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/12] budget=10, seed=1 -- done (macro_f1=0.6149)\n",
      "[PROGRESS] 28/120 (23.3%) | Elapsed: 4.29h | ETA: 14.10h\n",
      "[5/12] budget=10, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:44:18,466 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=10, seed_set=2\n",
      "2026-02-18 17:44:18,493 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:44:18,508 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 2653\n",
      "2026-02-18 17:44:18,509 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1051.14it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1186.38it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:44:29,274 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1078, mean_prob2=0.1075\n",
      "2026-02-18 17:44:39,110 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1087, mean_prob2=0.0919\n",
      "2026-02-18 17:44:49,098 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1064, mean_prob2=0.1024\n",
      "2026-02-18 17:44:58,992 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1059, mean_prob2=0.1183\n",
      "2026-02-18 17:45:09,080 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1052, mean_prob2=0.1248\n",
      "2026-02-18 17:45:18,943 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1081, mean_prob2=0.1244\n",
      "2026-02-18 17:45:28,637 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1126, mean_prob2=0.1187\n",
      "2026-02-18 17:45:28,637 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1186, range=[0.0600, 0.2132]\n",
      "2026-02-18 17:45:28,637 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0956, range=[0.0249, 0.1852]\n",
      "2026-02-18 17:45:28,642 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1031.86it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1064.07it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:46:06,620 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1363, loss2=0.1745, dev_macro_f1=0.3123, dev_err=29.68%\n",
      "2026-02-18 17:46:45,318 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0473, loss2=0.1619, dev_macro_f1=0.3703, dev_err=26.93%\n",
      "2026-02-18 17:47:25,018 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0228, loss2=0.1206, dev_macro_f1=0.4142, dev_err=27.68%\n",
      "2026-02-18 17:48:02,086 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0115, loss2=0.0929, dev_macro_f1=0.4840, dev_err=25.94%\n",
      "2026-02-18 17:48:41,097 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0073, loss2=0.0789, dev_macro_f1=0.4794, dev_err=26.43%\n",
      "2026-02-18 17:49:19,741 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0055, loss2=0.0587, dev_macro_f1=0.4712, dev_err=26.93%\n",
      "2026-02-18 17:49:56,424 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0049, loss2=0.0497, dev_macro_f1=0.5284, dev_err=24.94%\n",
      "2026-02-18 17:50:33,662 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0073, loss2=0.0402, dev_macro_f1=0.5191, dev_err=25.69%\n",
      "2026-02-18 17:51:10,609 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0061, loss2=0.0223, dev_macro_f1=0.5111, dev_err=25.44%\n",
      "2026-02-18 17:51:48,095 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0062, loss2=0.0251, dev_macro_f1=0.5380, dev_err=23.69%\n",
      "2026-02-18 17:51:48,096 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:51:49,942 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.5640, dev_err=23.19%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:51:51,768 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.5193, dev_err=26.68%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:51:53,598 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.4755, dev_err=34.16%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:51:55,425 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4939, dev_err=36.66%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:51:57,248 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5277, dev_err=29.93%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:51:59,078 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5503, dev_err=27.18%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:51:59,079 - lg_cotrain - INFO - Early stopping at epoch 6\n",
      "2026-02-18 17:51:59,086 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:52:02,985 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\10_set2\\metrics.json\n",
      "2026-02-18 17:52:02,986 - lg_cotrain - INFO - Test error rate: 22.21%, Test macro-F1: 0.5451, Test ECE: 0.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/12] budget=10, seed=2 -- done (macro_f1=0.5451)\n",
      "[PROGRESS] 29/120 (24.2%) | Elapsed: 4.42h | ETA: 13.87h\n",
      "[6/12] budget=10, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:52:03,554 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=10, seed_set=3\n",
      "2026-02-18 17:52:03,599 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:52:03,606 - lg_cotrain - INFO - D_l1: 50, D_l2: 50, D_LG: 2653\n",
      "2026-02-18 17:52:03,607 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1130.88it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1161.36it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:52:14,281 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0962, mean_prob2=0.1030\n",
      "2026-02-18 17:52:23,855 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1000, mean_prob2=0.1078\n",
      "2026-02-18 17:52:33,409 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.0998, mean_prob2=0.1072\n",
      "2026-02-18 17:52:42,979 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.0975, mean_prob2=0.1064\n",
      "2026-02-18 17:52:52,569 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.0951, mean_prob2=0.1070\n",
      "2026-02-18 17:53:02,127 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.0952, mean_prob2=0.1090\n",
      "2026-02-18 17:53:11,706 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.0958, mean_prob2=0.1115\n",
      "2026-02-18 17:53:11,708 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1057, range=[0.0612, 0.2074]\n",
      "2026-02-18 17:53:11,708 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0980, range=[0.0145, 0.2540]\n",
      "2026-02-18 17:53:11,708 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1184.63it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1139.17it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 17:53:49,281 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1539, loss2=0.1747, dev_macro_f1=0.2307, dev_err=36.16%\n",
      "2026-02-18 17:54:25,686 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0562, loss2=0.1595, dev_macro_f1=0.3292, dev_err=28.18%\n",
      "2026-02-18 17:55:02,074 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0286, loss2=0.1299, dev_macro_f1=0.3544, dev_err=30.17%\n",
      "2026-02-18 17:55:38,866 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0140, loss2=0.1024, dev_macro_f1=0.4370, dev_err=28.93%\n",
      "2026-02-18 17:56:15,707 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0080, loss2=0.0807, dev_macro_f1=0.4851, dev_err=28.18%\n",
      "2026-02-18 17:56:52,385 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0060, loss2=0.0593, dev_macro_f1=0.4983, dev_err=25.94%\n",
      "2026-02-18 17:57:28,901 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0049, loss2=0.0323, dev_macro_f1=0.4951, dev_err=26.18%\n",
      "2026-02-18 17:58:05,504 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0041, loss2=0.0205, dev_macro_f1=0.5124, dev_err=25.44%\n",
      "2026-02-18 17:58:42,372 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0062, loss2=0.0142, dev_macro_f1=0.4987, dev_err=26.18%\n",
      "2026-02-18 17:59:19,140 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0066, loss2=0.0157, dev_macro_f1=0.5114, dev_err=25.69%\n",
      "2026-02-18 17:59:19,141 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 17:59:20,983 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4489, dev_err=38.15%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:22,808 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.3782, dev_err=59.35%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:59:24,693 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.3611, dev_err=67.08%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:59:26,605 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4256, dev_err=62.59%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:59:28,447 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.4894, dev_err=47.63%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:30,358 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.4997, dev_err=37.41%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:32,210 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5101, dev_err=33.42%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:34,050 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.5215, dev_err=31.17%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:35,914 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.5360, dev_err=31.17%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 17:59:37,832 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.5243, dev_err=32.17%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 17:59:39,697 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.5120, dev_err=33.42%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 17:59:41,586 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.5111, dev_err=33.42%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 17:59:43,445 - lg_cotrain - INFO - Phase 3 epoch 13: dev_macro_f1=0.5095, dev_err=33.67%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 17:59:45,285 - lg_cotrain - INFO - Phase 3 epoch 14: dev_macro_f1=0.5109, dev_err=34.41%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 17:59:45,285 - lg_cotrain - INFO - Early stopping at epoch 14\n",
      "2026-02-18 17:59:45,301 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 17:59:49,192 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\10_set3\\metrics.json\n",
      "2026-02-18 17:59:49,192 - lg_cotrain - INFO - Test error rate: 27.98%, Test macro-F1: 0.6207, Test ECE: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/12] budget=10, seed=3 -- done (macro_f1=0.6207)\n",
      "[PROGRESS] 30/120 (25.0%) | Elapsed: 4.55h | ETA: 13.65h\n",
      "[7/12] budget=25, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 17:59:49,740 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=25, seed_set=1\n",
      "2026-02-18 17:59:49,763 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 17:59:49,769 - lg_cotrain - INFO - D_l1: 124, D_l2: 114, D_LG: 2515\n",
      "2026-02-18 17:59:49,771 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1223.06it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1116.50it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:00:00,835 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.0994, mean_prob2=0.1036\n",
      "2026-02-18 18:00:10,653 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.0990, mean_prob2=0.1108\n",
      "2026-02-18 18:00:20,487 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1104, mean_prob2=0.1179\n",
      "2026-02-18 18:00:30,400 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1157, mean_prob2=0.1225\n",
      "2026-02-18 18:00:40,332 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1182, mean_prob2=0.1281\n",
      "2026-02-18 18:00:50,407 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1246, mean_prob2=0.1301\n",
      "2026-02-18 18:01:00,311 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1353, mean_prob2=0.1297\n",
      "2026-02-18 18:01:00,312 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1364, range=[0.0523, 0.2501]\n",
      "2026-02-18 18:01:00,314 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.0972, range=[0.0260, 0.2454]\n",
      "2026-02-18 18:01:00,314 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1112.80it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1068.05it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:01:36,536 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1413, loss2=0.1968, dev_macro_f1=0.2841, dev_err=31.42%\n",
      "2026-02-18 18:02:12,795 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0489, loss2=0.1362, dev_macro_f1=0.3550, dev_err=26.18%\n",
      "2026-02-18 18:02:49,721 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0272, loss2=0.0997, dev_macro_f1=0.3792, dev_err=27.18%\n",
      "2026-02-18 18:03:26,715 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0180, loss2=0.0786, dev_macro_f1=0.3720, dev_err=27.93%\n",
      "2026-02-18 18:04:03,915 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0126, loss2=0.0546, dev_macro_f1=0.4684, dev_err=25.69%\n",
      "2026-02-18 18:04:40,793 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0108, loss2=0.0444, dev_macro_f1=0.5062, dev_err=24.94%\n",
      "2026-02-18 18:05:15,902 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0077, loss2=0.0370, dev_macro_f1=0.4833, dev_err=25.19%\n",
      "2026-02-18 18:05:50,729 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0082, loss2=0.0386, dev_macro_f1=0.4882, dev_err=24.19%\n",
      "2026-02-18 18:06:25,475 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0075, loss2=0.0201, dev_macro_f1=0.4887, dev_err=25.44%\n",
      "2026-02-18 18:07:00,267 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0079, loss2=0.0341, dev_macro_f1=0.5137, dev_err=24.19%\n",
      "2026-02-18 18:07:00,267 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 18:07:02,769 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4309, dev_err=46.88%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:07:05,249 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4123, dev_err=49.88%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 18:07:07,741 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.4364, dev_err=42.14%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:07:10,239 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4770, dev_err=37.66%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:07:12,725 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.4611, dev_err=37.41%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 18:07:15,205 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.4752, dev_err=35.16%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 18:07:17,700 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5019, dev_err=32.67%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:07:20,178 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.4941, dev_err=33.67%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 18:07:22,668 - lg_cotrain - INFO - Phase 3 epoch 9: dev_macro_f1=0.4880, dev_err=34.41%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 18:07:25,145 - lg_cotrain - INFO - Phase 3 epoch 10: dev_macro_f1=0.4851, dev_err=35.16%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 18:07:27,623 - lg_cotrain - INFO - Phase 3 epoch 11: dev_macro_f1=0.4877, dev_err=35.16%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 18:07:30,100 - lg_cotrain - INFO - Phase 3 epoch 12: dev_macro_f1=0.4929, dev_err=35.16%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 18:07:30,101 - lg_cotrain - INFO - Early stopping at epoch 12\n",
      "2026-02-18 18:07:30,110 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 18:07:34,004 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\25_set1\\metrics.json\n",
      "2026-02-18 18:07:34,004 - lg_cotrain - INFO - Test error rate: 31.19%, Test macro-F1: 0.6207, Test ECE: 0.0773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/12] budget=25, seed=1 -- done (macro_f1=0.6207)\n",
      "[PROGRESS] 31/120 (25.8%) | Elapsed: 4.68h | ETA: 13.44h\n",
      "[8/12] budget=25, seed=2 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 18:07:34,560 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=25, seed_set=2\n",
      "2026-02-18 18:07:34,601 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 18:07:34,609 - lg_cotrain - INFO - D_l1: 124, D_l2: 114, D_LG: 2515\n",
      "2026-02-18 18:07:34,610 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1127.75it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1240.80it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:07:45,462 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1017, mean_prob2=0.1019\n",
      "2026-02-18 18:07:55,236 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1041, mean_prob2=0.1150\n",
      "2026-02-18 18:08:04,992 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1078, mean_prob2=0.1217\n",
      "2026-02-18 18:08:14,749 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1148, mean_prob2=0.1322\n",
      "2026-02-18 18:08:24,528 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1261, mean_prob2=0.1375\n",
      "2026-02-18 18:08:34,332 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1333, mean_prob2=0.1230\n",
      "2026-02-18 18:08:44,306 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1438, mean_prob2=0.1357\n",
      "2026-02-18 18:08:44,307 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1375, range=[0.0566, 0.2537]\n",
      "2026-02-18 18:08:44,307 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1040, range=[0.0181, 0.1833]\n",
      "2026-02-18 18:08:44,308 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1097.74it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1095.77it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:09:20,527 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1442, loss2=0.1956, dev_macro_f1=0.2517, dev_err=32.92%\n",
      "2026-02-18 18:09:55,608 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0583, loss2=0.1666, dev_macro_f1=0.3442, dev_err=26.68%\n",
      "2026-02-18 18:10:30,738 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0265, loss2=0.1251, dev_macro_f1=0.3849, dev_err=27.93%\n",
      "2026-02-18 18:11:05,764 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0141, loss2=0.1020, dev_macro_f1=0.4396, dev_err=27.93%\n",
      "2026-02-18 18:11:40,562 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0091, loss2=0.0845, dev_macro_f1=0.4795, dev_err=27.18%\n",
      "2026-02-18 18:12:15,880 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0067, loss2=0.0681, dev_macro_f1=0.4818, dev_err=27.18%\n",
      "2026-02-18 18:12:51,901 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0055, loss2=0.0448, dev_macro_f1=0.4852, dev_err=25.69%\n",
      "2026-02-18 18:13:26,923 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0045, loss2=0.0305, dev_macro_f1=0.4775, dev_err=26.68%\n",
      "2026-02-18 18:14:01,674 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0077, loss2=0.0193, dev_macro_f1=0.4772, dev_err=25.94%\n",
      "2026-02-18 18:14:36,376 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0082, loss2=0.0135, dev_macro_f1=0.5080, dev_err=23.19%\n",
      "2026-02-18 18:14:36,378 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 18:14:38,870 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.3527, dev_err=56.86%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:14:41,371 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4727, dev_err=38.15%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:14:43,867 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5289, dev_err=28.93%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:14:46,346 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.4980, dev_err=28.18%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 18:14:48,843 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.5030, dev_err=27.68%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 18:14:51,324 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.5146, dev_err=28.68%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 18:14:53,808 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.5091, dev_err=31.17%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 18:14:56,288 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.4957, dev_err=32.67%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 18:14:56,288 - lg_cotrain - INFO - Early stopping at epoch 8\n",
      "2026-02-18 18:14:56,303 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 18:15:00,197 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\25_set2\\metrics.json\n",
      "2026-02-18 18:15:00,197 - lg_cotrain - INFO - Test error rate: 26.06%, Test macro-F1: 0.6023, Test ECE: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/12] budget=25, seed=2 -- done (macro_f1=0.6023)\n",
      "[PROGRESS] 32/120 (26.7%) | Elapsed: 4.80h | ETA: 13.21h\n",
      "[9/12] budget=25, seed=3 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 18:15:00,748 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=25, seed_set=3\n",
      "2026-02-18 18:15:00,786 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 18:15:00,792 - lg_cotrain - INFO - D_l1: 124, D_l2: 114, D_LG: 2515\n",
      "2026-02-18 18:15:00,793 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1206.68it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1190.31it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:15:11,680 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1000, mean_prob2=0.1077\n",
      "2026-02-18 18:15:21,442 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1040, mean_prob2=0.1088\n",
      "2026-02-18 18:15:31,221 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1040, mean_prob2=0.1077\n",
      "2026-02-18 18:15:41,010 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1041, mean_prob2=0.1117\n",
      "2026-02-18 18:15:50,790 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1102, mean_prob2=0.1143\n",
      "2026-02-18 18:16:00,550 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1112, mean_prob2=0.1151\n",
      "2026-02-18 18:16:10,327 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1125, mean_prob2=0.1186\n",
      "2026-02-18 18:16:10,328 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1176, range=[0.0520, 0.2533]\n",
      "2026-02-18 18:16:10,329 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1016, range=[0.0233, 0.2492]\n",
      "2026-02-18 18:16:10,329 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1092.44it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1186.41it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:16:46,127 - lg_cotrain - INFO - Phase 2 epoch 1/10: loss1=0.1556, loss2=0.1800, dev_macro_f1=0.2366, dev_err=34.66%\n",
      "2026-02-18 18:17:20,977 - lg_cotrain - INFO - Phase 2 epoch 2/10: loss1=0.0580, loss2=0.1447, dev_macro_f1=0.3174, dev_err=29.68%\n",
      "2026-02-18 18:17:55,948 - lg_cotrain - INFO - Phase 2 epoch 3/10: loss1=0.0291, loss2=0.1018, dev_macro_f1=0.3687, dev_err=28.43%\n",
      "2026-02-18 18:18:30,571 - lg_cotrain - INFO - Phase 2 epoch 4/10: loss1=0.0152, loss2=0.0829, dev_macro_f1=0.4456, dev_err=26.18%\n",
      "2026-02-18 18:19:05,414 - lg_cotrain - INFO - Phase 2 epoch 5/10: loss1=0.0120, loss2=0.0601, dev_macro_f1=0.4512, dev_err=28.18%\n",
      "2026-02-18 18:19:40,159 - lg_cotrain - INFO - Phase 2 epoch 6/10: loss1=0.0095, loss2=0.0408, dev_macro_f1=0.4980, dev_err=26.18%\n",
      "2026-02-18 18:20:15,008 - lg_cotrain - INFO - Phase 2 epoch 7/10: loss1=0.0066, loss2=0.0285, dev_macro_f1=0.5165, dev_err=24.94%\n",
      "2026-02-18 18:20:49,822 - lg_cotrain - INFO - Phase 2 epoch 8/10: loss1=0.0057, loss2=0.0199, dev_macro_f1=0.4937, dev_err=25.44%\n",
      "2026-02-18 18:21:25,021 - lg_cotrain - INFO - Phase 2 epoch 9/10: loss1=0.0062, loss2=0.0340, dev_macro_f1=0.4862, dev_err=25.44%\n",
      "2026-02-18 18:22:00,589 - lg_cotrain - INFO - Phase 2 epoch 10/10: loss1=0.0043, loss2=0.0334, dev_macro_f1=0.4970, dev_err=26.18%\n",
      "2026-02-18 18:22:00,589 - lg_cotrain - INFO - === Phase 3: Fine-Tuning ===\n",
      "2026-02-18 18:22:03,088 - lg_cotrain - INFO - Phase 3 epoch 1: dev_macro_f1=0.4577, dev_err=36.66%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:22:05,580 - lg_cotrain - INFO - Phase 3 epoch 2: dev_macro_f1=0.4760, dev_err=43.89%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:22:08,079 - lg_cotrain - INFO - Phase 3 epoch 3: dev_macro_f1=0.5144, dev_err=31.42%, es_counter1=0, es_counter2=0\n",
      "2026-02-18 18:22:10,556 - lg_cotrain - INFO - Phase 3 epoch 4: dev_macro_f1=0.5081, dev_err=30.42%, es_counter1=1, es_counter2=1\n",
      "2026-02-18 18:22:13,044 - lg_cotrain - INFO - Phase 3 epoch 5: dev_macro_f1=0.4836, dev_err=32.67%, es_counter1=2, es_counter2=2\n",
      "2026-02-18 18:22:15,528 - lg_cotrain - INFO - Phase 3 epoch 6: dev_macro_f1=0.4887, dev_err=32.42%, es_counter1=3, es_counter2=3\n",
      "2026-02-18 18:22:18,010 - lg_cotrain - INFO - Phase 3 epoch 7: dev_macro_f1=0.4940, dev_err=32.92%, es_counter1=4, es_counter2=4\n",
      "2026-02-18 18:22:20,480 - lg_cotrain - INFO - Phase 3 epoch 8: dev_macro_f1=0.4966, dev_err=33.67%, es_counter1=5, es_counter2=5\n",
      "2026-02-18 18:22:20,480 - lg_cotrain - INFO - Early stopping at epoch 8\n",
      "2026-02-18 18:22:20,501 - lg_cotrain - INFO - === Final Evaluation ===\n",
      "2026-02-18 18:22:24,392 - lg_cotrain - INFO - Results saved to D:\\Workspace\\Co-Training\\results\\gpt-4o-run-2\\cyclone_idai_2019\\25_set3\\metrics.json\n",
      "2026-02-18 18:22:24,393 - lg_cotrain - INFO - Test error rate: 27.73%, Test macro-F1: 0.6124, Test ECE: 0.0466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/12] budget=25, seed=3 -- done (macro_f1=0.6124)\n",
      "[PROGRESS] 33/120 (27.5%) | Elapsed: 4.93h | ETA: 12.99h\n",
      "[10/12] budget=50, seed=1 -- starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 18:22:24,949 - lg_cotrain - INFO - Starting LG-CoTrain: event=cyclone_idai_2019, budget=50, seed_set=1\n",
      "2026-02-18 18:22:24,971 - lg_cotrain - INFO - Detected 10 classes for event cyclone_idai_2019: ['caution_and_advice', 'displaced_people_and_evacuations', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'requests_or_urgent_needs', 'rescue_volunteering_or_donation_effort', 'sympathy_and_support']\n",
      "2026-02-18 18:22:24,971 - lg_cotrain - INFO - D_l1: 227, D_l2: 226, D_LG: 2300\n",
      "2026-02-18 18:22:24,971 - lg_cotrain - INFO - === Phase 1: Weight Generation ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1188.14it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1216.71it/s, Materializing param=bert.pooler.dense.weight]\n",
      "2026-02-18 18:22:36,569 - lg_cotrain - INFO - Phase 1 epoch 1/7: mean_prob1=0.1059, mean_prob2=0.1254\n",
      "2026-02-18 18:22:46,861 - lg_cotrain - INFO - Phase 1 epoch 2/7: mean_prob1=0.1102, mean_prob2=0.1264\n",
      "2026-02-18 18:22:57,573 - lg_cotrain - INFO - Phase 1 epoch 3/7: mean_prob1=0.1219, mean_prob2=0.1199\n",
      "2026-02-18 18:23:08,337 - lg_cotrain - INFO - Phase 1 epoch 4/7: mean_prob1=0.1297, mean_prob2=0.1239\n",
      "2026-02-18 18:23:18,889 - lg_cotrain - INFO - Phase 1 epoch 5/7: mean_prob1=0.1381, mean_prob2=0.1335\n",
      "2026-02-18 18:23:29,365 - lg_cotrain - INFO - Phase 1 epoch 6/7: mean_prob1=0.1477, mean_prob2=0.1512\n",
      "2026-02-18 18:23:40,161 - lg_cotrain - INFO - Phase 1 epoch 7/7: mean_prob1=0.1627, mean_prob2=0.1611\n",
      "2026-02-18 18:23:40,162 - lg_cotrain - INFO - Phase 1 done. lambda1: mean=0.1583, range=[0.0598, 0.2795]\n",
      "2026-02-18 18:23:40,163 - lg_cotrain - INFO - Phase 1 done. lambda2: mean=0.1093, range=[0.0185, 0.3042]\n",
      "2026-02-18 18:23:40,163 - lg_cotrain - INFO - === Phase 2: Co-Training ===\n",
      "Loading weights: 100%|███████████████| 199/199 [00:00<00:00, 1017.25it/s, Materializing param=bert.pooler.dense.weight]\n",
      "Loading weights: 100%|████████████████| 199/199 [00:00<00:00, 997.20it/s, Materializing param=bert.pooler.dense.weight]\n"
     ]
    }
   ],
   "source": [
    "class ProgressTracker:\n",
    "    \"\"\"Track global progress across all experiments.\"\"\"\n",
    "\n",
    "    def __init__(self, total, already_done, start_time):\n",
    "        self.total = total\n",
    "        self.done = already_done\n",
    "        self.start_time = start_time\n",
    "\n",
    "    def update(self, event, budget, seed_set, status):\n",
    "        self.done += 1\n",
    "        elapsed = time.time() - self.start_time\n",
    "        pct = 100.0 * self.done / self.total\n",
    "        elapsed_h = elapsed / 3600\n",
    "\n",
    "        remaining = self.total - self.done\n",
    "        if elapsed > 0 and self.done > 0:\n",
    "            eta_h = (elapsed / self.done) * remaining / 3600\n",
    "        else:\n",
    "            eta_h = 0\n",
    "\n",
    "        print(\n",
    "            f\"[PROGRESS] {self.done}/{self.total} ({pct:.1f}%)\"\n",
    "            f\" | Elapsed: {elapsed_h:.2f}h | ETA: {eta_h:.2f}h\"\n",
    "        )\n",
    "\n",
    "# Count already-completed experiments (from previous runs)\n",
    "already_done = sum(\n",
    "    1\n",
    "    for e in all_events\n",
    "    for b in BUDGETS\n",
    "    for s in SEED_SETS\n",
    "    if (Path(RESULTS_ROOT) / e / f\"{b}_set{s}\" / \"metrics.json\").exists()\n",
    ")\n",
    "total_experiments = len(all_events) * len(BUDGETS) * len(SEED_SETS)\n",
    "\n",
    "print(f\"Total experiments: {total_experiments}\")\n",
    "print(f\"Already completed: {already_done}\")\n",
    "print(f\"Remaining: {total_experiments - already_done}\")\n",
    "\n",
    "all_event_results = {}\n",
    "overall_start = time.time()\n",
    "tracker = ProgressTracker(total_experiments, already_done, overall_start)\n",
    "\n",
    "# Run pending events\n",
    "for i, event in enumerate(pending_events, 1):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Event {i}/{len(pending_events)}: {event}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    results = run_all_experiments(\n",
    "        event,\n",
    "        pseudo_label_source=PSEUDO_LABEL_SOURCE,\n",
    "        data_root=DATA_ROOT,\n",
    "        results_root=RESULTS_ROOT,\n",
    "        _on_experiment_done=tracker.update,\n",
    "    )\n",
    "    all_event_results[event] = results\n",
    "\n",
    "    print()\n",
    "    print(format_summary_table(results, event))\n",
    "\n",
    "# Load results for already-completed events\n",
    "for event in completed_events:\n",
    "    results = []\n",
    "    for budget in BUDGETS:\n",
    "        for seed_set in SEED_SETS:\n",
    "            path = Path(RESULTS_ROOT) / event / f\"{budget}_set{seed_set}\" / \"metrics.json\"\n",
    "            with open(path) as f:\n",
    "                results.append(json.load(f))\n",
    "    all_event_results[event] = results\n",
    "\n",
    "overall_elapsed = time.time() - overall_start\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"All events done in {overall_elapsed / 3600:.2f}h\")\n",
    "print(f\"Total events with results: {len(all_event_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Disaster Results\n",
    "\n",
    "We now aggregate results across all events to compare how the pipeline\n",
    "performs on different disaster types and how performance scales with the\n",
    "labeled data budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross-disaster summary: event -> budget -> mean macro-F1\n",
    "summary = {}\n",
    "for event in sorted(all_event_results.keys()):\n",
    "    results = all_event_results[event]\n",
    "    by_budget = {b: [] for b in BUDGETS}\n",
    "    for r in results:\n",
    "        if r is not None:\n",
    "            by_budget[r[\"budget\"]].append(r)\n",
    "    summary[event] = {}\n",
    "    for b in BUDGETS:\n",
    "        f1s = [r[\"test_macro_f1\"] for r in by_budget[b]]\n",
    "        errs = [r[\"test_error_rate\"] for r in by_budget[b]]\n",
    "        summary[event][b] = {\n",
    "            \"f1_mean\": statistics.mean(f1s) if f1s else None,\n",
    "            \"f1_std\": statistics.stdev(f1s) if len(f1s) >= 2 else None,\n",
    "            \"err_mean\": statistics.mean(errs) if errs else None,\n",
    "            \"err_std\": statistics.stdev(errs) if len(errs) >= 2 else None,\n",
    "            \"n_seeds\": len(f1s),\n",
    "        }\n",
    "\n",
    "# Print grand summary table\n",
    "header = f\"{'Event':<35}\"\n",
    "for b in BUDGETS:\n",
    "    header += f\" | B={b:<11}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for event in sorted(summary.keys()):\n",
    "    row = f\"{event:<35}\"\n",
    "    for b in BUDGETS:\n",
    "        s = summary[event][b]\n",
    "        if s[\"f1_mean\"] is not None and s[\"f1_std\"] is not None:\n",
    "            row += f\" | {s['f1_mean']:.3f}+/-{s['f1_std']:.3f}\"\n",
    "        elif s[\"f1_mean\"] is not None:\n",
    "            row += f\" | {s['f1_mean']:.3f}      \"\n",
    "        else:\n",
    "            row += f\" | {'N/A':<11}\"\n",
    "    print(row)\n",
    "\n",
    "# Line plot: Macro-F1 by budget, one line per event\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for event in sorted(summary.keys()):\n",
    "    means = [summary[event][b][\"f1_mean\"] or 0 for b in BUDGETS]\n",
    "    stds = [summary[event][b][\"f1_std\"] or 0 for b in BUDGETS]\n",
    "    ax.errorbar(BUDGETS, means, yerr=stds, marker=\"o\", capsize=3, label=event)\n",
    "\n",
    "ax.set_xlabel(\"Budget (labeled samples per class)\")\n",
    "ax.set_ylabel(\"Test Macro-F1 (mean +/- std across seeds)\")\n",
    "ax.set_title(f\"LG-CoTrain Performance — {PSEUDO_LABEL_SOURCE}\")\n",
    "ax.set_xticks(BUDGETS)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap: events (rows) x budgets (columns), colored by mean macro-F1\n",
    "events_sorted = sorted(summary.keys())\n",
    "heatmap_data = np.zeros((len(events_sorted), len(BUDGETS)))\n",
    "\n",
    "for i, event in enumerate(events_sorted):\n",
    "    for j, b in enumerate(BUDGETS):\n",
    "        val = summary[event][b][\"f1_mean\"]\n",
    "        heatmap_data[i, j] = val if val is not None else 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(heatmap_data, cmap=\"YlOrRd\", aspect=\"auto\")\n",
    "\n",
    "ax.set_xticks(range(len(BUDGETS)))\n",
    "ax.set_xticklabels([f\"B={b}\" for b in BUDGETS])\n",
    "ax.set_yticks(range(len(events_sorted)))\n",
    "ax.set_yticklabels(events_sorted, fontsize=9)\n",
    "ax.set_title(f\"Mean Test Macro-F1 — {PSEUDO_LABEL_SOURCE}\")\n",
    "\n",
    "for i in range(len(events_sorted)):\n",
    "    for j in range(len(BUDGETS)):\n",
    "        val = heatmap_data[i, j]\n",
    "        color = \"white\" if val > 0.6 else \"black\"\n",
    "        ax.text(j, i, f\"{val:.3f}\", ha=\"center\", va=\"center\", color=color, fontsize=9)\n",
    "\n",
    "fig.colorbar(im, ax=ax, label=\"Macro-F1\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lg_cotrain.dashboard import collect_all_metrics, generate_html\n",
    "\n",
    "metrics = collect_all_metrics(RESULTS_ROOT)\n",
    "html = generate_html(metrics, RESULTS_ROOT)\n",
    "dashboard_path = Path(RESULTS_ROOT) / \"dashboard.html\"\n",
    "dashboard_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dashboard_path.write_text(html)\n",
    "print(f\"Dashboard written to: {dashboard_path}\")\n",
    "print(f\"Metrics loaded: {len(metrics)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook ran experiments for all disaster events using:\n",
    "- **Pseudo-label source**: configured via `PSEUDO_LABEL_SOURCE`\n",
    "- **Results folder**: `results/{RUN_NAME}/`\n",
    "\n",
    "Results are stored separately from previous runs, enabling side-by-side\n",
    "comparison via the multi-tab dashboard.\n",
    "\n",
    "### CLI equivalent\n",
    "```bash\n",
    "# Run all experiments for all events with custom pseudo-label source and output folder\n",
    "python -m lg_cotrain.run_experiment \\\n",
    "    --events california_wildfires_2018 canada_wildfires_2016 cyclone_idai_2019 \\\n",
    "            hurricane_dorian_2019 hurricane_florence_2018 hurricane_harvey_2017 \\\n",
    "            hurricane_irma_2017 hurricane_maria_2017 kaikoura_earthquake_2016 \\\n",
    "            kerala_floods_2018 \\\n",
    "    --pseudo-label-source gpt-4o \\\n",
    "    --output-folder results/gpt-4o-run1\n",
    "```\n",
    "\n",
    "### Generate multi-tab dashboard from the CLI\n",
    "```bash\n",
    "python -m lg_cotrain.dashboard --results-root results/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
